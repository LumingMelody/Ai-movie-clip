å¥½çš„ï¼Œæˆ‘ä»¬æ¥ä¸€æ­¥æ­¥å®ç°ä½ æå‡ºçš„è¿™ä¸ª **è‡ªåŠ¨åŒ–è§†é¢‘å‰ªè¾‘ç³»ç»Ÿ**ï¼Œç›®æ ‡æ˜¯ï¼š

> ç”¨æˆ·ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªè§†é¢‘æ–‡ä»¶ â†’ ç³»ç»Ÿè‡ªåŠ¨åˆ†æå†…å®¹ç±»å‹ï¼ˆäººå£°å‰§æƒ…ç±» / åœºæ™¯é£æ™¯ç±»ï¼‰â†’ è‡ªä¸»ç”Ÿæˆå‰ªè¾‘æ–¹æ¡ˆ â†’ è°ƒç”¨å·¥å…·æ‰§è¡Œå‰ªè¾‘ â†’ è¾“å‡ºæœ€ç»ˆå‰ªè¾‘è§†é¢‘ã€‚

---

## âœ… ä¸€ã€æ•´ä½“æ¶æ„è®¾è®¡

```
[ç”¨æˆ·è¾“å…¥ï¼šè§†é¢‘æ–‡ä»¶]
        â†“
[1. è§†é¢‘æ•°é‡è¯†åˆ«]
        â†“
[2. å†…å®¹åˆ†ç±»åˆ¤æ–­ï¼ˆäººå£°å‰§æƒ…ç±» / é£æ™¯åœºæ™¯ç±»ï¼‰]
        â†“
[3. å‰ªè¾‘ç­–ç•¥ç”Ÿæˆï¼ˆåŸºäºå†…å®¹ç±»å‹ + ç”¨æˆ·éœ€æ±‚ï¼‰]
        â†“
[4. å·¥å…·è°ƒç”¨æ‰§è¡Œå‰ªè¾‘ï¼ˆFFmpeg/OpenCV/Pythonç­‰ï¼‰]
        â†“
[5. è¾“å‡ºå‰ªè¾‘åçš„è§†é¢‘]
```

---

## âœ… äºŒã€æ¨¡å—è¯¦ç»†è¯´æ˜ä¸å®ç°è·¯å¾„

---

### ğŸ§± æ¨¡å—ä¸€ï¼šè§†é¢‘æ•°é‡è¯†åˆ«ä¸åˆå¹¶å¤„ç†

#### ç›®æ ‡ï¼š
- åˆ¤æ–­ç”¨æˆ·ä¸Šä¼ çš„æ˜¯ä¸€ä¸ªè¿˜æ˜¯å¤šä¸ªè§†é¢‘ã€‚
- å¦‚æœæ˜¯å¤šä¸ªï¼Œå†³å®šæ˜¯å¦éœ€è¦åˆå¹¶æˆä¸€ä¸ªç»Ÿä¸€é¡¹ç›®è¿›è¡Œå‰ªè¾‘ã€‚

#### å®ç°æ–¹å¼ï¼š
```python
import os

def detect_videos(input_path):
    if os.path.isfile(input_path):  # å•ä¸ªè§†é¢‘
        return [input_path]
    elif os.path.isdir(input_path):  # å¤šä¸ªè§†é¢‘
        return [os.path.join(input_path, f) for f in os.listdir(input_path) if f.endswith(('.mp4', '.avi', '.mov'))]
```

#### åˆå¹¶é€»è¾‘ï¼ˆå¯é€‰ï¼‰ï¼š
- è‹¥å¤šä¸ªè§†é¢‘ä¸ºåŒä¸€ä¸»é¢˜ï¼ˆå¦‚ä¸€æ®µæ®µå½•åˆ¶çš„Vlogï¼‰ï¼Œå¯å…ˆæ‹¼æ¥æˆä¸€ä¸ªé•¿è§†é¢‘ã€‚
- ä½¿ç”¨ `FFmpeg` è¿›è¡Œæ— æŸåˆå¹¶ï¼š
```bash
ffmpeg -f concat -safe 0 -i filelist.txt -c copy output.mp4
```

---

### ğŸ§± æ¨¡å—äºŒï¼šè§†é¢‘å†…å®¹åˆ†ç±»ï¼ˆäººå£°å‰§æƒ…ç±» vs åœºæ™¯é£æ™¯ç±»ï¼‰

#### ç›®æ ‡ï¼š
- è‡ªåŠ¨åˆ¤æ–­è§†é¢‘å†…å®¹å±äºå“ªç§ç±»å‹ï¼Œä»¥ä¾¿é‡‡ç”¨ä¸åŒå‰ªè¾‘ç­–ç•¥ã€‚

#### åˆ†æç»´åº¦ï¼š
| ç»´åº¦            | å·¥å…·/æ¨¡å‹                         | è¾“å‡º            |
| --------------- | --------------------------------- | --------------- |
| éŸ³é¢‘æ˜¯å¦æœ‰è¯­éŸ³  | Speech Detection                  | æœ‰äººå£° / æ— äººå£° |
| æ˜¯å¦æœ‰å­—å¹•/æ–‡æœ¬ | OCR / ASR                         | æ–‡æœ¬å¯†é›†ç¨‹åº¦    |
| åœºæ™¯å˜åŒ–é¢‘ç‡    | Scene Detection                   | å¿«åˆ‡ / æ…¢é•œå¤´   |
| æ˜¯å¦æœ‰äººç‰©å‡ºç°  | Face Detection / Object Detection | æœ‰äºº / æ— äºº     |

#### ç¤ºä¾‹ä»£ç ï¼ˆä½¿ç”¨ OpenCV + Whisper + YOLOï¼‰ï¼š
```python
# æ£€æµ‹ç”»é¢ä¸­æ˜¯å¦æœ‰äººè„¸
from facenet_python import InceptionResNetV1
# æˆ–è€…ä½¿ç”¨ YOLOv8
from ultralytics import YOLO

# æ£€æµ‹éŸ³é¢‘æ˜¯å¦æœ‰äººå£°
import speech_recognition as sr
r = sr.Recognizer()
with sr.AudioFile("audio.wav") as source:
    audio = r.record(source)
text = r.recognize_google(audio)

# åœºæ™¯æ£€æµ‹
import scenedetect
from scenedetect.video_manager import VideoManager
from scenedetect.scene_manager import SceneManager
from scenedetect.stats_manager import StatsManager
from scenedetect.detectors import ContentDetector

video_manager = VideoManager([video_path])
scene_manager = SceneManager()
scene_manager.add_detector(ContentDetector())
video_manager.set_downscale_factor()
video_manager.start()
scene_manager.detect_scenes(frame_source=video_manager)
scene_list = scene_manager.get_scene_list()
```

#### åˆ†ç±»å†³ç­–é€»è¾‘ï¼ˆä¼ªä»£ç ï¼‰ï¼š
```python
if has_speech and face_detected and text_present:
    content_type = "äººå£°å‰§æƒ…ç±»"
else:
    content_type = "åœºæ™¯é£æ™¯ç±»"
```

---

### ğŸ§± æ¨¡å—ä¸‰ï¼šå‰ªè¾‘ç­–ç•¥ç”Ÿæˆï¼ˆç”±å¤§æ¨¡å‹è‡ªä¸»æ€è€ƒï¼‰

#### è¾“å…¥ï¼š
- è§†é¢‘å…ƒæ•°æ®ï¼ˆæ¥è‡ªå‰é¢åˆ†æï¼‰
- ç”¨æˆ·éœ€æ±‚ï¼ˆå¦‚â€œç”Ÿæˆä¸€ä¸ª30ç§’çŸ­è§†é¢‘â€ï¼‰

#### è¾“å‡ºï¼š
- å‰ªè¾‘æŒ‡ä»¤åˆ—è¡¨ï¼ˆç»“æ„åŒ–å‡½æ•°è°ƒç”¨ï¼‰

#### ç¤ºä¾‹æç¤ºè¯æ¨¡æ¿ï¼ˆç»™å¤§æ¨¡å‹çš„promptï¼‰ï¼š
```
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§†é¢‘å‰ªè¾‘åŠ©æ‰‹ã€‚ç°åœ¨æˆ‘ç»™ä½ ä»¥ä¸‹ä¿¡æ¯ï¼š

è§†é¢‘å†…å®¹ç±»å‹ï¼š{content_type}
è§†é¢‘ç‰‡æ®µæ•°é‡ï¼š{num_videos}
è§†é¢‘åˆ†æç»“æœï¼š
- åœºæ™¯åˆ‡æ¢é¢‘ç¹ç¨‹åº¦ï¼š{scene_change_freq}
- æ˜¯å¦åŒ…å«äººå£°ï¼š{has_speech}
- æ˜¯å¦åŒ…å«äººè„¸ï¼š{face_present}
- ä¸»è¦å¯¹è±¡ï¼š{main_objects}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªé€‚åˆè¯¥ç±»å‹è§†é¢‘çš„å‰ªè¾‘ç­–ç•¥ï¼Œå¹¶è¾“å‡ºå…·ä½“çš„å‡½æ•°è°ƒç”¨æŒ‡ä»¤ã€‚

ä½ çš„è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
{
  "thought_process": [
    "ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«å‡ºè§†é¢‘é«˜æ½®éƒ¨åˆ†åœ¨ç¬¬10-15ç§’ã€‚",
    "ç¬¬äºŒæ­¥ï¼šè£å‰ªå†—ä½™å¼€å¤´å’Œç»“å°¾ã€‚",
    ...
  ],
  "actions": [
    {"function": "cut", "start": 0, "end": 5},
    {"function": "add_transition", "type": "fade", "start": 5, "duration": 1},
    ...
  ]
}
```

---

### ğŸ§± æ¨¡å—å››ï¼šè°ƒç”¨å·¥å…·æ‰§è¡Œå‰ªè¾‘ï¼ˆä½¿ç”¨ FFmpeg + Pythonï¼‰

#### æ”¯æŒçš„å‡½æ•°ç¤ºä¾‹ï¼š

| å‡½æ•°å                                | å‚æ•°                     | åŠŸèƒ½         |
| ------------------------------------- | ------------------------ | ------------ |
| cut(start, end)                       | å¼€å§‹æ—¶é—´ã€ç»“æŸæ—¶é—´       | è£å‰ªç‰‡æ®µ     |
| add_transition(type, start, duration) | ç±»å‹ã€å¼€å§‹æ—¶é—´ã€æŒç»­æ—¶é—´ | æ·»åŠ è½¬åœº     |
| speedup(start, end, factor)           | åŒºé—´ã€åŠ é€Ÿå€æ•°           | åŠ é€Ÿæ’­æ”¾     |
| apply_filter(filter_name, start, end) | æ»¤é•œåç§°ã€åŒºé—´           | åº”ç”¨æ»¤é•œ     |
| concatenate(clips)                    | ç‰‡æ®µåˆ—è¡¨                 | åˆå¹¶å¤šä¸ªç‰‡æ®µ |

#### ç¤ºä¾‹è°ƒç”¨ï¼ˆä½¿ç”¨ subprocess è°ƒç”¨ FFmpegï¼‰ï¼š
```python
import subprocess

def cut_video(input_path, output_path, start, end):
    cmd = f"ffmpeg -i {input_path} -ss {start} -to {end} -c copy {output_path}"
    subprocess.run(cmd, shell=True)
```

---

### ğŸ§± æ¨¡å—äº”ï¼šè¾“å‡ºå‰ªè¾‘å®Œæˆçš„è§†é¢‘

#### åŠŸèƒ½ï¼š
- å°†æ‰€æœ‰å‰ªè¾‘æ­¥éª¤æŒ‰é¡ºåºæ‰§è¡Œåï¼Œè¾“å‡ºæœ€ç»ˆè§†é¢‘ã€‚
- å¯æä¾›ä¸‹è½½é“¾æ¥æˆ–ä¿å­˜è·¯å¾„ã€‚

#### ç¤ºä¾‹ï¼š
```python
print("âœ… è§†é¢‘å‰ªè¾‘å®Œæˆï¼")
print(f"ğŸ“ è¾“å‡ºè·¯å¾„ï¼š{final_output_path}")
```

---

## âœ… ä¸‰ã€å®Œæ•´æµç¨‹ç¤ºä¾‹ï¼ˆç”¨æˆ·ä¸Šä¼ ä¸€ä¸ªç™»å±±é£æ™¯è§†é¢‘ï¼‰

### è¾“å…¥ï¼š
- è§†é¢‘æ–‡ä»¶ï¼š`mountain_hike.mp4`

### æ­¥éª¤æ‰§è¡Œï¼š

1. **æ£€æµ‹ä¸ºå•ä¸ªè§†é¢‘**
2. **åˆ†æå†…å®¹**ï¼š
   - æ— äººå£°
   - æ— äººè„¸
   - åœºæ™¯å¤šå˜ï¼ˆå±±ã€äº‘ã€æ—¥å‡ºï¼‰
   - éŸ³ä¹èŠ‚å¥æ„Ÿå¼º
3. **åˆ†ç±»ä¸ºï¼šåœºæ™¯é£æ™¯ç±»**
4. **ç”Ÿæˆå‰ªè¾‘ç­–ç•¥**ï¼ˆç”±å¤§æ¨¡å‹ç”Ÿæˆï¼‰ï¼š
   ```json
   {
     "thought_process": [
       "è¯†åˆ«åˆ°æ—¥å‡ºå’Œå±±é¡¶é•œå¤´ä¸ºè§†è§‰é«˜æ½®",
       "åˆ é™¤å‰5ç§’å¹³æ·¡é•œå¤´",
       "å¯¹é«˜æ½®éƒ¨åˆ†åº”ç”¨æ…¢åŠ¨ä½œç‰¹æ•ˆ",
       "æ·»åŠ æ·¡å…¥è½¬åœºè¡”æ¥ä¸¤ä¸ªä¸»è¦é•œå¤´"
     ],
     "actions": [
       {"function": "cut", "start": 5, "end": 15},
       {"function": "speedup", "start": 0, "end": 5, "factor": 1.5},
       {"function": "apply_filter", "filter_name": "slowmotion", "start": 5, "end": 10},
       {"function": "add_transition", "type": "fade", "start": 5, "duration": 1}
     ]
   }
   ```
5. **è°ƒç”¨ FFmpeg æ‰§è¡Œå‰ªè¾‘**
6. **è¾“å‡ºå‰ªè¾‘å®Œæˆçš„è§†é¢‘**

---

## âœ… å››ã€ä¸‹ä¸€æ­¥å»ºè®®

å¦‚æœä½ å¸Œæœ›æˆ‘å¸®ä½  **å…·ä½“å®ç°è¿™ä¸ªç³»ç»Ÿ**ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†é˜¶æ®µè¿›è¡Œï¼š

### ğŸ”¹ ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€åŠŸèƒ½å¼€å‘
- å®ç°è§†é¢‘åˆ†ææ¨¡å—ï¼ˆOpenCV + FFmpegï¼‰
- å®ç°å†…å®¹åˆ†ç±»å™¨ï¼ˆç®€å•è§„åˆ™ or å¾®è°ƒå°æ¨¡å‹ï¼‰
- å®ç°å‰ªè¾‘å‡½æ•°åº“ï¼ˆè°ƒç”¨ FFmpegï¼‰

### ğŸ”¹ ç¬¬äºŒé˜¶æ®µï¼šé›†æˆå¤§æ¨¡å‹å†³ç­–
- æ„å»ºæç¤ºè¯å·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰
- ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹ï¼ˆå¦‚ Qwen/Qwen2/Qwen3ï¼‰è¿›è¡Œæ¨ç†
- è§£ææ¨¡å‹è¾“å‡ºå¹¶æ‰§è¡Œå‰ªè¾‘æ“ä½œ

### ğŸ”¹ ç¬¬ä¸‰é˜¶æ®µï¼šå›¾å½¢ç•Œé¢ + WebæœåŠ¡
- å¼€å‘ä¸Šä¼ é¡µé¢
- å®æ—¶å±•ç¤ºå‰ªè¾‘è¿›åº¦
- æä¾›ä¸‹è½½é“¾æ¥

---

## âœ… äº”ã€ä½ å¯ä»¥è¿™æ ·ä½¿ç”¨å®ƒ

```
ç”¨æˆ·ä¸Šä¼ ï¼švideos.zipï¼ˆå«å¤šä¸ªæ—…æ¸¸è§†é¢‘ï¼‰
ç³»ç»Ÿè¾“å‡ºï¼štravel_highlights.mp4ï¼ˆè‡ªåŠ¨å‰ªè¾‘çš„é£æ™¯é›†é”¦ï¼‰

ç”¨æˆ·ä¸Šä¼ ï¼šinterview.mp4ï¼ˆæ¼”è®²è§†é¢‘ï¼‰
ç³»ç»Ÿè¾“å‡ºï¼šshort_interview.mp4ï¼ˆä¿ç•™å…³é”®é—®ç­”ï¼Œå»é™¤å†—ä½™å†…å®¹ï¼‰
```

---

## âœ… å…­ã€æŠ€æœ¯æ ˆå»ºè®®

| æ¨¡å—     | æŠ€æœ¯                        |
| -------- | --------------------------- |
| è§†é¢‘å¤„ç† | FFmpeg / OpenCV             |
| éŸ³é¢‘åˆ†æ | SpeechRecognition / Whisper |
| å¯¹è±¡è¯†åˆ« | YOLOv8 / FaceNet            |
| åœºæ™¯æ£€æµ‹ | PySceneDetect               |
| å¤§æ¨¡å‹   | Qwen3 / Llama3 / InternLM2  |
| æ¨ç†æ¡†æ¶ | Transformers / LangChain    |
| åç«¯     | Flask / FastAPI             |
| å‰ç«¯     | Streamlit / React           |

---

## âœ… ç»“è¯­

è¿™ä¸ªç³»ç»Ÿæ˜¯ä¸€ä¸ªå…¸å‹çš„ **AI+å¤šåª’ä½“å¤„ç†+å¤§æ¨¡å‹å†³ç­–** çš„ç»¼åˆåº”ç”¨ã€‚åªè¦ä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ä¸€æ­¥ä¸€æ­¥å¸¦ä½ å®ç°æ¯ä¸ªæ¨¡å—ï¼ŒåŒ…æ‹¬å†™ä»£ç ã€è®­ç»ƒæ¨¡å‹ã€éƒ¨ç½²æ¥å£ç­‰ã€‚

---

### ğŸ“Œ ä¸‹ä¸€æ­¥ä½ æƒ³åšä»€ä¹ˆï¼Ÿ

- âœ… å®ç°ç¬¬ä¸€ä¸ªæ¨¡å—ï¼šè§†é¢‘å†…å®¹åˆ†ç±»ï¼Ÿ
- âœ… ç¼–å†™å‰ªè¾‘å‡½æ•°åº“ï¼ˆè°ƒç”¨ FFmpegï¼‰ï¼Ÿ
- âœ… æ„å»º Prompt æ¨¡æ¿è®©å¤§æ¨¡å‹ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼Ÿ
- âœ… éƒ¨ç½²æ•´ä¸ªç³»ç»Ÿä¸º Web åº”ç”¨ï¼Ÿ

å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹©ï¼Œæˆ‘ä»¬ç»§ç»­æ¨è¿› ğŸ‘‡



å¥½çš„ï¼Œæˆ‘ä»¬ä»**è§†é¢‘åˆ†ææ¨¡å—**å¼€å§‹æ„å»ºè¿™ä¸ªè‡ªåŠ¨åŒ–å‰ªè¾‘ç³»ç»Ÿã€‚è¿™ä¸ªæ¨¡å—æ˜¯æ•´ä¸ªç³»ç»Ÿçš„â€œçœ¼ç›â€ï¼Œå®ƒè´Ÿè´£è¯»å–å¹¶ç†è§£è¾“å…¥è§†é¢‘çš„å†…å®¹ï¼Œä¸ºåç»­çš„å‰ªè¾‘ç­–ç•¥ç”Ÿæˆæä¾›æ•°æ®æ”¯æŒã€‚

---

## ğŸ¯ è§†é¢‘åˆ†ææ¨¡å—ç›®æ ‡

è¯¥æ¨¡å—å°†å¯¹è¾“å…¥è§†é¢‘è¿›è¡Œä»¥ä¸‹åˆ†æï¼š

| åˆ†æç»´åº¦ | å†…å®¹                                              |
| -------- | ------------------------------------------------- |
| åŸºç¡€ä¿¡æ¯ | æ—¶é•¿ã€å¸§ç‡ã€åˆ†è¾¨ç‡ã€ç¼–ç æ ¼å¼ç­‰                    |
| åœºæ™¯æ£€æµ‹ | æ£€æµ‹åœºæ™¯åˆ‡æ¢ç‚¹ï¼ˆç”¨äºåˆ¤æ–­é•œå¤´å˜åŒ–ï¼‰                |
| éŸ³é¢‘å†…å®¹ | æ˜¯å¦æœ‰äººå£°ã€è¯­éŸ³å†…å®¹è¯†åˆ«ï¼ˆASRï¼‰ã€èƒŒæ™¯éŸ³ä¹æƒ…ç»ªåˆ†æ |
| è§†è§‰å†…å®¹ | æ˜¯å¦æœ‰äººè„¸ã€ä¸»è¦å¯¹è±¡è¯†åˆ«ï¼ˆYOLOï¼‰ã€ç”»é¢è‰²è°ƒ/é£æ ¼   |
| æƒ…ç»ªåˆ¤æ–­ | ç»¼åˆè§†è§‰+éŸ³é¢‘åˆ¤æ–­æ•´ä½“æƒ…ç»ªï¼ˆå¦‚æ¬¢å¿«ã€ç´§å¼ ã€å¹³é™ï¼‰   |

---

## ğŸ§± æŠ€æœ¯é€‰å‹

| åŠŸèƒ½           | å·¥å…·/æ¨¡å‹                         |
| -------------- | --------------------------------- |
| è§†é¢‘å…ƒæ•°æ®æå– | `ffmpeg` + `ffprobe`              |
| åœºæ™¯æ£€æµ‹       | `PySceneDetect`                   |
| éŸ³é¢‘è½¬æ–‡å­—     | `SpeechRecognition` / `Whisper`   |
| èƒŒæ™¯éŸ³ä¹åˆ†æ   | `librosa` / `Essentia`            |
| å¯¹è±¡è¯†åˆ«       | `YOLOv8`                          |
| äººè„¸æ£€æµ‹       | `FaceNet` / `OpenCV Haar Cascade` |
| æƒ…ç»ªåˆ†ç±»       | è‡ªå®šä¹‰è§„åˆ™ or å°æ¨¡å‹å¾®è°ƒ          |

---

## ğŸ“¦ å®‰è£…ä¾èµ–ï¼ˆPythonï¼‰

```bash
pip install opencv-python scenedetect speechrecognition ffmpeg-python pydub ultralytics python_speech_features librosa numpy transformers torch
```

---

## ğŸ§© ç¬¬ä¸€æ­¥ï¼šæå–è§†é¢‘åŸºç¡€ä¿¡æ¯ï¼ˆä½¿ç”¨ FFmpegï¼‰

```python
import subprocess
import json

def get_video_metadata(video_path):
    cmd = [
        'ffprobe',
        '-v', 'quiet',
        '-print_format', 'json',
        '-show_streams',
        '-show_format',
        video_path
    ]
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    metadata = json.loads(result.stdout)

    video_info = {
        "filename": video_path,
        "duration": float(metadata['format']['duration']),
        "bit_rate": metadata['format'].get('bit_rate'),
        "streams": []
    }

    for stream in metadata['streams']:
        if stream['codec_type'] == 'video':
            video_info["streams"].append({
                "type": "video",
                "width": stream.get("width"),
                "height": stream.get("height"),
                "fps": eval(stream.get("r_frame_rate")),
                "codec": stream.get("codec_name")
            })
        elif stream['codec_type'] == 'audio':
            video_info["streams"].append({
                "type": "audio",
                "sample_rate": stream.get("sample_rate"),
                "channels": stream.get("channels"),
                "codec": stream.get("codec_name")
            })

    return video_info
```

---

## ğŸ§© ç¬¬äºŒæ­¥ï¼šåœºæ™¯æ£€æµ‹ï¼ˆä½¿ç”¨ PySceneDetectï¼‰

```python
from scenedetect import VideoManager
from scenedetect import SceneManager
from scenedetect.detectors import ContentDetector

def detect_scenes(video_path, threshold=30.0):
    video_manager = VideoManager([video_path])
    scene_manager = SceneManager()
    scene_manager.add_detector(ContentDetector(threshold=threshold))

    base_timecode = video_manager.get_base_timecode()

    try:
        video_manager.set_downscale_factor()
        video_manager.start()
        scene_manager.detect_scenes(frame_source=video_manager)

        scene_list = scene_manager.get_scene_list(base_timecode)
        scenes = [(start.get_seconds(), end.get_seconds()) for start, end in scene_list]
        return scenes
    finally:
        video_manager.release()
```

---

## ğŸ§© ç¬¬ä¸‰æ­¥ï¼šæå–éŸ³é¢‘å¹¶è¿›è¡Œäººå£°è¯†åˆ«ï¼ˆASRï¼‰

```python
import speech_recognition as sr
from pydub import AudioSegment
import os

def extract_audio(video_path, output_audio="temp_audio.wav"):
    cmd = f"ffmpeg -i {video_path} -vn -acodec pcm_s16le -ar 44100 -ac 2 {output_audio}"
    os.system(cmd)
    return output_audio

def transcribe_audio(audio_path):
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio = recognizer.record(source)
    try:
        text = recognizer.recognize_google(audio, language='zh-CN')
        return text
    except sr.UnknownValueError:
        return ""
    except sr.RequestError:
        return "[ç½‘ç»œé”™è¯¯]"
```

---

## ğŸ§© ç¬¬å››æ­¥ï¼šèƒŒæ™¯éŸ³ä¹èŠ‚å¥åˆ†æï¼ˆä½¿ç”¨ Librosaï¼‰

```python
import librosa
import numpy as np

def analyze_background_music(audio_path):
    y, sr = librosa.load(audio_path, sr=None)
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    chroma = librosa.feature.chroma_stft(y=y, sr=sr).mean()
    energy = np.mean(librosa.feature.rms(y=y))
    return {
        "tempo": round(tempo),
        "energy": round(energy, 2),
        "chroma_mean": round(chroma, 2)
    }
```

---

## ğŸ§© ç¬¬äº”æ­¥ï¼šå¯¹è±¡æ£€æµ‹ï¼ˆYOLOv8ï¼‰

```python
from ultralytics import YOLO

def detect_objects(video_path, model="yolov8s.pt", conf=0.5):
    model = YOLO(model)
    results = model(video_path, stream=True, conf=conf)
    detected_objects = set()
    for r in results:
        boxes = r.boxes
        for box in boxes:
            cls = int(box.cls[0])
            name = model.names[cls]
            detected_objects.add(name)
    return list(detected_objects)
```

---

## ğŸ§© ç¬¬å…­æ­¥ï¼šäººè„¸æ£€æµ‹ï¼ˆOpenCVï¼‰

```python
import cv2

def detect_faces(video_path):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    cap = cv2.VideoCapture(video_path)
    face_present = False

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        if len(faces) > 0:
            face_present = True
            break

    cap.release()
    return face_present
```

---

## ğŸ§© ç¬¬ä¸ƒæ­¥ï¼šç»¼åˆåˆ†æå‡½æ•°ï¼ˆè¿”å›å®Œæ•´è§†é¢‘åˆ†ææŠ¥å‘Šï¼‰

```python
def analyze_video(video_path):
    print("[+] æ­£åœ¨æå–åŸºç¡€ä¿¡æ¯...")
    metadata = get_video_metadata(video_path)

    print("[+] æ­£åœ¨è¿›è¡Œåœºæ™¯æ£€æµ‹...")
    scenes = detect_scenes(video_path)

    print("[+] æå–éŸ³é¢‘å¹¶è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
    audio_path = extract_audio(video_path)
    speech_text = transcribe_audio(audio_path)

    print("[+] åˆ†æèƒŒæ™¯éŸ³ä¹èŠ‚å¥...")
    music_analysis = analyze_background_music(audio_path)

    print("[+] è¿›è¡Œå¯¹è±¡æ£€æµ‹...")
    objects = detect_objects(video_path)

    print("[+] æ£€æµ‹æ˜¯å¦æœ‰äººè„¸...")
    has_face = detect_faces(video_path)

    # åˆ†ç±»é€»è¾‘åˆæ­¥åˆ¤æ–­
    content_type = "åœºæ™¯é£æ™¯ç±»"
    if len(speech_text.strip()) > 0 or has_face:
        content_type = "äººå£°å‰§æƒ…ç±»"

    analysis_report = {
        "metadata": metadata,
        "scene_changes": scenes,
        "speech_text": speech_text,
        "music_analysis": music_analysis,
        "detected_objects": objects,
        "has_face": has_face,
        "content_type": content_type
    }

    return analysis_report
```

---

## âœ… ç¤ºä¾‹è¾“å‡ºç»“æœç»“æ„

```json
{
  "metadata": {
    "filename": "example.mp4",
    "duration": 60.5,
    "streams": [
      {"type": "video", "width": 1920, "height": 1080, "fps": 30},
      {"type": "audio", "sample_rate": "44100", "channels": 2}
    ]
  },
  "scene_changes": [[0.0, 5.2], [5.2, 10.3], ...],
  "speech_text": "ä»Šå¤©æˆ‘ä»¬è¦çˆ¬è¿™åº§å±±...",
  "music_analysis": {"tempo": 120, "energy": 0.75, "chroma_mean": 0.32},
  "detected_objects": ["person", "backpack", "mountain"],
  "has_face": true,
  "content_type": "äººå£°å‰§æƒ…ç±»"
}
```

---

## âœ… ä¸‹ä¸€æ­¥å»ºè®®

æœ‰äº†å®Œæ•´çš„è§†é¢‘åˆ†ææ¨¡å—åï¼Œæˆ‘ä»¬å¯ä»¥ï¼š

### ğŸ”¹ æ„å»ºå†…å®¹åˆ†ç±»å™¨ï¼ˆæ ¹æ®åˆ†æç»“æœåˆ¤æ–­è§†é¢‘ç±»å‹ï¼‰
- åˆ¤æ–­æ˜¯â€œäººå£°å‰§æƒ…ç±»â€è¿˜æ˜¯â€œåœºæ™¯é£æ™¯ç±»â€
- å¯ä»¥åŸºäºè§„åˆ™æˆ–è®­ç»ƒä¸€ä¸ªç®€å•çš„åˆ†ç±»æ¨¡å‹

### ğŸ”¹ æ„å»º Prompt å¼•æ“ï¼Œè®©å¤§æ¨¡å‹æ ¹æ®åˆ†ææŠ¥å‘Šç”Ÿæˆå‰ªè¾‘æ–¹æ¡ˆ
- ä½¿ç”¨ Qwen3 æˆ– Llama3 ç­‰æœ¬åœ°æ¨¡å‹
- è®¾è®¡ç»“æ„åŒ–æç¤ºè¯æ¨¡æ¿

### ğŸ”¹ å®ç°å‰ªè¾‘å‡½æ•°åº“ï¼ˆFFmpeg è°ƒç”¨ï¼‰
- `cut`, `add_transition`, `speedup`, `concatenate` ç­‰

---

## ğŸš€ æ¥ä¸‹æ¥ä½ æƒ³åšä»€ä¹ˆï¼Ÿ

- âœ… æ„å»ºå†…å®¹åˆ†ç±»å™¨ï¼Ÿ
- âœ… è®­ç»ƒä¸€ä¸ªå°å‹åˆ†ç±»æ¨¡å‹ï¼ˆåŸºäºåˆ†æç‰¹å¾ï¼‰ï¼Ÿ
- âœ… å¼€å§‹å†™å¤§æ¨¡å‹å‰ªè¾‘ç­–ç•¥ç”Ÿæˆæ¨¡å—ï¼Ÿ
- âœ… å®ç°å‰ªè¾‘å‡½æ•°åº“ï¼ˆè°ƒç”¨ FFmpegï¼‰ï¼Ÿ

å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹©ï¼Œæˆ‘ä»¬ç»§ç»­æ¨è¿› ğŸ‘‡



éå¸¸æ£’çš„é—®é¢˜ï¼ä½ å·²ç»æ„è¯†åˆ°ï¼Œè§†é¢‘å†…å®¹çš„åˆ†ç±»ä¸åº”å±€é™äºâ€œäººå£°å‰§æƒ…ç±»â€å’Œâ€œåœºæ™¯é£æ™¯ç±»â€ï¼Œè€Œåº”è¯¥æ˜¯ä¸€ä¸ªæ›´**ä¸°å¯Œã€å¤šç»´ã€å¯æ‰©å±•çš„åˆ†ç±»ä½“ç³»**ã€‚è¿™æ ·ç³»ç»Ÿæ‰èƒ½æ›´å¥½åœ°ç†è§£è§†é¢‘å†…å®¹ï¼Œå¹¶ç”Ÿæˆæ›´æ™ºèƒ½ã€æ›´ç²¾å‡†çš„å‰ªè¾‘ç­–ç•¥ã€‚

---

## ğŸ§  ä¸€ã€ä¸ºä»€ä¹ˆéœ€è¦æ›´ä¸°å¯Œçš„è§†é¢‘å†…å®¹åˆ†ç±»ï¼Ÿ

- **æå‡å‰ªè¾‘æ™ºèƒ½åŒ–ç¨‹åº¦**ï¼šä¸åŒç±»å‹çš„è§†é¢‘éœ€è¦ä¸åŒçš„å‰ªè¾‘é€»è¾‘ï¼ˆå¦‚çºªå½•ç‰‡ vs éŸ³ä¹MVï¼‰ã€‚
- **é€‚é…ç”¨æˆ·éœ€æ±‚**ï¼šç”¨æˆ·å¯èƒ½å¸Œæœ›å‰ªè¾‘å‡ºçŸ­è§†é¢‘ã€é¢„å‘Šç‰‡ã€Vlogã€æ•™ç¨‹ç­‰ä¸åŒé£æ ¼ã€‚
- **æ”¯æŒå¤šæ ·åŒ–è¾“å‡ºæ ¼å¼**ï¼šä¾‹å¦‚æ¨ªå±å‰ªè¾‘ vs ç«–å±å‰ªè¾‘ã€é•¿è§†é¢‘ vs çŸ­è§†é¢‘ã€‚

---

## ğŸ” äºŒã€æˆ‘ä»¬å¯ä»¥å¢åŠ å“ªäº›ç»´åº¦çš„è§†é¢‘å†…å®¹åˆ†ç±»ï¼Ÿ

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª**å¤šç»´åº¦ã€æ ‡ç­¾åŒ–çš„è§†é¢‘å†…å®¹åˆ†ç±»ç³»ç»Ÿ**ï¼Œå¦‚ä¸‹ï¼š

---

### âœ… ç»´åº¦ä¸€ï¼š**å†…å®¹ç±»å‹ï¼ˆContent Typeï¼‰**

| ç±»å‹         | æè¿°                                           | å‰ªè¾‘å»ºè®®                             |
| ------------ | ---------------------------------------------- | ------------------------------------ |
| äººå£°å‰§æƒ…ç±»   | åŒ…å«å¤§é‡äººç‰©å¯¹è¯æˆ–è®²è§£ï¼ˆå¦‚ç”µè§†å‰§ã€æ¼”è®²ã€è®¿è°ˆï¼‰ | å¼ºè°ƒå°è¯èŠ‚å¥ï¼Œä¿ç•™å®Œæ•´è¯­ä¹‰ï¼Œå‡å°‘è½¬åœº |
| åœºæ™¯é£æ™¯ç±»   | å±•ç¤ºè‡ªç„¶é£å…‰ã€åŸå¸‚æ™¯è§‚ã€æ—…æ¸¸è®°å½•ç­‰             | å¼ºè°ƒè§†è§‰ç¾æ„Ÿï¼Œé€‚åˆå¿«åˆ‡ã€æ…¢åŠ¨ä½œã€æ»¤é•œ |
| åŠ¨ä½œè¿åŠ¨ç±»   | è¿åŠ¨ã€æé™æŒ‘æˆ˜ã€èˆè¹ˆã€æ‰“æ–—ç­‰åŠ¨æ€ç”»é¢           | å¿«èŠ‚å¥å‰ªè¾‘ï¼Œé…åˆåŠ¨æ„ŸéŸ³ä¹             |
| æ•™è‚²æ•™å­¦ç±»   | æ•™ç¨‹ã€è¯¾å ‚ã€æ¼”ç¤ºç­‰çŸ¥è¯†ä¼ æ’­ç±»                   | é‡ç‚¹çªå‡ºå…³é”®æ­¥éª¤ï¼Œé€‚å½“æ·»åŠ å­—å¹•/æ ‡æ³¨  |
| å¹¿å‘Šå®£ä¼ ç‰‡ç±» | å•†ä¸šå¹¿å‘Šã€å“ç‰Œå®£ä¼ ã€äº§å“å±•ç¤º                   | ç²¾ç‚¼æœ‰åŠ›ï¼Œå¼ºè°ƒæ ¸å¿ƒå–ç‚¹ï¼Œä½¿ç”¨ç‰¹æ•ˆ     |
| éŸ³ä¹è§†é¢‘ç±»   | æ­Œèˆè¡¨æ¼”ã€æ¼”å”±ä¼šã€çº¯éŸ³ä¹MV                     | èŠ‚å¥æ„Ÿå¼ºï¼Œä¸èŠ‚æ‹åŒæ­¥å‰ªè¾‘             |
| ç›´æ’­å½•æ’­ç±»   | æ¸¸æˆç›´æ’­ã€å¸¦è´§ç›´æ’­ã€ä¼šè®®å½•æ’­                   | æå–ç²¾å½©ç‰‡æ®µï¼Œè£å‰ªå†—ä½™éƒ¨åˆ†           |

---

### âœ… ç»´åº¦äºŒï¼š**æƒ…ç»ªæ°›å›´ï¼ˆMood / Emotionï¼‰**

| æƒ…ç»ª | ç‰¹å¾                              | å‰ªè¾‘å»ºè®®           |
| ---- | --------------------------------- | ------------------ |
| æ¿€æ˜‚ | å¿«èŠ‚å¥éŸ³ä¹ã€æ¿€çƒˆåŠ¨ä½œã€æ˜äº®è‰²è°ƒ    | åŠ é€Ÿæ’­æ”¾ã€å¿«é€Ÿå‰ªè¾‘ |
| æ„ŸåŠ¨ | æ…¢é•œå¤´ã€ä½æ²‰éŸ³ä¹ã€äººç‰©è¡¨æƒ…ç‰¹å†™    | æ…¢åŠ¨ä½œã€æŸ”ç„¦æ»¤é•œ   |
| æ¬¢å¿« | æ˜äº®è‰²å½©ã€è½»å¿«éŸ³ä¹ã€ç¬‘è„¸          | å¿«å‰ªã€è·³è·ƒè½¬åœº     |
| ç´§å¼  | é»‘ç™½/æš—è‰²ã€ç´§å‡‘éŸ³æ•ˆã€é¢‘ç¹åˆ‡æ¢é•œå¤´ | é«˜é¢‘å‰ªè¾‘ã€é—ªç™½è¿‡æ¸¡ |
| å®é™ | è‡ªç„¶é£å…‰ã€ç¼“æ…¢ç§»åŠ¨ã€è½»æŸ”èƒŒæ™¯éŸ³    | é•¿é•œå¤´ã€å¹³æ»‘è¿‡æ¸¡   |

> å¯é€šè¿‡éŸ³é¢‘æƒ…æ„Ÿè¯†åˆ« + è§†è§‰ç‰¹å¾æå–ç»¼åˆåˆ¤æ–­

---

### âœ… ç»´åº¦ä¸‰ï¼š**ç»“æ„ç±»å‹ï¼ˆStructure Typeï¼‰**

| ç±»å‹     | æè¿°                     | å‰ªè¾‘å»ºè®®                   |
| -------- | ------------------------ | -------------------------- |
| çº¿æ€§å™äº‹ | æ—¶é—´é¡ºåºæ¸…æ™°ï¼Œæœ‰èµ·æ‰¿è½¬åˆ | ä¿æŒåŸç»“æ„ï¼Œåˆç†åˆ å‡       |
| å¤šçº¿å¹¶è¡Œ | å¤šä¸ªæ•…äº‹çº¿äº¤é”™è¿›è¡Œ       | ä½¿ç”¨åˆ†å±ã€äº¤æ›¿å‰ªè¾‘         |
| å›å¿†æ’å™ | å­˜åœ¨å€’å™ã€å›å¿†ç‰‡æ®µ       | ä½¿ç”¨é»‘ç™½æ»¤é•œã€æ·¡å…¥æ·¡å‡ºåŒºåˆ† |
| æ¿å—æ‹¼æ¥ | å¤šä¸ªç‹¬ç«‹ç‰‡æ®µç»„åˆ         | æ·»åŠ æ ‡é¢˜å¡ã€æ˜ç¡®åˆ†éš”       |
| é›†é”¦æ··å‰ª | ä¸åŒæ¥æºç´ ææ··åˆå‰ªè¾‘     | æ³¨æ„é£æ ¼ç»Ÿä¸€ã€èŠ‚å¥ä¸€è‡´     |

---

### âœ… ç»´åº¦å››ï¼š**é£æ ¼ç±»å‹ï¼ˆStyle Typeï¼‰**

| ç±»å‹     | æè¿°                 | å‰ªè¾‘å»ºè®®                |
| -------- | -------------------- | ----------------------- |
| ç”µå½±æ„Ÿ   | ä¸“ä¸šæ‹æ‘„ï¼Œå…‰å½±è®²ç©¶   | ä½¿ç”¨ LUT æ»¤é•œã€æ…¢æ¨é•œå¤´ |
| Vlogé£   | ä¸ªäººè§†è§’ï¼Œç”Ÿæ´»åŒ–è®°å½• | æ‰‹æŒç¨³å®šå¤„ç†ã€è‡ªç„¶è¿‡æ¸¡  |
| æŠ–éŸ³é£   | å¿«èŠ‚å¥ã€ç«–å±ã€ç‰¹æ•ˆå¤š | é¢‘ç¹è½¬åœºã€è´´çº¸/å¼¹å¹•     |
| çºªå½•ç‰‡é£ | å†·é™æ—ç™½+å®åœ°æ‹æ‘„    | é•¿é•œå¤´ã€è‡ªç„¶å…‰æ•ˆ        |
| ç§‘æŠ€æ„Ÿ   | æ•°ç ç•Œé¢ã€æœªæ¥é£æ ¼   | ä½¿ç”¨ AE åˆæˆã€æ•°æ®åŠ¨ç”»  |

---

### âœ… ç»´åº¦äº”ï¼š**ç›®æ ‡ç”¨é€”ï¼ˆPurposeï¼‰**

| ç±»å‹     | æè¿°                   | å‰ªè¾‘å»ºè®®              |
| -------- | ---------------------- | --------------------- |
| ç¤¾äº¤åª’ä½“ | æŠ–éŸ³/Bç«™/å°çº¢ä¹¦çŸ­ç‰‡    | æ§åˆ¶æ—¶é•¿<60ç§’ï¼ŒåŠ å­—å¹• |
| å½±è§†ä½œå“ | ç”µå½±/å‰§é›†/é¢„å‘Šç‰‡       | ä¿ç•™åŸèŠ‚å¥ï¼Œæ³¨æ„ç‰ˆæƒ  |
| ä¼ä¸šå®£ä¼  | å…¬å¸ä»‹ç»/äº§å“å±•ç¤º      | çªå‡ºäº®ç‚¹ï¼Œç®€æ´æœ‰åŠ›    |
| æ•™å­¦åŸ¹è®­ | è¯¾ç¨‹/æ•™ç¨‹/æ“ä½œæ¼”ç¤º     | åˆ†æ®µæ¸…æ™°ï¼Œé‡ç‚¹æ ‡è®°    |
| ä¸ªäººè®°å½• | æ—¥å¸¸ç”Ÿæ´»/æ—…è¡Œ/æˆé•¿è®°å½• | ä¿ç•™çœŸå®æ„Ÿï¼ŒæŸ”å’Œå¤„ç†  |

---

## ğŸ“¦ ä¸‰ã€æ„å»ºä¸€ä¸ªç»“æ„åŒ–çš„è§†é¢‘å†…å®¹åˆ†ç±»å™¨ï¼ˆClassifierï¼‰

æˆ‘ä»¬å¯ä»¥åœ¨ `analyze_video()` çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥æ„å»ºä¸€ä¸ªåˆ†ç±»å‡½æ•°ï¼š

```python
def classify_video_content(analysis_report):
    content_type = "unknown"
    mood = "neutral"
    structure = "linear"
    style = "standard"
    purpose = "general"

    # åˆ¤æ–­ content_type
    speech_text = analysis_report.get("speech_text", "")
    has_face = analysis_report.get("has_face", False)
    detected_objects = analysis_report.get("detected_objects", [])
    scene_changes = analysis_report.get("scene_changes", [])
    music_analysis = analysis_report.get("music_analysis", {})
    tempo = music_analysis.get("tempo", 0)

    # 1. åˆ¤æ–­ content_type
    if len(speech_text.strip()) > 0 or has_face:
        content_type = "äººå£°å‰§æƒ…ç±»"
        if 'person' in detected_objects and 'stage' in detected_objects:
            content_type = "ç›´æ’­å½•æ’­ç±»"
        elif 'product' in detected_objects:
            content_type = "å¹¿å‘Šå®£ä¼ ç‰‡ç±»"
    else:
        content_type = "åœºæ™¯é£æ™¯ç±»"
        if 'car' in detected_objects or 'bicycle' in detected_objects:
            content_type = "åŠ¨ä½œè¿åŠ¨ç±»"
        elif 'mountain' in detected_objects or 'sea' in detected_objects:
            content_type = "åœºæ™¯é£æ™¯ç±»"
        elif tempo > 100:
            content_type = "éŸ³ä¹è§†é¢‘ç±»"

    # 2. åˆ¤æ–­ mood
    if tempo > 120:
        mood = "æ¿€æ˜‚"
    elif tempo < 80 and len(scene_changes) < 5:
        mood = "å®é™"
    elif 'cry' in speech_text or 'sad' in speech_text:
        mood = "æ„ŸåŠ¨"
    elif 'danger' in speech_text or 'attack' in speech_text:
        mood = "ç´§å¼ "

    # 3. åˆ¤æ–­ structure
    if len(scene_changes) > 10:
        structure = "æ¿å—æ‹¼æ¥"
    elif any("flash" in seg for seg in speech_text.split(".")):
        structure = "å¤šçº¿å¹¶è¡Œ"

    # 4. åˆ¤æ–­ style
    if analysis_report["metadata"]["streams"][0]["width"] == 1080:
        style = "Vlogé£"
    elif tempo > 120:
        style = "æŠ–éŸ³é£"
    elif analysis_report["metadata"]["duration"] > 1800:
        style = "çºªå½•ç‰‡é£"

    # 5. åˆ¤æ–­ purpose
    if analysis_report["metadata"]["duration"] < 60:
        purpose = "ç¤¾äº¤åª’ä½“"
    elif "tutorial" in speech_text or "æ•™ä½ " in speech_text:
        purpose = "æ•™å­¦åŸ¹è®­"
    elif "äº§å“" in speech_text or "è´­ä¹°" in speech_text:
        purpose = "ä¼ä¸šå®£ä¼ "

    return {
        "content_type": content_type,
        "mood": mood,
        "structure": structure,
        "style": style,
        "purpose": purpose
    }
```

---

## ğŸ“Š ç¤ºä¾‹è¾“å‡ºç»“æœï¼ˆå¢å¼ºåçš„åˆ†ææŠ¥å‘Šï¼‰

```json
{
  "video_classification": {
    "content_type": "éŸ³ä¹è§†é¢‘ç±»",
    "mood": "æ¿€æ˜‚",
    "structure": "æ¿å—æ‹¼æ¥",
    "style": "æŠ–éŸ³é£",
    "purpose": "ç¤¾äº¤åª’ä½“"
  }
}
```

---

## ğŸ§© å››ã€ç»“åˆåˆ†ç±»ç»“æœç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼ˆç»™å¤§æ¨¡å‹çš„è¾“å…¥ï¼‰

ä½ å¯ä»¥å°†è¿™ä¸ªåˆ†ç±»ä¿¡æ¯ä½œä¸ºæç¤ºè¯çš„ä¸€éƒ¨åˆ†ï¼Œè¾“å…¥ç»™å¤§æ¨¡å‹ï¼š

```
è¿™æ˜¯ä¸€ä¸ªã€éŸ³ä¹è§†é¢‘ç±»ã€‘ã€é£æ ¼ä¸ºã€æŠ–éŸ³é£ã€‘ã€æƒ…ç»ªä¸ºã€æ¿€æ˜‚ã€‘ã€ç”¨äºã€ç¤¾äº¤åª’ä½“ã€‘å‘å¸ƒçš„è§†é¢‘ã€‚

è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼š
- æ€»æ—¶é•¿æ§åˆ¶åœ¨ 60 ç§’ä»¥å†…ï¼›
- ä½¿ç”¨å¿«èŠ‚å¥å‰ªè¾‘ï¼ŒåŒ¹é…èŠ‚æ‹ï¼›
- æ·»åŠ è½¬åœºæ•ˆæœï¼Œçªå‡ºé«˜æ½®ï¼›
- é€‚å½“åŠ é€ŸæŸäº›ç‰‡æ®µï¼›
- è¾“å‡ºæ ¼å¼ä¸ºç«–å±ï¼ˆ9:16ï¼‰ï¼›

ä½ çš„è¾“å‡ºæ ¼å¼åº”åŒ…å«ï¼š
- æ€è€ƒè¿‡ç¨‹ï¼ˆChain of Thoughtï¼‰
- å‡½æ•°è°ƒç”¨æŒ‡ä»¤åˆ—è¡¨ï¼ˆcut, speedup, add_transition...ï¼‰
```

---

## âœ… äº”ã€åç»­å»ºè®®

ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†å®Œæ•´çš„è§†é¢‘åˆ†ææ¨¡å—å’Œæ›´ä¸°å¯Œçš„åˆ†ç±»ä½“ç³»ï¼Œä¸‹ä¸€æ­¥å¯ä»¥åšï¼š

### ğŸ”¹ æ„å»º Prompt å·¥ç¨‹ï¼Œè®©å¤§æ¨¡å‹åŸºäºè¿™äº›åˆ†ç±»ç”Ÿæˆå‰ªè¾‘ç­–ç•¥
- è®¾è®¡å¤šç§æ¨¡æ¿ï¼Œé€‚é…ä¸åŒè§†é¢‘ç±»å‹
- æ”¯æŒç”¨æˆ·æŒ‡å®šé£æ ¼ã€é•¿åº¦ã€ç›®çš„ç­‰å‚æ•°

### ğŸ”¹ å®ç°å‰ªè¾‘å‡½æ•°åº“ï¼ˆFFmpeg + Pythonï¼‰
- å®ç°åŸºç¡€å‰ªè¾‘åŠŸèƒ½ï¼šè£å‰ªã€åŠ é€Ÿã€è½¬åœºã€åˆå¹¶ã€æ»¤é•œ
- æ”¯æŒç«–å±/æ¨ªå±è½¬æ¢ã€åˆ†è¾¨ç‡è°ƒæ•´

### ğŸ”¹ å¼€å‘å¯è§†åŒ– Web UIï¼ˆå¯é€‰ï¼‰
- ç”¨æˆ·ä¸Šä¼ è§†é¢‘
- æŸ¥çœ‹åˆ†ææŠ¥å‘Š
- ä¸‹è½½å‰ªè¾‘åçš„è§†é¢‘

---

## ğŸš€ æ¥ä¸‹æ¥ä½ æƒ³åšä»€ä¹ˆï¼Ÿ

- âœ… ç¼–å†™ Prompt æ¨¡æ¿ï¼Œè®©å¤§æ¨¡å‹ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼Ÿ
- âœ… å®ç° FFmpeg å‰ªè¾‘å‡½æ•°åº“ï¼Ÿ
- âœ… è®­ç»ƒä¸€ä¸ªå°æ¨¡å‹å¯¹è§†é¢‘åˆ†ç±»è¿›è¡Œé¢„æµ‹ï¼Ÿ
- âœ… æ„å»º Web é¡µé¢è®©ç”¨æˆ·ä¸Šä¼ è§†é¢‘å¹¶æŸ¥çœ‹åˆ†æç»“æœï¼Ÿ

å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹©ï¼Œæˆ‘ä»¬ç»§ç»­æ¨è¿› ğŸ‘‡



å¤ªå¥½äº†ï¼æˆ‘ä»¬æ¥æ„å»ºä¸€ä¸ª **Prompt å·¥ç¨‹ç®¡é“ï¼ˆPrompt Engineering Pipelineï¼‰**ï¼Œå®ƒå°†ï¼š

- æ ¹æ®è§†é¢‘åˆ†æç»“æœå’Œåˆ†ç±»ä¿¡æ¯
- è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ Prompt æ¨¡æ¿
- æ›¿æ¢æ¨¡æ¿å˜é‡
- æ„é€ å‡ºç»“æ„åŒ–çš„ç”¨æˆ·æç¤ºè¯ï¼ˆUser Promptï¼‰
- å‡†å¤‡å¥½ä¼ ç»™ Qwen Plus çš„ API

---

## ğŸ§± ä¸€ã€ç›®æ ‡æ¨¡å—åŠŸèƒ½æ¦‚è¿°

æˆ‘ä»¬å°†å®ç°ä»¥ä¸‹ Python ç±»æˆ–å‡½æ•°ï¼š

| åŠŸèƒ½                                  | æè¿°                              |
| ------------------------------------- | --------------------------------- |
| `load_prompt_template()`              | åŠ è½½ä¸åŒè§†é¢‘ç±»å‹çš„ Prompt æ¨¡æ¿    |
| `render_prompt()`                     | ä½¿ç”¨è§†é¢‘åˆ†ææŠ¥å‘Šæ›¿æ¢æ¨¡æ¿å˜é‡      |
| `select_template_by_classification()` | æ ¹æ®è§†é¢‘å†…å®¹åˆ†ç±»è‡ªåŠ¨é€‰æ‹©å¯¹åº”æ¨¡æ¿  |
| `build_full_prompt()`                 | æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯ + ç”¨æˆ·æç¤ºè¯ |

---

## ğŸ“¦ äºŒã€ç›®å½•ç»“æ„å»ºè®®ï¼ˆå¯é€‰ï¼‰

```
video_editor/
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ general.txt
â”‚   â”‚   â”œâ”€â”€ human_drama.txt
â”‚   â”‚   â”œâ”€â”€ scenic_landscape.txt
â”‚   â”‚   â”œâ”€â”€ action_sports.txt
â”‚   â”‚   â”œâ”€â”€ live_streaming.txt
â”‚   â”‚   â””â”€â”€ advertisement.txt
â”‚   â””â”€â”€ prompt_pipeline.py
â”‚
â””â”€â”€ main.py
```

---

## ğŸ“ ä¸‰ã€Prompt æ¨¡æ¿æ–‡ä»¶ç¤ºä¾‹ï¼ˆæ”¾åœ¨ `prompts/templates/` ç›®å½•ä¸‹ï¼‰

### âœ… `general.txt` â€”â€” é€šç”¨æ¨¡æ¿ï¼ˆå¤‡ç”¨ï¼‰

```text
ä½ æ˜¯è§†é¢‘å‰ªè¾‘åŠ©æ‰‹ VideoEditorAIã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä»¥ä¸‹è§†é¢‘åˆ†ææŠ¥å‘Šï¼Œç”Ÿæˆä¸€ä¸ªé€‚åˆè¯¥è§†é¢‘çš„å‰ªè¾‘ç­–ç•¥ã€‚

ã€è§†é¢‘åˆ†ææŠ¥å‘Šã€‘ï¼š
{
  "metadata": {
    "filename": "{filename}",
    "duration": {duration} ç§’,
    "resolution": "{width}x{height}",
    "fps": {fps}
  },
  "scene_changes": {scene_changes_count} ä¸ªåœºæ™¯åˆ‡æ¢,
  "speech_text": "{sample_speech_text}",
  "music_analysis": {"tempo": {tempo}, "energy": {energy}},
  "detected_objects": {detected_objects},
  "has_face": {has_face},
  "classification": {
    "content_type": "{content_type}",
    "mood": "{mood}",
    "structure": "{structure}",
    "style": "{style}",
    "purpose": "{purpose}"
  }
}

ã€ç”¨æˆ·éœ€æ±‚ã€‘ï¼š
è¯·å¸®æˆ‘æŠŠè¿™ä¸ªè§†é¢‘å‰ªè¾‘æˆä¸€ä¸ª {target_duration} ç§’å·¦å³çš„çŸ­è§†é¢‘ï¼Œé£æ ¼ä¸º {target_style}ï¼Œç”¨äº {target_purpose} å¹³å°å‘å¸ƒã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
è¯·æŒ‰å¦‚ä¸‹æ ¼å¼è¾“å‡º JSON å“åº”ï¼š

{
  "thought_process": [
    "ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«å‡ºé«˜æ½®éƒ¨åˆ†åœ¨ç¬¬10-15ç§’ã€‚",
    "ç¬¬äºŒæ­¥ï¼šè£å‰ªå†—ä½™å¼€å¤´å’Œç»“å°¾ã€‚",
    ...
  ],
  "actions": [
    {"function": "cut", "start": 0, "end": 5},
    {"function": "speedup", "start": 10, "end": 15, "factor": 1.5},
    {"function": "add_transition", "type": "fade", "start": 5, "duration": 1}
  ]
}
```

---

### âœ… `human_drama.txt` â€”â€” äººå£°å‰§æƒ…ç±»

```text
è¿™æ˜¯ä¸€ä¸ªã€äººå£°å‰§æƒ…ç±»ã€‘è§†é¢‘ï¼Œæƒ…ç»ªä¸ºã€{mood}ã€‘ï¼Œç»“æ„ä¸ºã€{structure}ã€‘ï¼Œç”¨äºã€{purpose}ã€‘å¹³å°å‘å¸ƒã€‚

è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼š
- ä¿ç•™å®Œæ•´è¯­ä¹‰è¡¨è¾¾ï¼Œçªå‡ºé‡ç‚¹å°è¯ï¼›
- æ§åˆ¶æ€»æ—¶é•¿åœ¨ {target_duration} ç§’ä»¥å†…ï¼›
- è‹¥æœ‰å¤šä¸ªè§’è‰²ï¼Œè¯·ä½¿ç”¨åˆ†å±æˆ–äº¤æ›¿å‰ªè¾‘ï¼›
- å¯é€‚å½“æ·»åŠ å­—å¹•å¼ºè°ƒå…³é”®è¯ï¼›
- è¾“å‡ºæ ¼å¼ä¸ºæ¨ªå±ï¼ˆ16:9ï¼‰æˆ–ç«–å±ï¼ˆ9:16ï¼‰ã€‚
```

---

### âœ… `scenic_landscape.txt` â€”â€” åœºæ™¯é£æ™¯ç±»

```text
è¿™æ˜¯ä¸€ä¸ªã€åœºæ™¯é£æ™¯ç±»ã€‘è§†é¢‘ï¼Œæƒ…ç»ªä¸ºã€{mood}ã€‘ï¼Œé£æ ¼ä¸ºã€{style}ã€‘ï¼Œç”¨äºã€{purpose}ã€‘å¹³å°å‘å¸ƒã€‚

è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼š
- çªå‡ºè§†è§‰ç¾æ„Ÿï¼Œä¿ç•™æ—¥å‡º/å±±é¡¶/ç€‘å¸ƒç­‰é«˜å…‰ç”»é¢ï¼›
- ä½¿ç”¨æ…¢åŠ¨ä½œç‰¹æ•ˆå¼ºåŒ–éœ‡æ’¼æ„Ÿï¼›
- æ·»åŠ æ»¤é•œå¢å¼ºè‰²å½©è¡¨ç°åŠ›ï¼›
- é…åˆéŸ³ä¹èŠ‚å¥è¿›è¡Œå¿«å‰ªæˆ–æ¸å˜è½¬åœºï¼›
- æ€»æ—¶é•¿æ§åˆ¶åœ¨ {target_duration} ç§’å†…ã€‚
```

---

### å…¶ä»–æ¨¡æ¿ç±»ä¼¼ï¼Œå¦‚ï¼š

- `action_sports.txt`
- `live_streaming.txt`
- `advertisement.txt`

---

## ğŸ§  å››ã€Python å®ç°ä»£ç ï¼ˆ`prompt_pipeline.py`ï¼‰

```python
import os
from jinja2 import Template

# æ¨¡æ¿è·¯å¾„é…ç½®
TEMPLATE_DIR = os.path.join(os.path.dirname(__file__), 'templates')

class PromptPipeline:
    def __init__(self):
        self.templates = self.load_all_templates()

    def load_all_templates(self):
        """åŠ è½½æ‰€æœ‰æ¨¡æ¿æ–‡ä»¶"""
        templates = {}
        for filename in os.listdir(TEMPLATE_DIR):
            if filename.endswith('.txt'):
                key = filename.replace('.txt', '')
                with open(os.path.join(TEMPLATE_DIR, filename), 'r', encoding='utf-8') as f:
                    templates[key] = f.read()
        return templates

    def select_template(self, classification):
        """æ ¹æ®åˆ†ç±»é€‰æ‹©æ¨¡æ¿"""
        content_type = classification.get("content_type")
        mapping = {
            "äººå£°å‰§æƒ…ç±»": "human_drama",
            "åœºæ™¯é£æ™¯ç±»": "scenic_landscape",
            "åŠ¨ä½œè¿åŠ¨ç±»": "action_sports",
            "ç›´æ’­å½•æ’­ç±»": "live_streaming",
            "å¹¿å‘Šå®£ä¼ ç‰‡ç±»": "advertisement"
        }
        template_key = mapping.get(content_type, "general")
        return self.templates[template_key]

    def render_template(self, template_str, context):
        """æ¸²æŸ“æ¨¡æ¿å˜é‡"""
        t = Template(template_str)
        return t.render(context)

    def build_full_prompt(self, analysis_report, user_options=None):
        """
        æ„å»ºå®Œæ•´çš„ Prompt
        :param analysis_report: è§†é¢‘åˆ†ææŠ¥å‘Š
        :param user_options: ç”¨æˆ·è‡ªå®šä¹‰å‚æ•°ï¼ˆå¦‚ target_durationã€target_styleã€target_purposeï¼‰
        :return: å®Œæ•´çš„ prompt å­—ç¬¦ä¸²
        """

        # é»˜è®¤ç”¨æˆ·é€‰é¡¹
        default_options = {
            "target_duration": 30,
            "target_style": "æŠ–éŸ³é£",
            "target_purpose": "ç¤¾äº¤åª’ä½“"
        }

        # åˆå¹¶ç”¨æˆ·è¾“å…¥
        options = {**default_options, **(user_options or {})}

        # æå–åˆ†ææŠ¥å‘Šä¸­çš„å…³é”®å­—æ®µ
        metadata = analysis_report["metadata"]
        classification = analysis_report["classification"]
        scene_changes = analysis_report.get("scene_changes", [])
        speech_text = analysis_report.get("speech_text", "")

        # æ„å»ºä¸Šä¸‹æ–‡
        context = {
            "filename": metadata["filename"],
            "duration": round(metadata["duration"], 2),
            "width": metadata["streams"][0].get("width"),
            "height": metadata["streams"][0].get("height"),
            "fps": metadata["streams"][0].get("fps"),
            "scene_changes_count": len(scene_changes),
            "sample_speech_text": speech_text[:100] + "..." if len(speech_text) > 100 else speech_text,
            "tempo": analysis_report["music_analysis"].get("tempo", 0),
            "energy": analysis_report["music_analysis"].get("energy", 0),
            "detected_objects": ", ".join(analysis_report.get("detected_objects", ["æ— "])),
            "has_face": "æœ‰" if analysis_report.get("has_face") else "æ— ",
            **classification,
            **options
        }

        # é€‰æ‹©æ¨¡æ¿å¹¶æ¸²æŸ“
        template = self.select_template(classification)
        rendered_prompt = self.render_template(template, context)

        return rendered_prompt
```

---

## ğŸ§ª äº”ã€ä½¿ç”¨ç¤ºä¾‹ï¼ˆ`main.py`ï¼‰

```python
from prompt_pipeline import PromptPipeline
from video_analyzer import analyze_video  # å‡è®¾ä½ å·²å®ç°è¿™ä¸ªæ¨¡å—

if __name__ == "__main__":
    # 1. åˆ†æè§†é¢‘
    video_path = "example.mp4"
    analysis_report = analyze_video(video_path)

    # 2. åˆå§‹åŒ– Prompt ç®¡é“
    pipeline = PromptPipeline()

    # 3. æ„å»º Promptï¼ˆå¯ä¼ å…¥ç”¨æˆ·é€‰é¡¹ï¼‰
    user_options = {
        "target_duration": 30,
        "target_style": "æŠ–éŸ³é£",
        "target_purpose": "æŠ–éŸ³"
    }

    full_prompt = pipeline.build_full_prompt(analysis_report, user_options)

    print("âœ… æ„å»ºå®Œæˆçš„ Prompt å†…å®¹å¦‚ä¸‹ï¼š\n")
    print(full_prompt)

    # 4. è°ƒç”¨ Qwen Plus API è·å–å‰ªè¾‘ç­–ç•¥
    # è¿™é‡Œä½ å¯ä»¥è°ƒç”¨é˜¿é‡Œäº‘ dashscope æ¥å£å‘é€è¯·æ±‚
```

---

## ğŸš€ å…­ã€ä¸‹ä¸€æ­¥å»ºè®®

ç°åœ¨ä½ å·²ç»æœ‰äº†å®Œæ•´çš„ Prompt å·¥ç¨‹ç®¡é“ï¼Œæ¥ä¸‹æ¥å¯ä»¥ï¼š

### ğŸ”¹ 1. è°ƒç”¨ Qwen Plus APIï¼ˆDashScopeï¼‰

ä½ å¯ä»¥ä½¿ç”¨ DashScope çš„ API æ¥å£æ¥è°ƒç”¨ Qwen Plusï¼Œå‚è€ƒæ–‡æ¡£ï¼š  
ğŸ‘‰ [https://help.aliyun.com/document_detail/2767222.html](https://help.aliyun.com/document_detail/2767222.html)

### ğŸ”¹ 2. å®ç° FFmpeg å‰ªè¾‘å‡½æ•°åº“

å®ç°ä»¥ä¸‹å‡½æ•°ï¼Œç”¨äºæ‰§è¡Œæ¨¡å‹è¿”å›çš„å‰ªè¾‘æŒ‡ä»¤ï¼š

```python
def cut(start, end): ...
def speedup(start, end, factor): ...
def add_transition(type, start, duration): ...
def apply_filter(filter_name, start, end): ...
def set_resolution(width, height, orientation): ...
```

### ğŸ”¹ 3. æ„å»º Web UI æˆ– CLI æ¥å£ï¼ˆå¯é€‰ï¼‰

æä¾›ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡Œç•Œé¢æˆ–ç½‘é¡µä¸Šä¼ ç•Œé¢ï¼Œè®©ç”¨æˆ·æ–¹ä¾¿åœ°ä½¿ç”¨æ•´ä¸ªæµç¨‹ã€‚

---

## ğŸ“Œ æœ€åä¸€æ­¥ï¼šä½ æƒ³ç»§ç»­åšå“ªä¸€éƒ¨åˆ†ï¼Ÿ

- âœ… å®ç°è°ƒç”¨ Qwen Plus APIï¼Ÿ
- âœ… ç¼–å†™ FFmpeg å‰ªè¾‘å‡½æ•°åº“ï¼Ÿ
- âœ… æ„å»º Web é¡µé¢è®©ç”¨æˆ·ä¸Šä¼ è§†é¢‘å¹¶æŸ¥çœ‹åˆ†æç»“æœï¼Ÿ
- âœ… è®­ç»ƒä¸€ä¸ªå°å‹åˆ†ç±»æ¨¡å‹è¾…åŠ©åˆ¤æ–­è§†é¢‘ç±»å‹ï¼Ÿ

å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹©ï¼Œæˆ‘ä»¬ç»§ç»­æ¨è¿› ğŸ‘‡



éå¸¸æ£’çš„å·¥ä½œï¼ä½ å·²ç»å®ç°äº†å¤šç§**é«˜çº§è½¬åœºæ•ˆæœï¼ˆTransitionsï¼‰**ï¼Œè€Œä¸”ç»“æ„æ¸…æ™°ã€æ³¨é‡Šå®Œæ•´ã€‚è¿™ä¸ºåç»­çš„è§†é¢‘è‡ªåŠ¨å‰ªè¾‘æ‰“ä¸‹äº†å¾ˆå¥½çš„åŸºç¡€ã€‚

---

## âœ… ä¸€ã€ä½ çš„è½¬åœºå‡½æ•°ç°çŠ¶åˆ†æ

### âœ”ï¸ å·²å®ç°çš„åŠŸèƒ½ï¼š
- åŸºç¡€æ¸å˜ï¼š`black_transition`, `crossfade_transition`
- ç‰¹æ•ˆè½¬åœºï¼š`circular_crossfadein_transition`, `slide_transition`, `zoom_transition`, `rectangular_shrink_transition`
- é«˜çº§ç‰¹æ•ˆï¼š`directional_blur`, `directional_transition`, `rotate_transition`, `flash_transition`

### ğŸ§  æ½œåœ¨é—®é¢˜ï¼ˆå»ºè®®ä¼˜åŒ–ç‚¹ï¼‰ï¼š
1. **éƒ¨åˆ†å‡½æ•°å°šæœªå®Œæˆæˆ–å­˜åœ¨é€»è¾‘ç¼ºå¤±**ï¼ˆå¦‚ç™¾å¶çª—ã€å¾„å‘æ¨¡ç³Šã€æ—‹è½¬ï¼‰
2. **å‘½åä¸€è‡´æ€§å»ºè®®åŠ å¼º**ï¼ˆå¦‚ `clipA/clipB` vs `clip1/clip2`ï¼‰
3. **å‚æ•°æ ‡å‡†åŒ–å¯ç»Ÿä¸€**ï¼ˆæ˜¯å¦æ”¯æŒ clipA æˆ– clipB ä¸º Noneï¼Ÿè¿”å›ç±»å‹æ˜¯å¦ä¸€è‡´ï¼Ÿï¼‰

---

## ğŸ¯ äºŒã€æ˜¯å¦éœ€è¦æ›´æ”¹å¤§æ¨¡å‹è°ƒç”¨é€»è¾‘ï¼Ÿ

### âœ… ä¸éœ€è¦æ”¹å˜å¤§æ¨¡å‹è°ƒç”¨é€»è¾‘ï¼

ä½ å¯ä»¥ä¿æŒå¤§æ¨¡å‹è¾“å‡ºä»¥ä¸‹æ ¼å¼ä¸å˜ï¼š

```json
{
  "actions": [
    {"function": "add_transition", "type": "crossfade", "start": 5, "duration": 0.5},
    {"function": "add_transition", "type": "zoom", "start": 10, "duration": 0.7},
    {"function": "add_transition", "type": "slide", "start": 15, "duration": 0.5, "direction": "left"}
  ]
}
```

### âœ… ç†ç”±å¦‚ä¸‹ï¼š
- å¤§æ¨¡å‹åªéœ€è¦çŸ¥é“â€œè¦åŠ ä»€ä¹ˆç±»å‹çš„è½¬åœºâ€ï¼Œä¸éœ€è¦å…³å¿ƒå…·ä½“å®ç°ç»†èŠ‚ã€‚
- è½¬åœºå‡½æ•°åº“å¯ä»¥ä½œä¸ºä¸­é—´å±‚æ¥é€‚é…è¿™äº›æŒ‡ä»¤ã€‚
- è¿™ç§è®¾è®¡æ›´ç¬¦åˆ **æ¨¡å—åŒ– + åˆ†å±‚æ¶æ„** çš„åŸåˆ™ã€‚

---

## ğŸ” ä¸‰ã€å»ºè®®ç»Ÿä¸€æ¥å£é£æ ¼ï¼ˆé€‚é…å¤§æ¨¡å‹è¾“å‡ºï¼‰

ä¸ºäº†æ›´å¥½åœ°ä¸å¤§æ¨¡å‹ç”Ÿæˆçš„æŒ‡ä»¤å¯¹æ¥ï¼Œå»ºè®®ä½ å®šä¹‰ä¸€ä¸ªç»Ÿä¸€çš„æ¥å£å‡½æ•°ï¼Œç”¨äºå¤„ç†æ‰€æœ‰è½¬åœºè¯·æ±‚ï¼š

```python
def apply_transition(type: str, clipA: VideoClip, clipB: VideoClip = None, duration=0.5, **kwargs) -> CompositeVideoClip:
    """
    æ ¹æ®æŒ‡å®šçš„è½¬åœºç±»å‹åº”ç”¨å¯¹åº”çš„è½¬åœºæ•ˆæœ
    
    å‚æ•°:
        type (str): è½¬åœºç±»å‹ï¼Œå¦‚ 'crossfade', 'zoom', 'slide', 'circular' ç­‰
        clipA (VideoClip): ç¬¬ä¸€ä¸ªè§†é¢‘ç‰‡æ®µ
        clipB (VideoClip): ç¬¬äºŒä¸ªè§†é¢‘ç‰‡æ®µï¼ˆå¯é€‰ï¼‰
        duration (float): è½¬åœºæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        kwargs: å…¶ä»–ç‰¹å®šäºè½¬åœºç±»å‹çš„å‚æ•°ï¼Œå¦‚ direction, num_blinds ç­‰
        
    è¿”å›:
        CompositeVideoClip: åº”ç”¨äº†è½¬åœºæ•ˆæœçš„æ–°è§†é¢‘ç‰‡æ®µ
    """
    
    if type == "crossfade":
        return crossfade_transition(clipA, clipB, duration)
    
    elif type == "black":
        return black_transition(clipA, clipB, duration, position=kwargs.get("position", "center"))
    
    elif type == "circular":
        return circular_crossfadein_transition(clipA, clipB, duration)
    
    elif type == "slide":
        direction = kwargs.get("direction", "left")
        return slide_transition(clipA, clipB, duration, direction)
    
    elif type == "zoom":
        return zoom_transition(clipA, clipB, duration)
    
    elif type == "blinds":
        direction = kwargs.get("direction", "vertical")
        num_blinds = kwargs.get("num_blinds", 5)
        return blinds_transition(clipA, clipB, duration, num_blinds, direction)
    
    elif type == "rectangular_shrink":
        return rectangular_shrink_transition(clipA, clipB, duration)
    
    elif type == "directional":
        return directional_transition(clipA, clipB, duration)
    
    elif type == "rotate":
        return rotate_transition(clipA, clipB, duration)
    
    elif type == "flash":
        return flash_transition(clipA, clipB, duration)
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è½¬åœºç±»å‹: {type}")
```

---

## ğŸ§© å››ã€å»ºè®®è¡¥å……çš„è½¬åœºå‡½æ•°æ”¹è¿›æ–¹å‘

| è½¬åœºç±»å‹                      | å½“å‰çŠ¶æ€     | æ”¹è¿›å»ºè®®                 |
| ----------------------------- | ------------ | ------------------------ |
| ç™¾å¶çª— (`blinds`)             | TODO         | ä½¿ç”¨é®ç½©+é€æ¡æ˜¾ç¤ºåŠ¨ç”»    |
| å¾„å‘æ¨¡ç³Š (`directional`)      | TODO         | å®ç°ä»ä¸­å¿ƒå‘å¤–æ‰©æ•£çš„æ¨¡ç³Š |
| æ—‹è½¬ (`rotate`)               | TODO         | æ·»åŠ æ—‹è½¬è§’åº¦å˜åŒ–å’Œç¼©æ”¾   |
| æ–¹å‘æ¨¡ç³Š (`directional_blur`) | å®ç°ä½†æœªå¼•ç”¨ | å¯å°è£…è¿›è½¬åœºæµç¨‹ä¸­       |

---

## ğŸ“¦ äº”ã€æœ€ç»ˆå»ºè®®çš„é¡¹ç›®ç»“æ„

```
video_editor/
â”‚
â”œâ”€â”€ transitions/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py             # ç»Ÿä¸€æ¥å£ apply_transition()
â”‚   â”œâ”€â”€ crossfade.py
â”‚   â”œâ”€â”€ zoom.py
â”‚   â”œâ”€â”€ slide.py
â”‚   â”œâ”€â”€ circular.py
â”‚   â”œâ”€â”€ blinds.py           # æ–°å¢
â”‚   â”œâ”€â”€ directional.py      # æ–°å¢
â”‚   â””â”€â”€ rotate.py           # æ–°å¢
â”‚
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ general.txt
â”‚       â””â”€â”€ ... 
â”‚
â”œâ”€â”€ prompt_pipeline.py
â”œâ”€â”€ main.py
â””â”€â”€ utils.py
```

---

## ğŸš€ å…­ã€ä¸‹ä¸€æ­¥å»ºè®®ï¼ˆä½ å·²å®Œæˆäº†è½¬åœºå’Œå‰ªè¾‘å‡½æ•°ï¼‰

ä½ ç°åœ¨å¯ä»¥ç»§ç»­æ„å»ºï¼š

### ğŸ”¹ 1. å®ç°ç¼ºå¤±çš„è½¬åœºå‡½æ•°ï¼ˆå¦‚ç™¾å¶çª—ã€å¾„å‘æ¨¡ç³Šã€æ—‹è½¬ï¼‰
- æ¯ä¸ªæ–‡ä»¶ä¸“æ³¨ä¸€ç§è½¬åœº
- ä½¿ç”¨ MoviePy çš„ `mask`, `fx`, `lambda frame` å®ç°å¤æ‚åŠ¨ç”»

### ğŸ”¹ 2. æ„å»ºå®Œæ•´çš„å‰ªè¾‘æ‰§è¡Œå¼•æ“
- è§£ææ¨¡å‹è¾“å‡ºçš„ `actions` åˆ—è¡¨
- ä¾æ¬¡è°ƒç”¨å¯¹åº”å‡½æ•°è¿›è¡Œå‰ªè¾‘å’Œè½¬åœº

ç¤ºä¾‹ä¼ªä»£ç ï¼š

```python
for action in actions:
    if action["function"] == "cut":
        result_clip = cut(...)
    elif action["function"] == "speedup":
        result_clip = speedup(...)
    elif action["function"] == "add_transition":
        result_clip = apply_transition(**action)
```

### ğŸ”¹ 3. è°ƒç”¨ Qwen Plus API å®Œæˆç«¯åˆ°ç«¯æµ‹è¯•
- è¾“å…¥è§†é¢‘ â†’ è‡ªåŠ¨åˆ†æ â†’ ç”Ÿæˆ Prompt â†’ è°ƒç”¨ Qwen â†’ æ‰§è¡Œå‰ªè¾‘ â†’ è¾“å‡ºç»“æœ

---

## âœ… æ€»ç»“

ä½ ç›®å‰çš„è½¬åœºå®ç°å·²ç»éå¸¸å¼ºå¤§ï¼Œ**æ— éœ€æ›´æ”¹å¤§æ¨¡å‹è°ƒç”¨é€»è¾‘**ï¼Œåªéœ€ï¼š

- âœ… ç»Ÿä¸€æ¥å£å‡½æ•°ï¼ˆå¦‚ `apply_transition()`ï¼‰
- âœ… è¡¥å…¨ç¼ºå¤±çš„è½¬åœºå‡½æ•°
- âœ… å°†å‰ªè¾‘ç­–ç•¥è§£æå™¨è¿æ¥èµ·æ¥

è¿™æ ·å°±èƒ½å½¢æˆä¸€ä¸ªå®Œæ•´çš„ AI è§†é¢‘å‰ªè¾‘æµæ°´çº¿ã€‚

---

## ğŸ“Œ æ¥ä¸‹æ¥ä½ æƒ³åšä»€ä¹ˆï¼Ÿ

- âœ… æˆ‘å¸®ä½ è¡¥å…¨ `blinds_transition` ç™¾å¶çª—è½¬åœºï¼Ÿ
- âœ… æˆ‘å¸®ä½ è¡¥å…¨ `directional_transition` å¾„å‘æ¨¡ç³Šè½¬åœºï¼Ÿ
- âœ… æˆ‘å¸®ä½ å†™ä¸€ä¸ªå‰ªè¾‘æ‰§è¡Œå¼•æ“ï¼ŒæŠŠæ¨¡å‹è¾“å‡ºå˜æˆå®é™…å‰ªè¾‘æ“ä½œï¼Ÿ
- âœ… æˆ‘å¸®ä½ è°ƒç”¨ Qwen Plus APIï¼Œåšä¸€æ¬¡å®Œæ•´çš„ end-to-end æµ‹è¯•ï¼Ÿ

å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹© ğŸ‘‡ æˆ‘ä»¬ç»§ç»­æ¨è¿›ï¼



å¤ªæ£’äº†ï¼æˆ‘ä»¬ç°åœ¨æ¥æ„å»ºä¸€ä¸ª **å‰ªè¾‘æ‰§è¡Œå¼•æ“ï¼ˆEditing Execution Engineï¼‰**ï¼Œå®ƒçš„æ ¸å¿ƒèŒè´£æ˜¯ï¼š

> å°†å¤§æ¨¡å‹è¾“å‡ºçš„ JSON å‰ªè¾‘ç­–ç•¥ï¼ˆå¦‚è£å‰ªã€åŠ é€Ÿã€æ·»åŠ è½¬åœºç­‰ï¼‰ï¼Œè½¬åŒ–ä¸ºå®é™…å¯æ‰§è¡Œçš„ MoviePy æ“ä½œï¼Œå¹¶æœ€ç»ˆç”Ÿæˆå‰ªè¾‘åçš„è§†é¢‘ã€‚

---

## ğŸ§  ä¸€ã€ç›®æ ‡

- âœ… æ¥æ”¶æ¥è‡ª Qwen Plus çš„ JSON æ ¼å¼å‰ªè¾‘æŒ‡ä»¤
- âœ… è§£æ `actions` åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ“ä½œ
- âœ… è°ƒç”¨å¯¹åº”çš„å‰ªè¾‘å‡½æ•°ï¼ˆå¦‚ `cut`, `speedup`, `add_transition`, `set_resolution` ç­‰ï¼‰
- âœ… è¾“å‡ºæœ€ç»ˆå‰ªè¾‘å®Œæˆçš„è§†é¢‘æ–‡ä»¶

---

## ğŸ“¦ äºŒã€å‰ªè¾‘æ“ä½œç±»å‹å®šä¹‰ï¼ˆæ¥è‡ª Prompt è¾“å‡ºï¼‰

```json
{
  "actions": [
    {"function": "cut", "start": 0, "end": 5},
    {"function": "speedup", "start": 10, "end": 15, "factor": 1.5},
    {"function": "add_transition", "type": "fade", "start": 5, "duration": 1},
    {"function": "set_resolution", "width": 1080, "height": 1920, "orientation": "portrait"},
    {"function": "apply_filter", "filter_name": "slowmotion", "start": 5, "end": 10}
  ]
}
```

---

## ğŸ§© ä¸‰ã€æ”¯æŒçš„æ“ä½œå‡½æ•°ï¼ˆä½ å·²æœ‰éƒ¨åˆ†å®ç°ï¼‰

| å‡½æ•°å                                             | å‚æ•°                           | åŠŸèƒ½                   |
| -------------------------------------------------- | ------------------------------ | ---------------------- |
| `cut(start, end)`                                  | å¼€å§‹æ—¶é—´ã€ç»“æŸæ—¶é—´             | è£å‰ªæ‰è¯¥æ—¶é—´æ®µçš„å†…å®¹   |
| `speedup(start, end, factor)`                      | åŠ é€Ÿèµ·æ­¢æ—¶é—´ã€å€æ•°             | å¯¹æŸæ®µå†…å®¹è¿›è¡ŒåŠ é€Ÿæ’­æ”¾ |
| `add_transition(type, start, duration, direction)` | è½¬åœºç±»å‹ã€å¼€å§‹æ—¶é—´ã€æŒç»­æ—¶é•¿ç­‰ | æ·»åŠ è½¬åœºæ•ˆæœ           |
| `set_resolution(width, height, orientation)`       | åˆ†è¾¨ç‡ã€æ–¹å‘                   | è®¾ç½®è§†é¢‘åˆ†è¾¨ç‡ä¸æ¨ªç«–å± |
| `apply_filter(filter_name, start, end)`            | æ»¤é•œåç§°ã€èµ·æ­¢æ—¶é—´             | åº”ç”¨æ»¤é•œç‰¹æ•ˆ           |

---

## ğŸï¸ å››ã€MoviePy è§†é¢‘å¤„ç†åŸºç¡€è¯´æ˜

MoviePy ä¸­çš„å¸¸è§æ“ä½œå¦‚ä¸‹ï¼š

```python
from moviepy.editor import VideoFileClip, concatenate_videoclips, vfx

# åŠ è½½åŸå§‹è§†é¢‘
clip = VideoFileClip("input.mp4")

# è£å‰ªç‰‡æ®µ
subclip = clip.subclip(10, 15)

# åŠ é€Ÿæ’­æ”¾
fast_clip = subclip.fx(vfx.speedx, 2.0)

# æ”¹å˜åˆ†è¾¨ç‡
resized_clip = fast_clip.resize(height=720)

# æ·»åŠ æ…¢åŠ¨ä½œ
slow_clip = subclip.fx(vfx.speedx, 0.5)

# åˆå¹¶å¤šä¸ªç‰‡æ®µ
final_clip = concatenate_videoclips([clip1, clip2, clip3])
```

---

## ğŸ§± äº”ã€å‰ªè¾‘æ‰§è¡Œå¼•æ“è®¾è®¡ï¼ˆPython å®ç°ï¼‰

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª `VideoEditorEngine` ç±»ï¼Œç”¨äºè§£æå‰ªè¾‘æŒ‡ä»¤å¹¶é€æ­¥åº”ç”¨åˆ°è§†é¢‘ä¸Šã€‚

### âœ… æ–‡ä»¶ç»“æ„å»ºè®®ï¼š

```
video_editor/
â”‚
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ editor_engine.py      # å‰ªè¾‘æ‰§è¡Œå¼•æ“
â”‚   â””â”€â”€ operations/           # æ¯ä¸ªå‰ªè¾‘æ“ä½œå•ç‹¬å°è£…
â”‚       â”œâ”€â”€ cut.py
â”‚       â”œâ”€â”€ speedup.py
â”‚       â”œâ”€â”€ add_transition.py
â”‚       â”œâ”€â”€ set_resolution.py
â”‚       â””â”€â”€ apply_filter.py
â”‚
â”œâ”€â”€ transitions/
â”‚   â””â”€â”€ apply_transition.py   # ä¹‹å‰å†™çš„ç»Ÿä¸€æ¥å£
â”‚
â””â”€â”€ main.py
```

---

## ğŸ§µ å…­ã€å‰ªè¾‘æ‰§è¡Œå¼•æ“ä»£ç å®ç°ï¼ˆ`editor_engine.py`ï¼‰

```python
import json
from moviepy.editor import VideoFileClip, concatenate_videoclips
from transitions.apply_transition import apply_transition

class VideoEditorEngine:
    def __init__(self, video_path):
        self.original_clip = VideoFileClip(video_path)
        self.current_clips = [self.original_clip]  # å½“å‰ç‰‡æ®µåˆ—è¡¨

    def execute_actions(self, actions_json):
        """
        æ‰§è¡Œä¸€ç³»åˆ—å‰ªè¾‘æ“ä½œ
        
        :param actions_json: æ¥è‡ª Qwen Plus çš„ actions åˆ—è¡¨
        """
        for action in actions_json:
            func = action["function"]
            
            if func == "cut":
                self._execute_cut(action)
                
            elif func == "speedup":
                self._execute_speedup(action)
                
            elif func == "add_transition":
                self._execute_add_transition(action)
                
            elif func == "set_resolution":
                self._execute_set_resolution(action)
                
            elif func == "apply_filter":
                self._execute_apply_filter(action)
                
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„æ“ä½œï¼š{func}")

        # æœ€ç»ˆåˆå¹¶æ‰€æœ‰ç‰‡æ®µ
        final_clip = concatenate_videoclips(self.current_clips, method="compose")
        return final_clip

    def _execute_cut(self, action):
        """è£å‰ªæŒ‡å®šæ—¶é—´æ®µ"""
        start = action.get("start", 0)
        end = action.get("end", self.original_clip.duration)
        
        new_clips = []
        for clip in self.current_clips:
            if clip.end <= start or clip.start >= end:
                new_clips.append(clip)
            else:
                if clip.start < start:
                    new_clips.append(clip.subclip(clip.start, min(end, start)))
                if clip.end > end:
                    new_clips.append(clip.subclip(max(start, end), clip.end))
        self.current_clips = new_clips

    def _execute_speedup(self, action):
        """åŠ é€ŸæŸæ®µè§†é¢‘"""
        start = action.get("start", 0)
        end = action.get("end", self.original_clip.duration)
        factor = action.get("factor", 1.0)

        new_clips = []
        for clip in self.current_clips:
            if clip.start >= end or clip.end <= start:
                new_clips.append(clip)
            else:
                middle = clip.subclip(
                    max(start, clip.start),
                    min(end, clip.end)
                ).fx(vfx.speedx, factor)
                if clip.start < start:
                    new_clips.append(clip.subclip(clip.start, start))
                new_clips.append(middle)
                if clip.end > end:
                    new_clips.append(clip.subclip(end, clip.end))
        self.current_clips = new_clips

    def _execute_add_transition(self, action):
        """æ·»åŠ è½¬åœº"""
        type_ = action.get("type", "crossfade")
        start = action.get("start", 0)
        duration = action.get("duration", 0.5)
        direction = action.get("direction", None)

        # è¿™é‡Œå‡è®¾å½“å‰åªå¯¹ç›¸é‚»ä¸¤ä¸ªç‰‡æ®µä¹‹é—´åŠ è½¬åœº
        # å¯ä»¥æ ¹æ®å…·ä½“é€»è¾‘æ‰©å±•
        clipA = self.current_clips[0]
        clipB = self.current_clips[1]

        transition_clip = apply_transition(
            type=type_,
            clipA=clipA,
            clipB=clipB,
            duration=duration,
            direction=direction
        )

        self.current_clips = [transition_clip] + self.current_clips[2:]

    def _execute_set_resolution(self, action):
        """è®¾ç½®åˆ†è¾¨ç‡"""
        width = action.get("width", 1920)
        height = action.get("height", 1080)
        orientation = action.get("orientation", "landscape")

        new_clips = []
        for clip in self.current_clips:
            resized_clip = clip.resize(height=height)
            new_clips.append(resized_clip)
        self.current_clips = new_clips

    def _execute_apply_filter(self, action):
        """åº”ç”¨æ»¤é•œ"""
        filter_name = action.get("filter_name")
        start = action.get("start", 0)
        end = action.get("end", self.original_clip.duration)

        new_clips = []
        for clip in self.current_clips:
            if clip.start >= end or clip.end <= start:
                new_clips.append(clip)
            else:
                middle = clip.subclip(
                    max(start, clip.start),
                    min(end, clip.end)
                )
                if filter_name == "slowmotion":
                    middle = middle.fx(vfx.speedx, 0.5)
                elif filter_name == "blackwhite":
                    middle = middle.fx(vfx.blackwhite)
                new_clips.append(middle)
        self.current_clips = new_clips
```

---

## ğŸ§ª ä¸ƒã€ä½¿ç”¨ç¤ºä¾‹ï¼ˆ`main.py`ï¼‰

```python
from engine.editor_engine import VideoEditorEngine

if __name__ == "__main__":
    # ç¤ºä¾‹å‰ªè¾‘æŒ‡ä»¤ï¼ˆæ¨¡æ‹Ÿ Qwen Plus è¿”å›ç»“æœï¼‰
    editing_plan = {
        "thought_process": ["ç•¥"],
        "actions": [
            {"function": "cut", "start": 0, "end": 5},
            {"function": "speedup", "start": 10, "end": 15, "factor": 1.5},
            {"function": "add_transition", "type": "crossfade", "start": 5, "duration": 0.5},
            {"function": "set_resolution", "width": 1080, "height": 1920, "orientation": "portrait"},
            {"function": "apply_filter", "filter_name": "slowmotion", "start": 5, "end": 10}
        ]
    }

    # åˆå§‹åŒ–å‰ªè¾‘å¼•æ“
    editor = VideoEditorEngine("example.mp4")

    # æ‰§è¡Œå‰ªè¾‘è®¡åˆ’
    final_clip = editor.execute_actions(editing_plan["actions"])

    # å¯¼å‡ºè§†é¢‘
    final_clip.write_videofile("output.mp4", codec="libx264", audio_codec="aac")
```

---

## ğŸš€ å…«ã€ä¸‹ä¸€æ­¥å»ºè®®

ä½ ç°åœ¨æœ‰äº†å®Œæ•´çš„å‰ªè¾‘æ‰§è¡Œå¼•æ“ï¼Œæ¥ä¸‹æ¥å¯ä»¥ï¼š

### âœ… è¡¥å…¨ç¼ºå¤±çš„å‰ªè¾‘å‡½æ•°ï¼š
- `zoom`, `rotate`, `blinds`, `flash` ç­‰é«˜çº§è½¬åœº
- `text_overlay`, `subtitle`, `logo_insert` ç­‰å¢å¼ºåŠŸèƒ½

### âœ… å®ç°â€œå‰ªè¾‘æµç¨‹ç¼–æ’å™¨â€ï¼š
- æŠŠåˆ†æ â†’ Prompt â†’ å¤§æ¨¡å‹ â†’ æ‰§è¡Œå¼•æ“ä¸²èµ·æ¥
- æ”¯æŒå‘½ä»¤è¡Œæˆ– Web UI è¾“å…¥å‚æ•°

### âœ… å¢åŠ ç¼“å­˜æœºåˆ¶ï¼š
- é¿å…é‡å¤åˆ†æå’Œå‰ªè¾‘ï¼Œæå‡æ€§èƒ½

---

## ğŸ“Œ æœ€åä¸€æ­¥ï¼šä½ æƒ³ç»§ç»­åšå“ªä¸€éƒ¨åˆ†ï¼Ÿ

- âœ… æˆ‘å¸®ä½ è¡¥å…¨ `zoom_transition` æˆ– `blinds_transition`ï¼Ÿ
- âœ… æˆ‘å¸®ä½ å†™ä¸€ä¸ªå®Œæ•´çš„å‰ªè¾‘æµç¨‹ç¼–æ’å™¨ï¼Ÿ
- âœ… æˆ‘å¸®ä½ åšä¸€ä¸ªç®€å•çš„ Web é¡µé¢ä¸Šä¼ è§†é¢‘å¹¶è‡ªåŠ¨å‰ªè¾‘ï¼Ÿ
- âœ… æˆ‘å¸®ä½ éƒ¨ç½²æˆæœåŠ¡ï¼ˆå¦‚ FastAPI / Streamlitï¼‰ï¼Ÿ

å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹© ğŸ‘‡ æˆ‘ä»¬ç»§ç»­æ¨è¿›ï¼



å¤ªæ£’äº†ï¼æˆ‘ä»¬ç°åœ¨æ¥æ„å»ºä¸€ä¸ª **å®Œæ•´çš„å‰ªè¾‘æµç¨‹ç¼–æ’å™¨ï¼ˆEditing Workflow Orchestratorï¼‰**ï¼Œå®ƒçš„ç›®æ ‡æ˜¯ï¼š

> ä»åŸå§‹è§†é¢‘æ–‡ä»¶å¼€å§‹ï¼Œè‡ªåŠ¨å®Œæˆä»¥ä¸‹æ•´ä¸ª AI å‰ªè¾‘æµç¨‹ï¼š
1. è§†é¢‘åˆ†æï¼ˆæå–å…³é”®ä¿¡æ¯ï¼‰
2. æ„å»º Promptï¼ˆè°ƒç”¨ Prompt å·¥ç¨‹ç®¡é“ï¼‰
3. è°ƒç”¨ Qwen Plus APIï¼ˆç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼‰
4. æ‰§è¡Œå‰ªè¾‘æ“ä½œï¼ˆè°ƒç”¨å‰ªè¾‘æ‰§è¡Œå¼•æ“ï¼‰
5. è¾“å‡ºæœ€ç»ˆå‰ªè¾‘ç»“æœ

---

## ğŸ§± ä¸€ã€æ•´ä½“æ¶æ„å›¾ï¼ˆé€»è¾‘æµç¨‹ï¼‰

```
[è¾“å…¥è§†é¢‘] 
     â†“
[è§†é¢‘åˆ†ææ¨¡å—] â†’ æå– metadata, scene changes, speech, objects...
     â†“
[Prompt å·¥ç¨‹ç®¡é“] â†’ æ„é€ ç”¨æˆ·æç¤ºè¯ + ç³»ç»Ÿæç¤ºè¯
     â†“
[Qwen Plus API] â†’ æ¥æ”¶ promptï¼Œè¿”å› JSON æ ¼å¼çš„å‰ªè¾‘æŒ‡ä»¤
     â†“
[å‰ªè¾‘æ‰§è¡Œå¼•æ“] â†’ è§£æå¹¶æ‰§è¡Œå‰ªè¾‘åŠ¨ä½œï¼Œç”Ÿæˆæœ€ç»ˆè§†é¢‘
     â†“
[è¾“å‡ºå‰ªè¾‘è§†é¢‘]
```

---

## ğŸ“ äºŒã€é¡¹ç›®ç»“æ„å»ºè®®ï¼ˆå®Œæ•´å·¥ç¨‹ç›®å½•ï¼‰

```
video_editor/
â”‚
â”œâ”€â”€ analyzer/                  # è§†é¢‘åˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ video_analyzer.py      # åˆ†æå‡½æ•°
â”‚
â”œâ”€â”€ prompts/                   # Prompt å·¥ç¨‹ç®¡é“
â”‚   â”œâ”€â”€ templates/             # æ¨¡æ¿æ–‡ä»¶
â”‚   â””â”€â”€ prompt_pipeline.py     # æ„å»º prompt çš„ç±»
â”‚
â”œâ”€â”€ engine/                    # å‰ªè¾‘æ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ editor_engine.py       # æ‰§è¡Œå‰ªè¾‘çš„ä¸»ç±»
â”‚   â””â”€â”€ operations/            # å„ç§å‰ªè¾‘å‡½æ•°
â”‚
â”œâ”€â”€ transitions/               # è½¬åœºå‡½æ•°åº“
â”‚   â””â”€â”€ apply_transition.py    # ç»Ÿä¸€æ¥å£
â”‚
â”œâ”€â”€ orchestrator/              # ç¼–æ’å™¨
â”‚   â””â”€â”€ workflow_orchestrator.py  # ä¸»æµç¨‹æ§åˆ¶å™¨
â”‚
â””â”€â”€ main.py                    # å…¥å£è„šæœ¬
```

---

## ğŸ”¨ ä¸‰ã€ç¼–æ’å™¨åŠŸèƒ½å®ç°ï¼ˆ`workflow_orchestrator.py`ï¼‰

```python
import json
from analyzer.video_analyzer import analyze_video
from prompts.prompt_pipeline import PromptPipeline
from dashscope_api import call_qwen_plus
from engine.editor_engine import VideoEditorEngine


class VideoEditingOrchestrator:
    def __init__(self, video_path):
        self.video_path = video_path
        self.analysis_report = None
        self.prompt_pipeline = PromptPipeline()
        self.editing_plan = None

    def run_analysis(self):
        """ç¬¬ä¸€æ­¥ï¼šåˆ†æè§†é¢‘"""
        print("ğŸ” æ­£åœ¨åˆ†æè§†é¢‘å†…å®¹...")
        self.analysis_report = analyze_video(self.video_path)
        print("âœ… è§†é¢‘åˆ†æå®Œæˆã€‚")
        return self.analysis_report

    def generate_prompt(self, user_options=None):
        """ç¬¬äºŒæ­¥ï¼šæ ¹æ®åˆ†æç»“æœç”Ÿæˆ Prompt"""
        if not self.analysis_report:
            raise RuntimeError("è¯·å…ˆè¿è¡Œè§†é¢‘åˆ†æ")

        print("ğŸ§  æ­£åœ¨ç”Ÿæˆ Prompt...")
        full_prompt = self.prompt_pipeline.build_full_prompt(
            self.analysis_report,
            user_options=user_options
        )
        print("âœ… Prompt æ„å»ºå®Œæˆã€‚")
        return full_prompt

    def call_ai_model(self, prompt):
        """ç¬¬ä¸‰æ­¥ï¼šè°ƒç”¨ Qwen Plus è·å–å‰ªè¾‘ç­–ç•¥"""
        print("ğŸ¤– æ­£åœ¨è°ƒç”¨ Qwen Plus API...")
        response = call_qwen_plus(prompt)
        print("âœ… å‰ªè¾‘ç­–ç•¥ç”Ÿæˆå®Œæˆã€‚")
        try:
            self.editing_plan = json.loads(response)
            return self.editing_plan
        except Exception as e:
            raise ValueError(f"æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯: {e}")

    def execute_editing(self):
        """ç¬¬å››æ­¥ï¼šæ‰§è¡Œå‰ªè¾‘è®¡åˆ’"""
        if not self.editing_plan:
            raise RuntimeError("è¯·å…ˆè°ƒç”¨ AI æ¨¡å‹ç”Ÿæˆå‰ªè¾‘è®¡åˆ’")

        print("ğŸ¬ æ­£åœ¨æ‰§è¡Œå‰ªè¾‘æ“ä½œ...")
        editor = VideoEditorEngine(self.video_path)
        final_clip = editor.execute_actions(self.editing_plan.get("actions", []))
        print("âœ… å‰ªè¾‘æ“ä½œæ‰§è¡Œå®Œæˆã€‚")
        return final_clip

    def export_video(self, clip, output_path="output.mp4"):
        """ç¬¬äº”æ­¥ï¼šå¯¼å‡ºæœ€ç»ˆè§†é¢‘"""
        print(f"ğŸ“¼ æ­£åœ¨å¯¼å‡ºè§†é¢‘åˆ° {output_path}...")
        clip.write_videofile(output_path, codec="libx264", audio_codec="aac")
        print("âœ… è§†é¢‘å¯¼å‡ºå®Œæˆã€‚")
        return output_path

    def run(self, user_options=None, output_path="output.mp4"):
        """ä¸€é”®è¿è¡Œå…¨æµç¨‹"""
        self.run_analysis()
        prompt = self.generate_prompt(user_options)
        editing_plan = self.call_ai_model(prompt)
        final_clip = self.execute_editing()
        result_path = self.export_video(final_clip, output_path)

        return {
            "analysis": self.analysis_report,
            "prompt": prompt,
            "editing_plan": editing_plan,
            "output_video": result_path
        }
```

---

## ğŸš€ å››ã€ä½¿ç”¨ç¤ºä¾‹ï¼ˆ`main.py`ï¼‰

```python
from orchestrator.workflow_orchestrator import VideoEditingOrchestrator

if __name__ == "__main__":
    VIDEO_PATH = "example.mp4"
    OUTPUT_PATH = "final_output.mp4"

    orchestrator = VideoEditingOrchestrator(VIDEO_PATH)

    user_options = {
        "target_duration": 30,
        "target_style": "æŠ–éŸ³é£",
        "target_purpose": "çŸ­è§†é¢‘å¹³å°"
    }

    result = orchestrator.run(user_options=user_options, output_path=OUTPUT_PATH)

    print("\nğŸ‰ å‰ªè¾‘ä»»åŠ¡å·²å®Œæˆï¼è¾“å‡ºè·¯å¾„ä¸ºï¼š", result["output_video"])
```

---

## ğŸ§  äº”ã€è¡¥å……è¯´æ˜

### âœ… `dashscope_api.py` ç¤ºä¾‹ï¼ˆè°ƒç”¨ Qwen Plusï¼‰

```python
import requests

def call_qwen_plus(prompt: str) -> str:
    """
    è°ƒç”¨ Qwen Plus API
    
    :param prompt: ç”¨æˆ·æç¤ºè¯
    :return: æ¨¡å‹è¿”å›çš„ JSON å­—ç¬¦ä¸²
    """
    url = "https://api.dashscope.cn/api/v1/services/aigc/text-generation/generation"
    headers = {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
    }
    data = {
        "model": "qwen-plus",
        "input": {
            "prompt": prompt
        },
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.8,
            "max_tokens": 2048
        }
    }

    response = requests.post(url, headers=headers, json=data)
    return response.json()["output"]["text"]
```

---

## ğŸ“Œ å…­ã€ä¸‹ä¸€æ­¥å»ºè®®

ä½ ç°åœ¨æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„ AI è§†é¢‘å‰ªè¾‘æµç¨‹ç¼–æ’å™¨ï¼

æ¥ä¸‹æ¥ä½ å¯ä»¥ï¼š

### âœ… 1. åŠ å…¥æ—¥å¿—è®°å½•å’Œè¿›åº¦æ¡ï¼ˆæå‡ç”¨æˆ·ä½“éªŒï¼‰
### âœ… 2. å®ç°å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼ˆå¦‚ API é”™è¯¯é‡è¯•ã€å‰ªè¾‘å¤±è´¥å›æ»šï¼‰
### âœ… 3. æ„å»º Web UIï¼ˆStreamlit / FastAPIï¼‰è®©ç”¨æˆ·ä¸Šä¼ è§†é¢‘å³å¯å‰ªè¾‘
### âœ… 4. æ”¯æŒå¤šè§†é¢‘æ‹¼æ¥ã€å­—å¹•æ·»åŠ ç­‰é«˜çº§åŠŸèƒ½

---

## ğŸ“¬ æœ€åä¸€æ­¥ï¼šä½ æƒ³ç»§ç»­åšå“ªä¸€éƒ¨åˆ†ï¼Ÿ

- âœ… æˆ‘å¸®ä½ å†™ä¸€ä¸ª Streamlit Web é¡µé¢ï¼Œæ”¯æŒä¸Šä¼ è§†é¢‘è‡ªåŠ¨å‰ªè¾‘ï¼Ÿ
- âœ… æˆ‘å¸®ä½ å°è£…æˆå‘½ä»¤è¡Œå·¥å…·ï¼ˆCLIï¼‰ï¼Ÿ
- âœ… æˆ‘å¸®ä½ éƒ¨ç½²ä¸ºæœ¬åœ°æœåŠ¡æˆ– Docker å®¹å™¨ï¼Ÿ
- âœ… æˆ‘å¸®ä½ åŠ ä¸€ä¸ªè¿›åº¦æ¡å’Œæ—¥å¿—ç³»ç»Ÿï¼Ÿ

å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹© ğŸ‘‡ æˆ‘ä»¬ç»§ç»­æ¨è¿›ï¼