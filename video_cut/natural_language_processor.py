"""
è‡ªç„¶è¯­è¨€è§†é¢‘æ—¶é—´è½´å¤„ç†å™¨

è¯¥æ¨¡å—æä¾›å°†è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºè§†é¢‘ç¼–è¾‘æ—¶é—´è½´JSONç»“æ„çš„åŠŸèƒ½ã€‚
æ”¯æŒä¸­æ–‡æè¿°çš„æ—¶é—´ã€ç‰¹æ•ˆã€èŠ‚å¥å’Œé¢œè‰²ä¸»é¢˜è¯†åˆ«ã€‚
"""
import json
import re
from typing import Dict, List, Any, Tuple, Optional, Union
from dataclasses import dataclass
from enum import Enum
import jieba
import logging
from pathlib import Path

# æ·»åŠ éªŒè¯å™¨
try:
    from .utils.validators import InputValidator, ErrorHandler
except ImportError:
    # å¦‚æœvalidatorsè¿˜æœªåˆ›å»ºï¼Œä½¿ç”¨ä¸´æ—¶å ä½
    class InputValidator:
        @staticmethod
        def validate_natural_language(text): return text
        @staticmethod
        def validate_duration(d): return float(d)
    class ErrorHandler:
        @staticmethod
        def handle_api_error(e, f=None): return {"error": str(e)}

# ç±»å‹åˆ«åï¼Œæé«˜ä»£ç å¯è¯»æ€§
TimelineDict = Dict[str, Any]
PatternConverter = Union[callable, Tuple[callable, ...]]
DurationPattern = Tuple[str, PatternConverter]
RhythmConfig = Dict[str, Union[int, float, List[str]]]


class VideoEffectType(Enum):
    """è§†é¢‘ç‰¹æ•ˆç±»å‹æšä¸¾
    
    æ¯ä¸ªæšä¸¾å€¼åŒ…å«è¯¥ç‰¹æ•ˆçš„ä¸­è‹±æ–‡å…³é”®è¯åˆ—è¡¨
    """
    FADE_IN = ["æ·¡å…¥", "æ¸å…¥", "fade in"]
    FADE_OUT = ["æ·¡å‡º", "æ¸å‡º", "fade out"] 
    TRANSITION = ["è½¬åœº", "è¿‡æ¸¡", "åˆ‡æ¢"]
    SUBTITLE = ["å­—å¹•", "æ–‡å­—", "æ ‡é¢˜", "subtitle"]
    BACKGROUND_MUSIC = ["èƒŒæ™¯éŸ³ä¹", "éŸ³ä¹", "é…ä¹", "bgm"]
    BLUR = ["æ¨¡ç³Š", "è™šåŒ–", "blur"]
    ZOOM = ["æ”¾å¤§", "ç¼©æ”¾", "zoom"]
    ROTATE = ["æ—‹è½¬", "rotate"]
    GLOW = ["å‘å…‰", "å…‰æ™•", "glow"]


@dataclass
class VideoTimeSegment:
    """è§†é¢‘æ—¶é—´æ®µæ•°æ®ç±»
    
    è¡¨ç¤ºè§†é¢‘ä¸­çš„ä¸€ä¸ªæ—¶é—´æ®µï¼ŒåŒ…å«æ—¶é—´èŒƒå›´ã€å†…å®¹æè¿°å’Œåº”ç”¨çš„ç‰¹æ•ˆ
    """
    start_time: float
    end_time: float
    description: str
    effect_list: List[str]
    
    @property
    def duration(self) -> float:
        """è·å–æ—¶é—´æ®µæŒç»­æ—¶é•¿"""
        return self.end_time - self.start_time


class VideoTimelineProcessor:
    """è‡ªç„¶è¯­è¨€è§†é¢‘æ—¶é—´è½´å¤„ç†å™¨
    
    å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°è§£æä¸ºç»“æ„åŒ–çš„è§†é¢‘ç¼–è¾‘æ—¶é—´è½´é…ç½®ã€‚
    æ”¯æŒæ—¶é—´è¡¨è¾¾å¼ã€ç‰¹æ•ˆå…³é”®è¯ã€èŠ‚å¥æè¿°å’Œé¢œè‰²ä¸»é¢˜çš„æ™ºèƒ½è¯†åˆ«ã€‚
    """
    
    # å¸¸é‡å®šä¹‰
    DEFAULT_VIDEO_DURATION = 60.0
    DEFAULT_FPS = 30
    DEFAULT_RESOLUTION = {"width": 1920, "height": 1080}
    DEFAULT_SEGMENT_DURATION = 10.0
    
    def __init__(self):
        """åˆå§‹åŒ–æ—¶é—´è½´å¤„ç†å™¨"""
        self._setup_jieba_tokenizer()
        self._initialize_patterns()
        self._setup_logger()
    
    def _setup_logger(self) -> None:
        """è®¾ç½®æ—¥å¿—å™¨"""
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
        
    def _setup_jieba_tokenizer(self) -> None:
        """è®¾ç½®ä¸­æ–‡åˆ†è¯å™¨"""
        video_editing_terms = [
            "è½¬åœº", "æ·¡å…¥", "æ·¡å‡º", "å­—å¹•", "èƒŒæ™¯éŸ³ä¹",
            "ç‰‡å¤´", "ç‰‡å°¾", "ç‰¹æ•ˆ", "æ»¤é•œ", "åŠ¨ç”»",
            "ç¨åŠ¡", "çº³ç¨", "ä¾æ³•çº³ç¨", "ä¸»è¦ç¨ç§"
        ]
        
        for term in video_editing_terms:
            jieba.add_word(term, freq=10000)
    
    def _initialize_patterns(self) -> None:
        """åˆå§‹åŒ–å„ç§è¯†åˆ«æ¨¡å¼"""
        self._duration_patterns: List[DurationPattern] = [
            (r'(\d+)ç§’', lambda x: float(x)),
            (r'(\d+)s', lambda x: float(x)),
            (r'(\d+)åˆ†é’Ÿ', lambda x: float(x) * 60),
            (r'(\d+)åˆ†(\d+)ç§’', lambda x, y: float(x) * 60 + float(y)),
            (r'(\d+)min', lambda x: float(x) * 60),
            (r'(\d+):(\d+)', lambda x, y: float(x) * 60 + float(y))
        ]
        
        self._time_range_patterns: List[Tuple[str, callable]] = [
            (r'(\d+)-(\d+)ç§’', lambda x, y: (float(x), float(y))),
            (r'(\d+)åˆ°(\d+)ç§’', lambda x, y: (float(x), float(y))),
            (r'å‰(\d+)ç§’', lambda x: (0, float(x))),
            (r'æœ€å(\d+)ç§’', lambda x: (-float(x), None)),
            (r'ç¬¬(\d+)ç§’å¼€å§‹', lambda x: (float(x), None))
        ]
        
        self._rhythm_configurations: Dict[str, RhythmConfig] = {
            "å¿«èŠ‚å¥": {"cuts_per_minute": 12, "transition_duration": 0.3},
            "æ…¢èŠ‚å¥": {"cuts_per_minute": 4, "transition_duration": 1.0},
            "åŠ¨æ„Ÿ": {"cuts_per_minute": 10, "effects": ["shake", "zoom"]},
            "å¹³ç¼“": {"cuts_per_minute": 3, "effects": ["fade"]},
            "ç´§å¼ ": {"cuts_per_minute": 15, "effects": ["glitch", "shake"]}
        }
        
        self._color_palette: Dict[str, str] = {
            "ç»¿è‰²": "#00FF00", "è“è‰²": "#0000FF", "çº¢è‰²": "#FF0000",
            "é»„è‰²": "#FFFF00", "ç´«è‰²": "#800080", "æ©™è‰²": "#FFA500",
            "é»‘ç™½": "#000000", "é‡‘è‰²": "#FFD700"
        }

    def generate_timeline_from_text(self, user_description: str, duration: Optional[float] = None) -> TimelineDict:
        """å°†è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºè§†é¢‘æ—¶é—´è½´é…ç½®
        
        Args:
            user_description: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è§†é¢‘æè¿°
            
        Returns:
            åŒ…å«å®Œæ•´æ—¶é—´è½´é…ç½®çš„å­—å…¸ç»“æ„
            
        Example:
            >>> processor = VideoTimelineProcessor()
            >>> result = processor.generate_timeline_from_text("åˆ¶ä½œ30ç§’è§†é¢‘ï¼ŒåŠ è½¬åœºå’Œå­—å¹•")
            >>> result['timeline']['duration']
            30.0
        """
        try:
            # éªŒè¯è¾“å…¥
            user_description = InputValidator.validate_natural_language(user_description)
            self.logger.info(f"å¤„ç†è‡ªç„¶è¯­è¨€è¾“å…¥: {user_description[:50]}...")
            
            # è§£æç”¨æˆ·æè¿°ä¸­çš„å„ç§ä¿¡æ¯
            video_duration = duration or self._parse_duration(user_description)
            time_segments = self._parse_time_segments(user_description, total_duration=video_duration)
            global_effects = self._parse_global_effects(user_description)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è½¬åœºæ•ˆæœ
            transition_effect = None
            self.logger.info(f"ğŸ” æ£€æŸ¥å…¨å±€ç‰¹æ•ˆä¸­çš„è½¬åœº: {global_effects}")
            # ğŸ”¥ ä¿®å¤ï¼šæ£€æŸ¥æ‰€æœ‰è½¬åœºç±»å‹ï¼Œä¸åªæ˜¯åŒ…å«"transition"çš„
            transition_keywords = ["transition", "leaf_flip", "blinds", "wind_blow"]
            for effect in global_effects:
                if any(keyword in effect for keyword in transition_keywords):
                    transition_effect = effect
                    self.logger.info(f"ğŸ¬ è¯†åˆ«åˆ°è½¬åœºæ•ˆæœ: {transition_effect}")
                    # ä»å…¨å±€ç‰¹æ•ˆä¸­ç§»é™¤è½¬åœºæ•ˆæœï¼Œå› ä¸ºå®ƒè¦ç‰¹æ®Šå¤„ç†
                    global_effects = [e for e in global_effects if e != effect]
                    break
            
            if not transition_effect:
                self.logger.info("âš ï¸ æ²¡æœ‰è¯†åˆ«åˆ°è½¬åœºæ•ˆæœ")
            
            artistic_style = self._parse_artistic_style(user_description)  # æ–°å¢è‰ºæœ¯é£æ ¼è§£æ
            if artistic_style:
                self.logger.info(f"ğŸ¨ è¯†åˆ«åˆ°è‰ºæœ¯é£æ ¼: {artistic_style}")
            rhythm_config = self._parse_rhythm_style(user_description)
            color_theme = self._parse_color_theme(user_description)
        except Exception as e:
            self.logger.error(f"è§£æè‡ªç„¶è¯­è¨€å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤å€¼ç»§ç»­
            video_duration = self.DEFAULT_VIDEO_DURATION
            time_segments = []
            global_effects = []
            artistic_style = None
            rhythm_config = {}
            color_theme = None
            transition_effect = None
        
        # æ„å»ºæ—¶é—´è½´ç»“æ„
        timeline_config = self._build_timeline_structure(
            title=self._extract_video_title(user_description),
            description=self._create_description_summary(user_description),
            duration=video_duration,
            color_theme=color_theme
        )
        
        # è®¾ç½®è½¬åœºæ•ˆæœåˆ°metadata
        if transition_effect:
            timeline_config["metadata"]["transition_effect"] = transition_effect
            self.logger.info(f"âœ… è½¬åœºæ•ˆæœå·²è®¾ç½®åˆ°metadata: {transition_effect}")
        else:
            self.logger.info("â„¹ï¸ æ²¡æœ‰è½¬åœºæ•ˆæœéœ€è¦è®¾ç½®åˆ°metadata")
        
        # ç”Ÿæˆè§†é¢‘è½¨é“
        timeline_config["timeline"]["tracks"] = self._generate_video_tracks(
            time_segments, global_effects, video_duration, rhythm_config, artistic_style
        )
        
        return timeline_config
    
    def _build_timeline_structure(self, title: str, description: str, 
                                duration: float, color_theme: Optional[str]) -> TimelineDict:
        """æ„å»ºåŸºç¡€æ—¶é—´è½´ç»“æ„"""
        return {
            "version": "1.0",
            "metadata": {
                "title": title,
                "description": description,
                "tags": self._extract_content_tags(title + " " + description),
                "generated_from": "natural_language_processing",
                "generator_version": "1.0",
                "transition_effect": None  # å°†åœ¨åé¢è®¾ç½®
            },
            "timeline": {
                "duration": duration,
                "fps": self.DEFAULT_FPS,
                "resolution": self.DEFAULT_RESOLUTION.copy(),
                "background_color": color_theme or "#000000",
                "tracks": []
            }
        }
    
    def _create_description_summary(self, text: str) -> str:
        """åˆ›å»ºæè¿°æ‘˜è¦"""
        max_length = 100
        if len(text) <= max_length:
            return text
        return text[:max_length].rsplit(' ', 1)[0] + "..."

    def _parse_duration(self, text: str) -> float:
        """è§£æè§†é¢‘æ€»æ—¶é•¿
        
        ä»è‡ªç„¶è¯­è¨€ä¸­è¯†åˆ«æ—¶é•¿è¡¨è¾¾å¼ï¼Œå¦‚"30ç§’"ã€"2åˆ†é’Ÿ"ç­‰
        """
        for pattern, converter in self._duration_patterns:
            matches = re.findall(pattern, text)
            if matches:
                if isinstance(matches[0], tuple):
                    return converter(*matches[0])
                else:
                    return converter(matches[0])
        
        return self.DEFAULT_VIDEO_DURATION

    def _parse_time_segments(self, text: str, total_duration: Optional[float] = None) -> List[VideoTimeSegment]:
        """è§£ææ—¶é—´æ®µä¿¡æ¯
        
        å°†æ–‡æœ¬åˆ†è§£ä¸ºå¤šä¸ªæ—¶é—´æ®µï¼Œæ¯ä¸ªæ®µè½åŒ…å«æ—¶é—´èŒƒå›´å’Œå†…å®¹æè¿°
        """
        segments = []
        sentences = re.split(r'[ã€‚ï¼›\n]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå¥å­ï¼Œä½¿ç”¨æ•´ä¸ªæ—¶é•¿
        if len(sentences) <= 1 and total_duration:
            sentence = sentences[0] if sentences else text
            segment_effects = self._identify_segment_effects(sentence)
            segments.append(VideoTimeSegment(
                start_time=0.0,
                end_time=total_duration,
                description=sentence,
                effect_list=segment_effects
            ))
            return segments
        
        # å¤šä¸ªå¥å­æ—¶ï¼Œå¹³å‡åˆ†é…æ—¶é•¿
        segment_duration = (total_duration or self.DEFAULT_VIDEO_DURATION) / len(sentences) if sentences else self.DEFAULT_SEGMENT_DURATION
        
        current_time = 0.0
        for sentence in sentences:
            # è§£ææ—¶é—´èŒƒå›´
            time_range = self._parse_time_range(sentence)
            
            if time_range:
                start_time, end_time = time_range
                if end_time is None:
                    end_time = start_time + segment_duration
            else:
                # è‡ªåŠ¨åˆ†é…æ—¶é—´æ®µ
                start_time = current_time
                end_time = current_time + segment_duration
                # ç¡®ä¿æœ€åä¸€æ®µä¸è¶…è¿‡æ€»æ—¶é•¿
                if total_duration and end_time > total_duration:
                    end_time = total_duration
            
            # è¯†åˆ«è¯¥æ®µçš„ç‰¹æ•ˆ
            segment_effects = self._identify_segment_effects(sentence)
            
            segments.append(VideoTimeSegment(
                start_time=start_time,
                end_time=end_time,
                description=sentence,
                effect_list=segment_effects
            ))
            
            current_time = end_time
        
        return segments

    def _parse_time_range(self, text: str) -> Optional[Tuple[float, Optional[float]]]:
        """è§£ææ—¶é—´èŒƒå›´è¡¨è¾¾å¼
        
        è¯†åˆ«å¦‚"0-5ç§’"ã€"å‰10ç§’"ç­‰æ—¶é—´èŒƒå›´æè¿°
        """
        for pattern, converter in self._time_range_patterns:
            match = re.search(pattern, text)
            if match:
                groups = match.groups()
                if len(groups) == 1:
                    return converter(groups[0])
                else:
                    return converter(*groups)
        return None

    def _identify_segment_effects(self, text: str) -> List[str]:
        """è¯†åˆ«ç‰‡æ®µä¸­çš„ç‰¹æ•ˆå…³é”®è¯
        
        æ£€æµ‹æ–‡æœ¬ä¸­æåˆ°çš„ç‰¹æ•ˆç±»å‹ï¼Œè¿”å›ç‰¹æ•ˆåç§°åˆ—è¡¨
        """
        detected_effects = []
        
        # ä¼˜å…ˆæ£€æŸ¥è½¬åœºæ•ˆæœå…³é”®è¯ï¼Œé¿å…è¢«å…¶ä»–æ•ˆæœè¯¯è¯†åˆ«
        transition_keywords = ["å¶ç‰‡ç¿»è½¬", "ç™¾å¶çª—", "é£å¹", "è½¬åœº"]
        has_transition = False
        for keyword in transition_keywords:
            if keyword in text:
                # ğŸ”¥ é‡è¦ï¼šè½¬åœºæ•ˆæœä¸åº”è¯¥åŠ å…¥åˆ°ç‰‡æ®µçš„effect_list
                # è½¬åœºæ•ˆæœä¼šåœ¨å…¨å±€å¤„ç†ï¼Œä¸åœ¨å•ä¸ªç‰‡æ®µä¸­å¤„ç†
                has_transition = True
                self.logger.info(f"æ£€æµ‹åˆ°è½¬åœºå…³é”®è¯ '{keyword}'ï¼Œå°†åœ¨å…¨å±€å¤„ç†")
                break
        
        # å¦‚æœæœ‰è½¬åœºæ•ˆæœï¼Œä¸æ·»åŠ åˆ°ç‰‡æ®µæ•ˆæœåˆ—è¡¨
        if not has_transition:
            for effect_type in VideoEffectType:
                # è·³è¿‡TRANSITIONç±»å‹ï¼Œå› ä¸ºå·²ç»å•ç‹¬å¤„ç†
                if effect_type == VideoEffectType.TRANSITION:
                    continue
                for keyword in effect_type.value:
                    if keyword in text:
                        detected_effects.append(effect_type.name.lower())
                        break
        
        return detected_effects

    def _parse_global_effects(self, text: str) -> List[str]:
        """è§£æå…¨å±€ç‰¹æ•ˆ
        
        è¯†åˆ«åº”ç”¨äºæ•´ä¸ªè§†é¢‘çš„ç‰¹æ•ˆç±»å‹
        """
        global_effects = []
        
        # è½¬åœºæ•ˆæœå…³é”®è¯æ˜ å°„ - è¿™äº›åº”è¯¥ä½œä¸ºè½¬åœºè€Œä¸æ˜¯æ»¤é•œ
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé•¿çš„å…³é”®è¯ä¼˜å…ˆåŒ¹é…
        transition_keyword_map = {
            "å¶ç‰‡ç¿»è½¬è½¬åœº": "leaf_flip_transition",
            "å¶ç‰‡ç¿»è½¬": "leaf_flip_transition",
            "ç™¾å¶çª—è½¬åœº": "blinds_transition",
            "ç™¾å¶çª—": "blinds_transition",
            "é£å¹è½¬åœº": "wind_blow_transition",
            "é£å¹": "wind_blow_transition",
            "ç¿»è½¬è½¬åœº": "leaf_flip_transition",  # é¢å¤–æ•è·"ç¿»è½¬è½¬åœº"
        }
        
        # æ»¤é•œæ•ˆæœå…³é”®è¯æ˜ å°„
        filter_keyword_map = {
            # ç«å±±å¼•æ“æ»¤é•œ
            "å¤å¤": "vintage", "æ¸…æ™°": "clear", "æ¢¦å¢ƒ": "dream",
            "ç«¥å¹´": "childhood", "ç¾å¼": "american", "å¥¶æ²¹": "cream",
            "æ¨±èŠ±": "sakura", "äº¬éƒ½": "kyoto", "æ™šéœ": "sunset",
            # åŸºç¡€æ•ˆæœ
            "æ•…éšœ": "glitch", "éœ‡åŠ¨": "shake",
            "æ¨¡ç³Š": "blur", "å‘å…‰": "glow", "ç²’å­": "particle",
            "ç¼©æ”¾": "zoom"
            # ç§»é™¤"æ—‹è½¬"å…³é”®è¯ï¼Œé¿å…ä¸"ç¿»è½¬"å†²çª
        }
        
        # ä¼˜å…ˆæ£€æŸ¥è½¬åœºæ•ˆæœ
        found_transition = False
        for keyword, effect_name in transition_keyword_map.items():
            if keyword in text:
                global_effects.append(effect_name)
                self.logger.info(f"ğŸ¬ æ£€æµ‹åˆ°è½¬åœºå…³é”®è¯: '{keyword}' -> {effect_name}")
                found_transition = True
                # è½¬åœºæ•ˆæœæ‰¾åˆ°åï¼Œè·³è¿‡å¯¹åº”çš„æ»¤é•œæ£€æŸ¥
                break
        
        # å¦‚æœæ‰¾åˆ°äº†è½¬åœºæ•ˆæœï¼Œä¸å†æŸ¥æ‰¾æ»¤é•œï¼ˆé¿å…"ç¿»è½¬"è¢«è¯†åˆ«ä¸º"æ—‹è½¬"ï¼‰
        if not found_transition:
            # æ£€æŸ¥æ»¤é•œæ•ˆæœ
            for keyword, effect_name in filter_keyword_map.items():
                if keyword in text:
                    global_effects.append(effect_name)
            
            # ç‰¹æ®Šå¤„ç†ï¼šåªæœ‰æ˜ç¡®è¯´"æ—‹è½¬"ä¸”ä¸åŒ…å«"ç¿»è½¬"æ—¶æ‰æ·»åŠ æ—‹è½¬æ»¤é•œ
            if "æ—‹è½¬" in text and "ç¿»è½¬" not in text:
                global_effects.append("rotate")
        
        return global_effects
    
    def _parse_artistic_style(self, text: str) -> Optional[str]:
        """è§£æè‰ºæœ¯é£æ ¼
        
        è¯†åˆ«ç”¨æˆ·æƒ³è¦çš„8å¤§è‰ºæœ¯é£æ ¼ä¹‹ä¸€
        """
        # è‰ºæœ¯é£æ ¼å…³é”®è¯æ˜ å°„
        style_keywords = {
            "å¤å¤èµ›åš": ["å¤å¤èµ›åš", "èµ›åšæœ‹å…‹", "éœ“è™¹", "cyberpunk", "neon"],
            "é»‘ç™½é»˜ç‰‡": ["é»‘ç™½é»˜ç‰‡", "é»˜ç‰‡", "è€ç”µå½±", "é»‘ç™½", "æ€€æ—§"],
            "æ¢¦å¹»ä»™å¢ƒ": ["æ¢¦å¹»ä»™å¢ƒ", "æ¢¦å¹»", "ç«¥è¯", "ä»™å¢ƒ", "æ¢¦å¢ƒ"],
            "æ‰‹ç»˜åŠ¨ç”»": ["æ‰‹ç»˜åŠ¨ç”»", "æ‰‹ç»˜", "ç´ æ", "é“…ç¬”", "æ°´å½©"],
            "æç®€æ‰å¹³": ["æç®€æ‰å¹³", "æ‰å¹³", "æç®€", "ç®€çº¦", "flat"],
            "èƒ¶ç‰‡è´¨æ„Ÿ": ["èƒ¶ç‰‡è´¨æ„Ÿ", "èƒ¶ç‰‡", "ç”µå½±æ„Ÿ", "35mm", "film"],
            "æ•…éšœè‰ºæœ¯": ["æ•…éšœè‰ºæœ¯", "æ•…éšœ", "glitch", "å¤±çœŸ", "é”™ä½"],
            "è’¸æ±½æ³¢": ["è’¸æ±½æ³¢", "vaporwave", "å¤å¤æœªæ¥", "vhs", "retro"]
        }
        
        for style_name, keywords in style_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text.lower():
                    return style_name
        
        return None

    def _parse_rhythm_style(self, text: str) -> RhythmConfig:
        """è§£æèŠ‚å¥é£æ ¼
        
        æ ¹æ®æè¿°è¯†åˆ«è§†é¢‘çš„èŠ‚å¥ç±»å‹ï¼ˆå¿«èŠ‚å¥ã€æ…¢èŠ‚å¥ç­‰ï¼‰
        """
        for rhythm_keyword, config in self._rhythm_configurations.items():
            if rhythm_keyword in text:
                return config
        
        # è¿”å›é»˜è®¤èŠ‚å¥é…ç½®
        return {"cuts_per_minute": 6, "transition_duration": 0.5}

    def _parse_color_theme(self, text: str) -> Optional[str]:
        """è§£æé¢œè‰²ä¸»é¢˜
        
        ä»æè¿°ä¸­è¯†åˆ«é¢œè‰²ç›¸å…³çš„è¡¨è¾¾ï¼Œè¿”å›å¯¹åº”çš„é¢œè‰²ä»£ç 
        """
        for color_name, color_code in self._color_palette.items():
            if color_name in text:
                return color_code
        return None

    def _extract_video_title(self, text: str) -> str:
        """æå–è§†é¢‘æ ‡é¢˜
        
        ä»è‡ªç„¶è¯­è¨€æè¿°ä¸­æå–åˆé€‚çš„è§†é¢‘æ ‡é¢˜
        """
        # ä»ç¬¬ä¸€å¥ä¸­æå–å…³é”®ä¿¡æ¯
        first_sentence = text.split('ã€‚')[0].split('ï¼Œ')[0]
        
        # æ¸…ç†å¸¸è§çš„åŠ¨è¯å‰ç¼€
        title = re.sub(r'åˆ¶ä½œä¸€ä¸ª|åˆ¶ä½œ|åˆ›å»º|ç”Ÿæˆ', '', first_sentence)
        title = re.sub(r'çš„è§†é¢‘|è§†é¢‘', '', title)
        
        cleaned_title = title.strip()
        return cleaned_title if cleaned_title else "AIç”Ÿæˆè§†é¢‘"

    def _extract_content_tags(self, text: str) -> List[str]:
        """æå–å†…å®¹æ ‡ç­¾
        
        ä½¿ç”¨åˆ†è¯æŠ€æœ¯è¯†åˆ«è§†é¢‘å†…å®¹çš„å…³é”®æ ‡ç­¾
        """
        # ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯
        word_segments = list(jieba.cut(text))
        
        # é‡è¦å…³é”®è¯åˆ—è¡¨
        important_keywords = [
            "ç¨åŠ¡", "äº§å“", "æ•™è‚²", "å®£ä¼ ", "ç§‘æ™®", "æ•™å­¦", 
            "å¹¿å‘Š", "vlog", "ä»‹ç»", "å±•ç¤º", "æ¼”ç¤º"
        ]
        
        detected_tags = []
        for word in word_segments:
            if word in important_keywords and word not in detected_tags:
                detected_tags.append(word)
        
        return detected_tags[:5]  # è¿”å›æœ€å¤š5ä¸ªæ ‡ç­¾

    def _generate_video_tracks(self, segments: List[VideoTimeSegment], 
                             global_effects: List[str], duration: float, 
                             rhythm_config: RhythmConfig, artistic_style: Optional[str] = None) -> List[Dict]:
        """ç”Ÿæˆè§†é¢‘è½¨é“
        
        æ ¹æ®è§£æçš„æ—¶é—´æ®µå’Œç‰¹æ•ˆé…ç½®ç”Ÿæˆå®Œæ•´çš„è§†é¢‘è½¨é“ç»“æ„
        """
        all_tracks = []
        
        # ä¸»è§†é¢‘è½¨é“
        main_video_track = {
            "type": "video",
            "name": "ä¸»è§†é¢‘",
            "clips": []
        }
        
        # ä¸ºæ¯ä¸ªæ—¶é—´æ®µç”Ÿæˆè§†é¢‘ç‰‡æ®µ
        for segment_index, segment in enumerate(segments):
            # ğŸ”¥ ä¿®å¤æ—¶é•¿å­—æ®µçš„ç”Ÿæˆé€»è¾‘
            # clipInå’ŒclipOutæ˜¯æºè§†é¢‘ä¸­çš„æ—¶é—´ç‚¹ï¼Œstartå’Œendæ˜¯è¾“å‡ºæ—¶é—´è½´ä¸Šçš„æ—¶é—´
            video_clip = {
                "start": segment.start_time,
                "end": segment.end_time,
                "clipIn": segment.start_time,  # ä»æºè§†é¢‘çš„å¯¹åº”æ—¶é—´ç‚¹å¼€å§‹
                "clipOut": segment.end_time,   # åˆ°æºè§†é¢‘çš„å¯¹åº”æ—¶é—´ç‚¹ç»“æŸ
                "filters": self._convert_effects_to_filters(segment.effect_list + global_effects),
                "transform": {"scale": 1.0, "position": "center"}  # ğŸ”¥ ä½¿ç”¨centerè€Œä¸æ˜¯åƒç´ åæ ‡
            }
            
            # æ·»åŠ è‰ºæœ¯é£æ ¼ï¼ˆå¦‚æœç”¨æˆ·æŒ‡å®šäº†ï¼‰
            if artistic_style:
                video_clip["artistic_style"] = artistic_style
                self.logger.info(f"ğŸ¨ åº”ç”¨è‰ºæœ¯é£æ ¼åˆ°ç‰‡æ®µ: {artistic_style}")
            
            # ğŸ”¥ ç¡®ä¿æ‰€æœ‰æ—¶é•¿å­—æ®µä¸€è‡´
            self.logger.info(f"ç”Ÿæˆè§†é¢‘ç‰‡æ®µ: {segment.start_time}s-{segment.end_time}s (æ—¶é•¿: {segment.end_time - segment.start_time}s)")
            
            # æ·»åŠ è½¬åœºæ•ˆæœ
            if segment_index > 0 and "transition" in segment.effect_list:
                video_clip["transition_in"] = {
                    "type": "fade",
                    "duration": rhythm_config.get("transition_duration", 0.5)
                }
            
            main_video_track["clips"].append(video_clip)
        
        all_tracks.append(main_video_track)
        
        # å­—å¹•è½¨é“ç”Ÿæˆ
        subtitle_clips = []
        for segment in segments:
            needs_subtitle = ("subtitle" in segment.effect_list or 
                            "å­—å¹•" in segment.description or
                            "background_music" in segment.effect_list)
            
            if needs_subtitle:
                subtitle_clips.append({
                    "start": segment.start_time,
                    "end": segment.end_time,
                    "clipIn": segment.start_time,
                    "clipOut": segment.end_time,
                    "filters": [],
                    "content": {
                        "text": self._extract_subtitle_text(segment.description),
                        "font": "æ€æºé»‘ä½“",
                        "size": 36,
                        "color": "#FFFFFF",
                        "position": "bottom",
                        "alignment": "center",
                        "outline": {"color": "#000000", "width": 2}
                    }
                })
        
        if subtitle_clips:
            all_tracks.append({
                "type": "text",
                "name": "å­—å¹•è½¨é“",
                "clips": subtitle_clips
            })
        
        # èƒŒæ™¯éŸ³ä¹è½¨é“ç”Ÿæˆ
        needs_background_music = any(
            "background_music" in segment.effect_list or "èƒŒæ™¯éŸ³ä¹" in segment.description 
            for segment in segments
        )
        
        all_descriptions = ' '.join(segment.description for segment in segments)
        if needs_background_music or "èƒŒæ™¯éŸ³ä¹" in all_descriptions:
            all_tracks.append({
                "type": "audio",
                "name": "èƒŒæ™¯éŸ³ä¹",
                "clips": [{
                    "start": 0,
                    "end": duration,
                    "clipIn": 0,
                    "clipOut": duration,
                    "filters": [],
                    "content": {
                        "source": "default_background_music.mp3",
                        "volume": 0.3,
                        "loop": True,
                        "fade_in": 2.0,
                        "fade_out": 2.0
                    }
                }]
            })
        
        return all_tracks

    def _convert_effects_to_filters(self, effect_names: List[str]) -> List[str]:
        """å°†ç‰¹æ•ˆåç§°è½¬æ¢ä¸ºæ»¤é•œæ ‡è¯†ç¬¦
        
        å°†è¯­ä¹‰åŒ–çš„ç‰¹æ•ˆåç§°è½¬æ¢ä¸ºç³»ç»Ÿå¯è¯†åˆ«çš„æ»¤é•œIDæ ¼å¼
        """
        import random
        filter_identifiers = []
        
        # ç‰¹æ•ˆåˆ°æ»¤é•œçš„æ˜ å°„è¡¨
        effect_to_filter_map = {
            "fade_in": "fade_001",
            "fade_out": "fade_002", 
            "blur": "blur_001",
            "glow": "glow_001",
            "zoom": "zoom_001",
            "rotate": "rotate_001",
            "transition_001": "transition_001"  # å…¼å®¹æ—§ç‰ˆæœ¬
        }
        
        # å¯ç”¨çš„è½¬åœºæ•ˆæœåˆ—è¡¨
        # æ³¨æ„ï¼šrotateä¸æ˜¯è½¬åœºæ•ˆæœï¼Œæ˜¯æ»¤é•œæ•ˆæœï¼Œæ‰€ä»¥ç§»é™¤
        transition_effects = [
            "zoom_in",
            "zoom_out", 
            "pan_left",
            "pan_right",
            # "rotate",  # ç§»é™¤ï¼Œè¿™æ˜¯æ»¤é•œä¸æ˜¯è½¬åœº
            "shake",
            "glitch"
        ]
        
        for effect_name in effect_names:
            # ğŸ”¥ é‡è¦ï¼šè½¬åœºæ•ˆæœä¸åº”è¯¥ä½œä¸ºæ»¤é•œæ·»åŠ ï¼
            # è½¬åœºæ•ˆæœåº”è¯¥åœ¨metadataä¸­å¤„ç†ï¼Œä¸æ˜¯ä½œä¸ºclipçš„filter
            if effect_name in ["leaf_flip_transition", "blinds_transition", "wind_blow_transition"]:
                # è¿™äº›æ˜¯è½¬åœºæ•ˆæœï¼Œä¸æ·»åŠ åˆ°æ»¤é•œåˆ—è¡¨
                self.logger.info(f"è·³è¿‡è½¬åœºæ•ˆæœï¼ˆå°†åœ¨metadataä¸­å¤„ç†ï¼‰: {effect_name}")
                continue
            elif effect_name == "transition" or effect_name == "transition_001":
                # å¦‚æœæ˜¯é€šç”¨è½¬åœºæ ‡è®°ï¼Œä¹Ÿè·³è¿‡ï¼ˆåº”è¯¥åœ¨metadataä¸­å¤„ç†ï¼‰
                self.logger.info(f"è·³è¿‡é€šç”¨è½¬åœºæ ‡è®°: {effect_name}")
                continue
            elif effect_name in effect_to_filter_map:
                filter_identifiers.append(effect_to_filter_map[effect_name])
        
        return filter_identifiers

    def _extract_subtitle_text(self, content_description: str) -> str:
        """ä»å†…å®¹æè¿°ä¸­æå–å­—å¹•æ–‡æœ¬
        
        æ™ºèƒ½æå–é€‚åˆä½œä¸ºå­—å¹•æ˜¾ç¤ºçš„æ–‡æœ¬å†…å®¹
        """
        # æ¸…ç†æ—¶é—´æ ‡è®°
        cleaned_text = re.sub(r'\d+-\d+ç§’|ç¬¬\d+ç§’|å‰\d+ç§’', '', content_description)
        
        # æå–å¼•å·ä¸­çš„ç›´æ¥å†…å®¹
        quoted_content = re.findall(r'["""](.*?)["""]', cleaned_text)
        if quoted_content:
            return quoted_content[0]
        
        # æå–å†’å·åçš„è¯´æ˜å†…å®¹
        if 'ï¼š' in cleaned_text:
            return cleaned_text.split('ï¼š', 1)[1].strip()
        
        # è¿”å›æ¸…ç†åçš„æ–‡æœ¬
        return cleaned_text.strip()


def test_video_timeline_processor():
    """æµ‹è¯•è§†é¢‘æ—¶é—´è½´å¤„ç†å™¨"""
    processor = VideoTimelineProcessor()
    
    # æµ‹è¯•ç”¨ä¾‹1ï¼šç®€å•æè¿°
    simple_description = "åˆ¶ä½œä¸€ä¸ª30ç§’çš„äº§å“å®£ä¼ è§†é¢‘ï¼Œè¦æœ‰è½¬åœºç‰¹æ•ˆå’Œå­—å¹•"
    result1 = processor.generate_timeline_from_text(simple_description)
    print("=== æµ‹è¯•1ï¼šç®€å•æè¿° ===")
    print(f"æ—¶é•¿: {result1['timeline']['duration']}ç§’")
    print(f"è½¨é“æ•°: {len(result1['timeline']['tracks'])}")
    
    # æµ‹è¯•ç”¨ä¾‹2ï¼šè¯¦ç»†æè¿°
    detailed_description = """
    åˆ¶ä½œ45ç§’çš„ç¨åŠ¡çŸ¥è¯†ç§‘æ™®è§†é¢‘ï¼š
    0-5ç§’ï¼šæ˜¾ç¤ºæ ‡é¢˜"ç¨åŠ¡çŸ¥è¯†ç§‘æ™®"ï¼Œæ·¡å…¥æ•ˆæœ
    5-20ç§’ï¼šä»‹ç»ç¨åŠ¡åŸºç¡€çŸ¥è¯†ï¼Œé…å­—å¹•
    20-35ç§’ï¼šè¯´æ˜çº³ç¨ä¹‰åŠ¡ï¼Œä½¿ç”¨ç»¿è‰²ä¸»é¢˜
    35-45ç§’ï¼šæ€»ç»“è¦ç‚¹ï¼Œæ·¡å‡ºæ•ˆæœï¼ŒèƒŒæ™¯éŸ³ä¹
    """
    result2 = processor.generate_timeline_from_text(detailed_description)
    print("\n=== æµ‹è¯•2ï¼šè¯¦ç»†æè¿° ===")
    print(f"æ ‡é¢˜: {result2['metadata']['title']}")
    print(f"æ—¶é•¿: {result2['timeline']['duration']}ç§’")
    print(f"èƒŒæ™¯è‰²: {result2['timeline']['background_color']}")
    
    # è¾“å‡ºå®Œæ•´ç»“æœç”¨äºè°ƒè¯•
    print("\nå®Œæ•´æ—¶é—´è½´é…ç½®:")
    print(json.dumps(result2, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    test_video_timeline_processor()