"""
AuraRender æœºæ¢°æ‰§è¡Œå™¨

è´Ÿè´£ï¼š
1. è§£ææ‰§è¡Œè„šæœ¬
2. åŠ è½½å’Œç”Ÿæˆèµ„æº
3. æ‰§è¡Œæ—¶é—´è½´
4. åº”ç”¨ç‰¹æ•ˆ
5. æ¸²æŸ“è¾“å‡º
"""

import json
import os
import sys
from typing import Dict, Any, List, Optional
from pathlib import Path
import tempfile
import shutil
from datetime import datetime
from moviepy import VideoFileClip, AudioFileClip, ImageClip, TextClip, ColorClip, CompositeVideoClip, concatenate_videoclips, VideoClip
from moviepy.video.fx import CrossFadeIn, CrossFadeOut, MultiplyColor
from moviepy.video.fx.Resize import Resize
import numpy as np
import requests

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '../../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from core.utils.file_utils import download_file_with_retry


class AuraExecutor:
    """æœºæ¢°æ‰§è¡Œå™¨ - ç²¾ç¡®æ‰§è¡Œè„šæœ¬ï¼Œæ— æ™ºèƒ½å†³ç­–"""
    
    def __init__(self, ai_generators: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–æ‰§è¡Œå™¨
        
        Args:
            ai_generators: AIç”Ÿæˆå™¨é…ç½®ï¼ŒåŒ…å«ä¸‡ç›¸ç­‰AIç”Ÿæˆæ¥å£
        """
        self.ai_generators = ai_generators or {}
        self.temp_dir = None
        self.resources_cache = {}
        
    def execute(self, script: Dict[str, Any], output_path: str) -> str:
        """
        æ‰§è¡Œè„šæœ¬ç”Ÿæˆè§†é¢‘
        
        Args:
            script: æ‰§è¡Œè„šæœ¬
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
            self.temp_dir = tempfile.mkdtemp(prefix='aura_exec_')
            
            # 1. éªŒè¯è„šæœ¬
            self._validate_script(script)
            
            # 2. åŠ è½½èµ„æº
            resources = self._load_resources(script['resources'])
            
            # 3. æ„å»ºæ—¶é—´è½´
            timeline = self._build_timeline(script['timeline'], resources, script['project'])
            
            # 4. åº”ç”¨å…¨å±€æ•ˆæœ
            final_video = self._apply_global_effects(timeline, script.get('global_effects', {}))
            
            # 5. æ¸²æŸ“è¾“å‡º
            output_file = self._render_output(final_video, script['project'], output_path)
            
            return output_file
            
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if self.temp_dir and os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
    
    def _validate_script(self, script: Dict[str, Any]):
        """éªŒè¯è„šæœ¬æ ¼å¼"""
        required_fields = ['version', 'project', 'resources', 'timeline']
        for field in required_fields:
            if field not in script:
                raise ValueError(f"è„šæœ¬ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # éªŒè¯é¡¹ç›®é…ç½®
        project = script['project']
        required_project_fields = ['duration', 'resolution', 'fps']
        for field in required_project_fields:
            if field not in project:
                raise ValueError(f"é¡¹ç›®é…ç½®ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
    
    def _load_resources(self, resources_config: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ è½½æ‰€æœ‰èµ„æº"""
        resources = {
            'videos': {},
            'images': {},
            'audio': {},
            'text': {}
        }
        
        print(f"ğŸ“¦ åŠ è½½èµ„æºé…ç½®ä¸­...")
        
        # åŠ è½½è§†é¢‘èµ„æº
        for video in resources_config.get('videos', []):
            video_id = video['id']
            video_source = video['source']
            print(f"ğŸ¬ åŠ è½½è§†é¢‘èµ„æº: {video_id}")
            
            if video['source'] == 'ai_generated':
                # ä½¿ç”¨AIç”Ÿæˆè§†é¢‘
                video_path = self._generate_video(video['params'])
            else:
                # ä¸‹è½½æˆ–åŠ è½½æœ¬åœ°è§†é¢‘
                video_path = self._load_media_file(video['source'])
            
            if video_path:
                try:
                    clip = VideoFileClip(video_path)
                    # åº”ç”¨æ—¶é•¿é™åˆ¶
                    if 'duration' in video:
                        # MoviePy 2.x ä½¿ç”¨ subclipped
                        clip = clip.subclipped(0, min(video['duration'], clip.duration))
                    resources['videos'][video_id] = clip
                    print(f"âœ… è§†é¢‘èµ„æº {video_id} åŠ è½½æˆåŠŸï¼Œæ—¶é•¿: {clip.duration}s")
                except Exception as e:
                    print(f"âŒ åŠ è½½è§†é¢‘æ–‡ä»¶å¤±è´¥: {video_path}, é”™è¯¯: {e}")
            else:
                print(f"âŒ è§†é¢‘èµ„æº {video_id} åŠ è½½å¤±è´¥: æ— æ³•è·å–æ–‡ä»¶è·¯å¾„")
        
        # åŠ è½½å›¾ç‰‡èµ„æº
        for image in resources_config.get('images', []):
            image_id = image['id']
            if image['source'].startswith('oss://') or image['source'].startswith('http'):
                image_path = self._load_media_file(image['source'])
                if image_path:
                    resources['images'][image_id] = ImageClip(image_path)
        
        # åŠ è½½éŸ³é¢‘èµ„æº
        for audio in resources_config.get('audio', []):
            audio_id = audio['id']
            if audio['source'] == 'ai_generated':
                # ä½¿ç”¨AIç”ŸæˆéŸ³é¢‘
                audio_path = self._generate_audio(audio['params'])
            else:
                audio_path = self._load_media_file(audio['source'])
            
            if audio_path:
                resources['audio'][audio_id] = AudioFileClip(audio_path)
        
        return resources
    
    def _build_timeline(self, timeline_config: List[Dict[str, Any]], 
                       resources: Dict[str, Any], project: Dict[str, Any]) -> VideoClip:
        """æ„å»ºè§†é¢‘æ—¶é—´è½´"""
        print(f"\nğŸ•°ï¸ æ„å»ºè§†é¢‘æ—¶é—´è½´")
        print(f"ğŸ“ æ—¶é—´è½´é…ç½®ï¼š")
        print("-" * 60)
        
        # è¾“å‡ºæ—¶é—´è½´è¯¦æƒ…
        total_duration = 0
        for i, segment in enumerate(timeline_config, 1):
            print(f"\nğŸ¬ ç‰‡æ®µ {i}:")
            print(f"   â±ï¸  æ—¶é—´: {segment.get('start', 0)}s - {segment.get('end', 0)}s")
            print(f"   ğŸ¨ ç±»å‹: {segment.get('type', 'unknown')}")
            
            # è¾“å‡ºå›¾å±‚ä¿¡æ¯
            layers = segment.get('layers', [])
            for j, layer in enumerate(layers, 1):
                print(f"   ğŸ—ƒï¸  å›¾å±‚ {j}: {layer.get('type', 'unknown')} - {layer.get('resource_id', 'unknown')}")
                if layer.get('effects'):
                    print(f"      âœ¨ ç‰¹æ•ˆ: {', '.join(layer.get('effects', []))}")
                if layer.get('transform'):
                    print(f"      ğŸ”„ å˜æ¢: {layer.get('transform')}")
            
            total_duration = max(total_duration, segment.get('end', 0))
        
        print(f"\nğŸ“Š æ€»æ—¶é•¿: {total_duration}s")
        print("-" * 60)
        
        # è§£æåˆ†è¾¨ç‡
        resolution = project['resolution']
        if isinstance(resolution, str):
            width, height = map(int, resolution.split('x'))
        else:
            width = resolution.get('width', 1920)
            height = resolution.get('height', 1080)
        
        print(f"ğŸ“º åˆ†è¾¨ç‡: {width}x{height}")
        
        # åˆ›å»ºä¸»åˆæˆ
        clips = []
        
        for segment in timeline_config:
            start_time = segment['start']
            end_time = segment['end']
            duration = end_time - start_time
            
            # å¤„ç†æ¯ä¸ªå›¾å±‚
            segment_clips = []
            for layer in segment.get('layers', []):
                layer_clip = self._process_layer(layer, resources, duration)
                if layer_clip:
                    # è®¾ç½®èµ·å§‹æ—¶é—´
                    layer_clip = layer_clip.with_start(start_time)
                    segment_clips.append(layer_clip)
            
            # åˆæˆè¯¥ç‰‡æ®µçš„æ‰€æœ‰å›¾å±‚
            if segment_clips:
                # æ³¨æ„ï¼šsegment_clips ä¸­çš„æ¯ä¸ªclipå·²ç»è®¾ç½®äº†start_time
                # ä¸éœ€è¦å†æ¬¡è®¾ç½®æ—¶é—´ï¼Œç›´æ¥æ·»åŠ åˆ°clipsåˆ—è¡¨
                for clip in segment_clips:
                    # åº”ç”¨è½¬åœºæ•ˆæœï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'transition_out' in segment:
                        clip = self._apply_transition(clip, segment['transition_out'])
                    clips.append(clip)
        
        # åˆæˆæ‰€æœ‰ç‰‡æ®µ - ä½¿ç”¨ CompositeVideoClip è€Œä¸æ˜¯ concatenate
        if clips:
            # åˆ›å»ºèƒŒæ™¯ï¼ˆé»‘è‰²ï¼‰
            bg = ColorClip(size=(width, height), color=(0, 0, 0), duration=project['duration'])
            # å°†æ‰€æœ‰ç‰‡æ®µæŒ‰æ—¶é—´è½´åˆæˆ
            final_video = CompositeVideoClip([bg] + clips, size=(width, height))
            # MoviePy 2.x ä½¿ç”¨ with_duration
            final_video = final_video.with_duration(project['duration'])
            return final_video
        else:
            # å¦‚æœæ²¡æœ‰ç‰‡æ®µï¼Œåˆ›å»ºä¸€ä¸ªç©ºç™½è§†é¢‘
            return ColorClip(size=(width, height), color=(0, 0, 0), duration=project['duration'])
    
    def _process_layer(self, layer: Dict[str, Any], resources: Dict[str, Any], duration: float) -> Optional[VideoClip]:
        """å¤„ç†å•ä¸ªå›¾å±‚"""
        layer_type = layer['type']
        
        if layer_type == 'video':
            resource_id = layer['resource_id']
            
            if resource_id in resources['videos']:
                clip = resources['videos'][resource_id].copy()
                # MoviePy 2.x ä½¿ç”¨ with_duration
                clip = clip.with_duration(duration)
            else:
                # å¦‚æœè§†é¢‘èµ„æºä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªå ä½æ–‡æœ¬
                print(f"âš ï¸ è§†é¢‘èµ„æºä¸å­˜åœ¨: {resource_id}ï¼Œåˆ›å»ºå ä½å†…å®¹")
                clip = TextClip(
                    text=f"è§†é¢‘ç‰‡æ®µ: {resource_id}",
                    font='Arial',
                    font_size=40,
                    color='white',
                    text_align='center'
                ).with_duration(duration)
                # æ·»åŠ èƒŒæ™¯è‰²
                bg = ColorClip(size=(1920, 1080), color=(30, 30, 50), duration=duration)
                clip = CompositeVideoClip([bg, clip.with_position('center')])
                
        elif layer_type == 'image':
            resource_id = layer['resource_id']
            if resource_id in resources['images']:
                clip = resources['images'][resource_id].copy()
                # MoviePy 2.x ä½¿ç”¨ with_duration
                clip = clip.with_duration(duration)
            else:
                # å¦‚æœå›¾ç‰‡èµ„æºä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªå ä½å›¾ç‰‡
                clip = TextClip(
                    text=f"å›¾ç‰‡: {resource_id}",
                    font='Arial',
                    font_size=30,
                    color='white',
                    text_align='center'
                ).with_duration(duration)
                # æ·»åŠ èƒŒæ™¯è‰²
                bg = ColorClip(size=(1920, 1080), color=(50, 30, 30), duration=duration)
                clip = CompositeVideoClip([bg, clip.with_position('center')])
                
        elif layer_type == 'text':
            # åˆ›å»ºæ–‡å­—å›¾å±‚
            content = layer.get('content', '')
            style = layer.get('style', {})
            
            clip = TextClip(
                text=content,
                font=style.get('font', 'Arial'),
                font_size=style.get('size', 50),
                color=style.get('color', 'white'),
                text_align='center'
            ).with_duration(duration)
            
            # åº”ç”¨åŠ¨ç”»
            if style.get('animation') == 'fade_in':
                clip = clip.with_effects([CrossFadeIn(0.5)])
                
        else:
            return None
        
        # åº”ç”¨å˜æ¢
        if 'transform' in layer:
            transform = layer['transform']
            if 'scale' in transform:
                # MoviePy 2.x ä½¿ç”¨ with_effects
                clip = clip.with_effects([Resize(transform['scale'])])
            if 'position' in transform:
                clip = clip.with_position(transform['position'])
        
        # åº”ç”¨ç‰¹æ•ˆ
        for effect in layer.get('effects', []):
            clip = self._apply_effect(clip, effect)
        
        return clip
    
    def _apply_effect(self, clip: VideoClip, effect: Dict[str, Any]) -> VideoClip:
        """åº”ç”¨å•ä¸ªç‰¹æ•ˆ"""
        effect_type = effect.get('type', '') if isinstance(effect, dict) else effect
        
        # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´å¤šç‰¹æ•ˆ
        if effect_type == 'glow':
            # ç®€å•çš„å‘å…‰æ•ˆæœï¼ˆé€šè¿‡å¢åŠ äº®åº¦æ¨¡æ‹Ÿï¼‰
            intensity = effect.get('intensity', 0.5) if isinstance(effect, dict) else 0.5
            # ç®€å•çš„å‘å…‰æ•ˆæœï¼ˆé€šè¿‡å¢åŠ äº®åº¦æ¨¡æ‹Ÿï¼‰
            # MoviePy 2.x ä½¿ç”¨ MultiplyColor æ•ˆæœ
            clip = clip.with_effects([MultiplyColor(intensity + 1)])
        elif effect_type == 'blur':
            # æ¨¡ç³Šæ•ˆæœ - MoviePy 2.x æš‚æ—¶è·³è¿‡
            # TODO: å®ç°æ¨¡ç³Šæ•ˆæœ
            pass
        
        return clip
    
    def _apply_transition(self, clip: VideoClip, transition: Dict[str, Any]) -> VideoClip:
        """åº”ç”¨è½¬åœºæ•ˆæœ"""
        transition_type = transition['type']
        duration = transition.get('duration', 0.5)
        
        if transition_type == 'fade':
            clip = clip.with_effects([CrossFadeOut(duration)])
        elif transition_type == 'glitch':
            # æ•…éšœæ•ˆæœè½¬åœºï¼ˆç®€åŒ–ç‰ˆï¼‰
            pass
        
        return clip
    
    def _apply_global_effects(self, video: VideoClip, effects: Dict[str, Any]) -> VideoClip:
        """åº”ç”¨å…¨å±€æ•ˆæœ"""
        # é¢œè‰²åˆ†çº§
        if 'color_grading' in effects:
            grading = effects['color_grading']
            if grading == 'cyberpunk_preset':
                # èµ›åšæœ‹å…‹è‰²è°ƒï¼ˆåè“ç´«è‰²ï¼‰
                # èµ›åšæœ‹å…‹è‰²è°ƒï¼ˆåè“ç´«è‰²ï¼‰
                # ä½¿ç”¨ MultiplyColor æ•ˆæœæ¨¡æ‹Ÿ
                # RGBé¡ºåºï¼Œå¢å¼ºçº¢å’Œè“ï¼Œå‡å°‘ç»¿
                video = video.with_effects([MultiplyColor([1.1, 0.9, 1.3])])
            elif grading == 'warm':
                # æš–è‰²è°ƒ
                # æš–è‰²è°ƒ
                # ä½¿ç”¨ MultiplyColor æ•ˆæœ
                # RGBé¡ºåºï¼Œå¢å¼ºçº¢ï¼Œç•¥å¢ç»¿ï¼Œå‡å°‘è“
                video = video.with_effects([MultiplyColor([1.15, 1.05, 0.9])])
        
        # æ»¤é•œ
        for filter_name in effects.get('filters', []):
            if filter_name == 'digital_noise':
                # æ•°å­—å™ªç‚¹æ•ˆæœ
                pass
            elif filter_name == 'scan_lines':
                # æ‰«æçº¿æ•ˆæœ
                pass
        
        return video
    
    def _render_output(self, video: VideoClip, project: Dict[str, Any], output_path: str) -> str:
        """æ¸²æŸ“è¾“å‡ºè§†é¢‘"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # æ¸²æŸ“å‚æ•°
        fps = project.get('fps', 30)
        codec = 'libx264'
        audio_codec = 'aac'
        
        # å†™å…¥è§†é¢‘
        video.write_videofile(
            output_path,
            fps=fps,
            codec=codec,
            audio_codec=audio_codec,
            preset='medium'
        )
        
        return output_path
    
    def _generate_video(self, params: Dict[str, Any]) -> Optional[str]:
        """ä½¿ç”¨AIç”Ÿæˆè§†é¢‘"""
        model = params.get('model', '')
        
        if model == 'animate_diff' and 'animate_diff' in self.ai_generators:
            # è°ƒç”¨AnimateDiffç”Ÿæˆè§†é¢‘
            generator = self.ai_generators['animate_diff']
            result = generator.generate(params)
            if result and 'video_path' in result:
                return result['video_path']
        
        # å¦‚æœæ— æ³•ç”Ÿæˆï¼Œè¿”å›None
        return None
    
    def _generate_audio(self, params: Dict[str, Any]) -> Optional[str]:
        """ä½¿ç”¨AIç”ŸæˆéŸ³é¢‘"""
        model = params.get('model', '')
        
        if model == 'musicgen' and 'musicgen' in self.ai_generators:
            # è°ƒç”¨MusicGenç”ŸæˆéŸ³é¢‘
            generator = self.ai_generators['musicgen']
            result = generator.generate(params)
            if result and 'audio_path' in result:
                return result['audio_path']
        
        # å¦‚æœæ— æ³•ç”Ÿæˆï¼Œåˆ›å»ºé™éŸ³éŸ³é¢‘ä½œä¸ºfallback
        duration = params.get('duration', 30)
        silence_path = os.path.join(self.temp_dir, 'silence.mp3')
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨AudioClipåˆ›å»ºé™éŸ³
        
        return None
    
    def _load_media_file(self, source: str) -> Optional[str]:
        """åŠ è½½åª’ä½“æ–‡ä»¶"""
        if source in self.resources_cache:
            return self.resources_cache[source]
        
        try:
            if source.startswith('oss://'):
                # å¤„ç†OSSè·¯å¾„
                # è¿™é‡Œéœ€è¦å®ç°OSSä¸‹è½½é€»è¾‘
                local_path = os.path.join(self.temp_dir, os.path.basename(source))
                # ä¸‹è½½æ–‡ä»¶...
                self.resources_cache[source] = local_path
                return local_path
                
            elif source.startswith('http'):
                # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘æˆªå›¾æ¥å£
                if 'vframe/jpg' in source or 'vframe/png' in source:
                    print(f"âš ï¸ æ£€æµ‹åˆ°è§†é¢‘æˆªå›¾æ¥å£ï¼Œå°è¯•è½¬æ¢ä¸ºè§†é¢‘URL...")
                    # å°è¯•ç§»é™¤vframeå‚æ•°è·å–åŸå§‹è§†é¢‘
                    video_url = source.split('?')[0]  # ç§»é™¤æŸ¥è¯¢å‚æ•°
                    print(f"ğŸ¬ å°è¯•ä½¿ç”¨åŸå§‹è§†é¢‘URL: {video_url}")
                    source = video_url  # æ›´æ–°sourceä¸ºè§†é¢‘URL
                
                # ç‰¹æ®Šå¤„ç†ç¾èŠ±èµ„æºURL
                if 'resource.meihua.info' in source:
                    print(f"ğŸ‡ æ£€æµ‹åˆ°ç¾èŠ±èµ„æºURL")
                    # è¿™ä¸ªURLå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†æˆ–è€…æ˜¯ä¸€ä¸ªåŠ å¯†èµ„æº
                    # ç›®å‰å…ˆå°è¯•ç›´æ¥ä¸‹è½½
                
                # ä¸‹è½½ç½‘ç»œæ–‡ä»¶
                print(f"ğŸ“¥ ä¸‹è½½ç½‘ç»œæ–‡ä»¶: {source}")
                print(f"ğŸ” URLåˆ†æ:")
                print(f"   - åè®®: {source.split('://')[0]}")
                print(f"   - åŸŸå: {source.split('/')[2]}")
                print(f"   - è·¯å¾„: {'/'.join(source.split('/')[3:])}")
                filename = os.path.basename(source.split('?')[0])  # å¤„ç†URLå‚æ•°
                if not filename or '.' not in filename:
                    # å¦‚æœæ²¡æœ‰æ–‡ä»¶åæˆ–æ²¡æœ‰æ‰©å±•åï¼Œé»˜è®¤ä½¿ç”¨mp4
                    filename = f"downloaded_{int(datetime.now().timestamp())}.mp4"
                elif not any(filename.lower().endswith(ext) for ext in ['.mp4', '.avi', '.mov', '.mkv', '.flv']):
                    # å¦‚æœä¸æ˜¯è§†é¢‘æ‰©å±•åï¼Œæ·»åŠ mp4
                    filename += '.mp4'
                    
                local_path = os.path.join(self.temp_dir, filename)
                
                # å¯¼å…¥ä¸‹è½½å‡½æ•°
                try:
                    from core.utils.file_utils import download_file_with_retry
                    success = download_file_with_retry(source, local_path, verbose=True)
                except Exception as download_error:
                    print(f"âŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {download_error}")
                    print(f"ğŸ” é”™è¯¯ç±»å‹: {type(download_error).__name__}")
                    import traceback
                    traceback.print_exc()
                    success = False
                
                if success and os.path.exists(local_path):
                    # æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶å¤§å°
                    file_size = os.path.getsize(local_path)
                    print(f"ğŸ“ ä¸‹è½½æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                    
                    if file_size < 1024:  # å°äº1KBå¯èƒ½æ˜¯é”™è¯¯æ–‡ä»¶
                        print(f"âš ï¸ ä¸‹è½½çš„æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆè§†é¢‘")
                        try:
                            with open(local_path, 'r') as f:
                                content = f.read()
                            print(f"ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆ: {content[:200]}...")
                        except:
                            pass
                    
                    self.resources_cache[source] = local_path
                    return local_path
                else:
                    print(f"âŒ ç½‘ç»œæ–‡ä»¶ä¸‹è½½å¤±è´¥: {source}")
                    # å°è¯•ä½¿ç”¨å¤‡ç”¨è§†é¢‘
                    print(f"ğŸ† å°è¯•ä½¿ç”¨ç¤ºä¾‹è§†é¢‘ä½œä¸ºå¤‡ç”¨...")
                    # è¿™é‡Œå¯ä»¥è¿”å›ä¸€ä¸ªé»˜è®¤è§†é¢‘è·¯å¾„æˆ–None
                    return None
                
            elif os.path.exists(source):
                # æœ¬åœ°æ–‡ä»¶
                self.resources_cache[source] = source
                return source
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {source}")
                
        except Exception as e:
            print(f"âŒ åŠ è½½èµ„æºå¤±è´¥: {e}")
            
        return None