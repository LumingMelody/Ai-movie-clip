# -*- coding: utf-8 -*-
# @Time    : 2025/6/16 11:22
# @Author  : è”é¸£éœ¸éœ¸
# @FileName: ai_video_editing_mcp_sse.py
# @Software: PyCharm
# @Blog    ï¼šåªå› ä½ å¤ªç¾


"""
AIè§†é¢‘å‰ªè¾‘MCPæœåŠ¡å™¨ - SSEç‰ˆæœ¬
é€šè¿‡Server-Sent Eventsæ”¯æŒMCPåè®®
"""

import asyncio
import json
import logging
import os
import sys
import threading
import queue
import time
import uuid
import tempfile
import shutil
from typing import Any, Dict, List, Optional, Union
from threading import Condition
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from mcp.server.fastmcp import FastMCP
import uvicorn
from core.analyzer.video_analyzer import VideoAnalyzer

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥è§†é¢‘å¤„ç†æ¨¡å—
try:

    from core.orchestrator.workflow_orchestrator import VideoEditingOrchestrator, create_orchestrator_from_analysis
except ImportError as e:
    print(f"è­¦å‘Š: å¯¼å…¥æ¨¡å—å¤±è´¥ {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æ¨¡å—éƒ½åœ¨æ­£ç¡®çš„è·¯å¾„ä¸­")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(title="AI Video Editing MCP Server", version="1.0.0")

# åˆ›å»ºFastMCPå®ä¾‹
mcp = FastMCP("AI Video Editing MCP Server")

# å…¨å±€å˜é‡
task_queue = queue.Queue()
results = {}
result_condition = Condition()
temp_dirs = []  # å­˜å‚¨ä¸´æ—¶ç›®å½•ï¼Œç”¨äºæ¸…ç†


class VideoEditingError(Exception):
    """è‡ªå®šä¹‰å¼‚å¸¸ç±»"""
    pass


# ==================== æ ¸å¿ƒè§†é¢‘å¤„ç†åŠŸèƒ½ ====================

def get_api_key_from_file(file_name="api_key.txt"):
    """ä»æœ¬åœ°æ–‡ä»¶è¯»å–API Key"""
    try:
        base_path = os.path.abspath(os.path.dirname(__file__))
        file_path = os.path.join(base_path, file_name)

        if not os.path.exists(file_path):
            return None

        with open(file_path, "r", encoding="utf-8") as f:
            api_key = f.read().strip()

        return api_key if api_key else None
    except Exception as e:
        logger.error(f"è¯»å–API Keyå¤±è´¥: {e}")
        return None


def is_url(string: str) -> bool:
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæœ‰æ•ˆçš„URL"""
    import urllib.parse
    try:
        result = urllib.parse.urlparse(string)
        return all([result.scheme, result.netloc])
    except:
        return False


def download_video_from_url(url: str) -> str:
    """ä»URLä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶ç›®å½•"""
    try:
        import requests
        import urllib.parse

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp(prefix="ai_video_download_")
        temp_dirs.append(temp_dir)  # è®°å½•ç”¨äºæ¸…ç†

        # è·å–æ–‡ä»¶å
        parsed_url = urllib.parse.urlparse(url)
        filename = os.path.basename(parsed_url.path)
        if not filename or '.' not in filename:
            filename = f"downloaded_video_{int(time.time())}.mp4"

        output_path = os.path.join(temp_dir, filename)

        # ä¸‹è½½æ–‡ä»¶
        logger.info(f"æ­£åœ¨ä¸‹è½½è§†é¢‘: {url}")
        response = requests.get(url, stream=True, timeout=60)
        response.raise_for_status()

        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        logger.info(f"ä¸‹è½½å®Œæˆ: {output_path}")
        return output_path

    except Exception as e:
        raise VideoEditingError(f"ä¸‹è½½è§†é¢‘å¤±è´¥: {str(e)}")


def collect_video_files(paths: List[str]) -> List[str]:
    """æ”¶é›†è§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶å’ŒURL"""
    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm')
    video_files = []

    for path in paths:
        try:
            if is_url(path):
                # å¤„ç†URL
                if any(ext in path.lower() for ext in
                       video_extensions) or 'youtube' in path.lower() or 'bilibili' in path.lower():
                    try:
                        downloaded_path = download_video_from_url(path)
                        video_files.append(downloaded_path)
                        logger.info(f"æˆåŠŸä¸‹è½½è§†é¢‘: {path}")
                    except Exception as e:
                        logger.error(f"ä¸‹è½½å¤±è´¥: {path}, é”™è¯¯: {e}")
                        continue
                else:
                    logger.warning(f"ä¸æ”¯æŒçš„URLç±»å‹: {path}")

            elif os.path.isfile(path):
                # å¤„ç†æœ¬åœ°æ–‡ä»¶
                if path.lower().endswith(video_extensions):
                    video_files.append(path)
                    logger.info(f"æ‰¾åˆ°æœ¬åœ°è§†é¢‘: {path}")
                else:
                    logger.warning(f"è·³è¿‡éè§†é¢‘æ–‡ä»¶: {path}")

            elif os.path.isdir(path):
                # å¤„ç†ç›®å½•
                found_count = 0
                for file in os.listdir(path):
                    if file.lower().endswith(video_extensions):
                        video_files.append(os.path.join(path, file))
                        found_count += 1
                logger.info(f"ç›®å½•ä¸­æ‰¾åˆ° {found_count} ä¸ªè§†é¢‘æ–‡ä»¶: {path}")

            else:
                logger.warning(f"è·¯å¾„ä¸å­˜åœ¨: {path}")

        except Exception as e:
            logger.error(f"å¤„ç†è·¯å¾„ {path} æ—¶å‡ºé”™: {e}")

    return video_files


def cleanup_temp_dirs():
    """æ¸…ç†ä¸´æ—¶ç›®å½•"""
    global temp_dirs
    for temp_dir in temp_dirs:
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
        except Exception as e:
            logger.error(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
    temp_dirs.clear()


# ==================== ä»»åŠ¡å¤„ç†ç³»ç»Ÿ ====================

def process_task(task):
    """å¤„ç†ä»»åŠ¡çš„æ ¸å¿ƒå‡½æ•°"""
    task_id = task["task_id"]
    func_name = task["func_name"]
    args = task["args"]

    start_time = time.time()

    try:
        # è®¾ç½®åˆå§‹çŠ¶æ€
        with result_condition:
            results[task_id] = {
                "status": "processing",
                "started_at": start_time,
                "current_step": "å¼€å§‹æ‰§è¡Œ",
                "progress": "0%"
            }
            result_condition.notify_all()

        func = globals().get(func_name)
        if not func:
            raise VideoEditingError(f"Function {func_name} not found")

        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}, å‡½æ•°: {func_name}")

        # æ‰§è¡Œå®é™…ä»»åŠ¡
        result = func(**args)

        end_time = time.time()
        processing_time = round(end_time - start_time, 2)

        with result_condition:
            results[task_id] = {
                "status": "completed",
                "result": result,
                "timestamp": end_time,
                "started_at": start_time,
                "processing_time": processing_time,
                "function_name": func_name
            }
            result_condition.notify_all()

    except Exception as e:
        end_time = time.time()
        processing_time = round(end_time - start_time, 2)

        logger.error(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        error_traceback = traceback.format_exc()

        with result_condition:
            results[task_id] = {
                "status": "failed",
                "error": str(e),
                "error_type": type(e).__name__,
                "traceback": error_traceback,
                "timestamp": end_time,
                "started_at": start_time,
                "processing_time": processing_time,
                "function_name": func_name
            }
            result_condition.notify_all()


def worker():
    """åå°å·¥ä½œçº¿ç¨‹"""
    while True:
        task = task_queue.get()
        try:
            process_task(task)
        finally:
            task_queue.task_done()


# å¯åŠ¨å·¥ä½œçº¿ç¨‹
worker_thread = threading.Thread(target=worker, daemon=True)
worker_thread.start()


async def execute_task_async(func_name: str, args: dict, mode: str = "async"):
    """å¼‚æ­¥æ‰§è¡Œä»»åŠ¡"""
    task_id = str(uuid.uuid4())
    task_data = {
        "task_id": task_id,
        "func_name": func_name,
        "args": args
    }

    if mode == "sync":
        task_queue.put(task_data)
        timeout_seconds = 1800  # 30åˆ†é’Ÿè¶…æ—¶

        start_time = time.time()
        with result_condition:
            while True:
                elapsed_time = time.time() - start_time
                remaining_time = timeout_seconds - elapsed_time

                if remaining_time <= 0:
                    return {
                        "error": "ä»»åŠ¡æ‰§è¡Œè¶…æ—¶",
                        "timeout": True,
                        "task_id": task_id
                    }

                if task_id in results:
                    result = results[task_id]
                    if result["status"] in ["completed", "failed"]:
                        break

                result_condition.wait(timeout=min(10, remaining_time))

            final_result = results.pop(task_id)

        if final_result["status"] == "completed":
            return final_result["result"]
        elif final_result["status"] == "failed":
            raise VideoEditingError(final_result.get("error", "Unknown error occurred"))
    else:
        task_queue.put(task_data)
        return {"task_id": task_id}


# ==================== æ ¸å¿ƒè§†é¢‘å¤„ç†å‡½æ•° ====================

def analyze_videos_intelligent(video_paths: List[str]) -> Dict[str, Any]:
    """æ™ºèƒ½åˆ†æè§†é¢‘å†…å®¹"""
    logger.info(f"å¼€å§‹æ™ºèƒ½åˆ†æ {len(video_paths)} ä¸ªè§†é¢‘")

    try:
        analyzer = VideoAnalyzer()
    except Exception as e:
        raise VideoEditingError(f"æ— æ³•åˆ›å»ºè§†é¢‘åˆ†æå™¨: {e}")

    analysis_results = []

    for i, video_path in enumerate(video_paths):
        logger.info(f"åˆ†æè§†é¢‘ {i + 1}/{len(video_paths)}: {os.path.basename(video_path)}")

        try:
            result = analyzer.analyze_video(video_path)
            result['file_path'] = video_path
            analysis_results.append(result)

            # è¾“å‡ºåˆ†ææ‘˜è¦
            metadata = result.get('metadata', {})
            classification = result.get('classification', {})
            highlights = result.get('highlights', [])

            logger.info(f"  æ—¶é•¿: {metadata.get('duration', 0):.1f}ç§’")
            logger.info(f"  å†…å®¹ç±»å‹: {classification.get('content_type', 'æœªçŸ¥')}")
            logger.info(f"  ç²¾å½©ç‰‡æ®µ: {len(highlights)}ä¸ª")

        except Exception as e:
            logger.error(f"åˆ†æè§†é¢‘å¤±è´¥: {video_path}, é”™è¯¯: {e}")
            analysis_results.append({
                'file_path': video_path,
                'error': str(e),
                'status': 'failed'
            })

    return {
        "analysis_results": analysis_results,
        "total_videos": len(video_paths),
        "successful_analyses": len([r for r in analysis_results if 'error' not in r]),
        "failed_analyses": len([r for r in analysis_results if 'error' in r])
    }


def format_analysis_results(res: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–åˆ†æç»“æœä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²"""
    successful = res["successful_analyses"]
    total = res["total_videos"]

    analysis_text = f"âœ… è§†é¢‘åˆ†æå®Œæˆï¼\n"
    analysis_text += f"ğŸ“Š æˆåŠŸåˆ†æ: {successful}/{total} ä¸ªè§†é¢‘\n"
    analysis_text += "=" * 50 + "\n\n"

    for i, result in enumerate(res["analysis_results"]):
        if "error" not in result:
            metadata = result.get("metadata", {})
            classification = result.get("classification", {})
            highlights = result.get("highlights", [])
            audio_analysis = result.get("audio_analysis", {})

            analysis_text += f"ğŸ“¹ è§†é¢‘ {i + 1}: {os.path.basename(result.get('file_path', ''))}\n"
            analysis_text += f"  â±ï¸ æ—¶é•¿: {metadata.get('duration', 0):.1f}ç§’\n"
            analysis_text += f"  ğŸ“º åˆ†è¾¨ç‡: {metadata.get('width', 0)}x{metadata.get('height', 0)}\n"
            analysis_text += f"  ğŸµ éŸ³é¢‘: {'âœ…' if metadata.get('has_audio') else 'âŒ'}\n"
            analysis_text += f"  ğŸ“Š å¸§ç‡: {metadata.get('fps', 0):.1f}fps\n"
            analysis_text += f"  ğŸ“¦ æ–‡ä»¶å¤§å°: {metadata.get('file_size_mb', 0):.2f}MB\n\n"

            # å†…å®¹åˆ†ç±»
            analysis_text += f"ğŸ­ å†…å®¹åˆ†æ:\n"
            analysis_text += f"  ğŸ“ å†…å®¹ç±»å‹: {classification.get('content_type', 'æœªçŸ¥')}\n"
            analysis_text += f"  ğŸ˜Š æƒ…ç»ªæ°›å›´: {classification.get('mood', 'æœªçŸ¥')}\n"
            analysis_text += f"  ğŸ¨ é£æ ¼ç±»å‹: {classification.get('style', 'æœªçŸ¥')}\n"
            analysis_text += f"  ğŸ·ï¸ æ ‡ç­¾: {', '.join(classification.get('tags', []))}\n\n"

            # éŸ³é¢‘è¯†åˆ«ç»“æœ
            if audio_analysis:
                transcription = audio_analysis.get('transcription', '')
                if transcription:
                    analysis_text += f"ğŸ¤ è¯­éŸ³è¯†åˆ«:\n"
                    # æˆªå–å‰200ä¸ªå­—ç¬¦é¿å…è¿‡é•¿
                    display_text = transcription[:200] + "..." if len(transcription) > 200 else transcription
                    analysis_text += f"  ğŸ“ æ–‡æœ¬: {display_text}\n"
                    analysis_text += f"  ğŸ“ æ–‡æœ¬é•¿åº¦: {len(transcription)}å­—ç¬¦\n\n"

            # ç²¾å½©ç‰‡æ®µ
            analysis_text += f"â­ ç²¾å½©ç‰‡æ®µ ({len(highlights)}ä¸ª):\n"
            for j, highlight in enumerate(highlights[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                start_time = highlight.get('start_time', 0)
                end_time = highlight.get('end_time', 0)
                reason = highlight.get('reason', 'æœªçŸ¥åŸå› ')
                confidence = highlight.get('confidence', 0)

                analysis_text += f"  {j}. {start_time:.1f}s - {end_time:.1f}s"
                analysis_text += f" (ç½®ä¿¡åº¦: {confidence:.2f})\n"
                analysis_text += f"     ğŸ’¡ åŸå› : {reason}\n"

            if len(highlights) > 5:
                analysis_text += f"  ... è¿˜æœ‰ {len(highlights) - 5} ä¸ªç²¾å½©ç‰‡æ®µ\n"

            # åœºæ™¯æ£€æµ‹
            scenes = result.get('scenes', [])
            if scenes:
                analysis_text += f"\nğŸ¬ åœºæ™¯æ£€æµ‹ ({len(scenes)}ä¸ªåœºæ™¯):\n"
                for j, scene in enumerate(scenes[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ªåœºæ™¯
                    start_time = scene.get('start_time', 0)
                    end_time = scene.get('end_time', 0)
                    analysis_text += f"  åœºæ™¯{j}: {start_time:.1f}s - {end_time:.1f}s\n"

                if len(scenes) > 3:
                    analysis_text += f"  ... è¿˜æœ‰ {len(scenes) - 3} ä¸ªåœºæ™¯\n"

            analysis_text += "\n" + "=" * 50 + "\n\n"
        else:
            # å¤„ç†åˆ†æå¤±è´¥çš„è§†é¢‘
            analysis_text += f"âŒ è§†é¢‘ {i + 1} åˆ†æå¤±è´¥:\n"
            analysis_text += f"  ğŸ“„ æ–‡ä»¶: {result.get('file_path', 'æœªçŸ¥')}\n"
            analysis_text += f"  ğŸ’¥ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\n\n"

    return analysis_text

# ==================== MCPå·¥å…·å®šä¹‰ ====================

@mcp.tool()
async def analyze_videos(
        video_paths: List[str],
        mode: str = "async"
) -> str:
    """
    æ™ºèƒ½åˆ†æè§†é¢‘å†…å®¹ï¼Œè¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œå†…å®¹ç‰¹å¾

    Args:
        video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–URLåˆ—è¡¨
        mode: æ‰§è¡Œæ¨¡å¼ï¼Œ'sync'åŒæ­¥æ‰§è¡Œï¼Œ'async'å¼‚æ­¥æ‰§è¡Œ

    Returns:
        åˆ†æç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    if not video_paths:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›è‡³å°‘ä¸€ä¸ªè§†é¢‘è·¯å¾„"

    # æ”¶é›†è§†é¢‘æ–‡ä»¶
    collected_videos = collect_video_files(video_paths)

    if not collected_videos:
        return f"âŒ é”™è¯¯: åœ¨æä¾›çš„è·¯å¾„ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶\næä¾›çš„è·¯å¾„: {video_paths}"

    res = await execute_task_async("analyze_videos_intelligent", {"video_paths": collected_videos}, mode)

    if mode == "sync":
        if isinstance(res, dict) and "analysis_results" in res:
            return format_analysis_results(res)
        else:
            return f"âŒ åˆ†æå¤±è´¥: {res.get('error', 'æœªçŸ¥é”™è¯¯')}"
    else:
        return f"âœ… è§†é¢‘åˆ†æä»»åŠ¡å·²æäº¤\nğŸ“‹ ä»»åŠ¡ID: {res['task_id']}\nğŸ” æ­£åœ¨åˆ†æ {len(collected_videos)} ä¸ªè§†é¢‘æ–‡ä»¶\n\nğŸ’¡ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥è¯¢ç»“æœï¼š\nget_task_result(task_id=\"{res['task_id']}\", remove=False)"


@mcp.tool()
async def get_task_result(
        task_id: str,
        remove: bool = False
) -> str:
    """
    è·å–å¼‚æ­¥ä»»åŠ¡ç»“æœ

    Args:
        task_id: ä»»åŠ¡ID
        remove: æ˜¯å¦ç§»é™¤ç»“æœ

    Returns:
        ä»»åŠ¡ç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    if not task_id:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›ä»»åŠ¡ID"

    with result_condition:
        if task_id not in results:
            return f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}\nå¯èƒ½å·²è¢«åˆ é™¤æˆ–ä»»åŠ¡IDé”™è¯¯\n\nğŸ’¡ ä½¿ç”¨ list_active_tasks() æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡"

        if remove:
            result = results.pop(task_id)
        else:
            result = results[task_id]

        task_status = result.get("status", "unknown")
        function_name = result.get("function_name", "unknown")

        if task_status == "completed":
            task_result = result.get("result", {})
            processing_time = result.get("processing_time", 0)

            result_text = f"âœ… ä»»åŠ¡å®Œæˆ: {task_id[:8]}...\n"
            result_text += f"ğŸ”§ åŠŸèƒ½: {function_name}\n"
            result_text += f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time}ç§’\n"
            result_text += "=" * 50 + "\n\n"

            # æ ¹æ®ä¸åŒåŠŸèƒ½æ˜¾ç¤ºä¸åŒçš„ç»“æœæ ¼å¼
            if function_name == "analyze_videos_intelligent":
                if isinstance(task_result, dict) and "analysis_results" in task_result:
                    # ä½¿ç”¨æ ¼å¼åŒ–å‡½æ•°æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                    result_text += format_analysis_results(task_result)
                else:
                    result_text += f"ğŸ“Š åŸå§‹åˆ†æç»“æœ:\n{json.dumps(task_result, indent=2, ensure_ascii=False)}"
            else:
                result_text += f"ğŸ“‹ ç»“æœ: {json.dumps(task_result, indent=2, ensure_ascii=False)}"

            return result_text

        elif task_status == "failed":
            error = result.get("error", "æœªçŸ¥é”™è¯¯")
            error_type = result.get("error_type", "Unknown")
            processing_time = result.get("processing_time", 0)
            traceback_info = result.get("traceback", "")

            error_text = f"âŒ ä»»åŠ¡å¤±è´¥: {task_id[:8]}...\n"
            error_text += f"ğŸ”§ åŠŸèƒ½: {function_name}\n"
            error_text += f"ğŸ’¥ é”™è¯¯: {error}\n"
            error_text += f"ğŸ·ï¸ é”™è¯¯ç±»å‹: {error_type}\n"
            error_text += f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time}ç§’\n"

            if traceback_info:
                error_text += f"\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback_info[-500:]}"  # åªæ˜¾ç¤ºæœ€å500å­—ç¬¦

            return error_text

        elif task_status == "processing":
            progress = result.get("progress", "æœªçŸ¥")
            current_step = result.get("current_step", "æœªçŸ¥")
            started_at = result.get("started_at", 0)
            elapsed = time.time() - started_at if started_at else 0

            return f"ğŸ”„ ä»»åŠ¡å¤„ç†ä¸­: {task_id[:8]}...\nğŸ”§ åŠŸèƒ½: {function_name}\nğŸ“Š è¿›åº¦: {progress}\nğŸ“ å½“å‰æ­¥éª¤: {current_step}\nâ±ï¸ å·²ç”¨æ—¶é—´: {elapsed:.1f}ç§’\n\nğŸ’¡ è¯·ç¨åå†æ¬¡æŸ¥è¯¢ç»“æœ"

        else:
            return f"â“ ä»»åŠ¡çŠ¶æ€æœªçŸ¥: {task_id[:8]}...\nğŸ”§ åŠŸèƒ½: {function_name}\nğŸ“Š çŠ¶æ€: {task_status}"


@mcp.tool()
async def list_active_tasks() -> str:
    """
    åˆ—å‡ºæ‰€æœ‰æ´»è·ƒçš„ä»»åŠ¡

    Returns:
        æ´»è·ƒä»»åŠ¡åˆ—è¡¨çš„å­—ç¬¦ä¸²æè¿°
    """
    with result_condition:
        if not results:
            return "ğŸ“‹ å½“å‰æ²¡æœ‰æ´»è·ƒçš„ä»»åŠ¡"

        task_list = []
        for task_id, result in results.items():
            status = result.get("status", "unknown")
            function_name = result.get("function_name", "unknown")
            started_at = result.get("started_at", 0)
            elapsed = time.time() - started_at if started_at else 0

            # çŠ¶æ€å›¾æ ‡
            status_icon = {
                "completed": "âœ…",
                "failed": "âŒ",
                "processing": "ğŸ”„"
            }.get(status, "â“")

            task_info = f"{status_icon} {task_id[:8]}... | {function_name} | {status}"

            if status == "processing":
                progress = result.get("progress", "")
                task_info += f" | {progress} | {elapsed:.1f}s"
            elif status in ["completed", "failed"]:
                processing_time = result.get("processing_time", 0)
                task_info += f" | {processing_time:.1f}s"

            task_list.append(task_info)

        task_text = f"ğŸ“‹ æ´»è·ƒä»»åŠ¡åˆ—è¡¨ ({len(results)} ä¸ª):\n\n"
        task_text += "\n".join(task_list)

        return task_text


@mcp.tool()
async def cleanup_temp_files() -> str:
    """
    æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç›®å½•

    Returns:
        æ¸…ç†ç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    cleanup_temp_dirs()
    return "ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆï¼\nå·²æ¸…ç†æ‰€æœ‰ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶å’Œä¸´æ—¶ç›®å½•ã€‚"


@mcp.tool()
async def get_server_info() -> str:
    """
    è·å–æœåŠ¡å™¨ä¿¡æ¯

    Returns:
        æœåŠ¡å™¨ä¿¡æ¯çš„å­—ç¬¦ä¸²æè¿°
    """
    return json.dumps({
        "server": "AI Video Editing MCP Server",
        "version": "1.0.0",
        "status": "running",
        "timestamp": time.time(),
        "active_tasks": len(results),
        "temp_dirs": len(temp_dirs),
        "supported_formats": [".mp4", ".avi", ".mov", ".mkv", ".wmv", ".flv", ".webm"]
    }, indent=2, ensure_ascii=False)


# ==================== FastAPIè·¯ç”± ====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›æœåŠ¡ä¿¡æ¯"""
    return {
        "service": "AI Video Editing MCP Server",
        "version": "1.0.0",
        "status": "running",
        "description": "AIè§†é¢‘å‰ªè¾‘æœåŠ¡å™¨ï¼Œæ”¯æŒæ™ºèƒ½åˆ†æå’Œå‰ªè¾‘",
        "sse_endpoint": "/sse",
        "mcp_tools": [
            "analyze_videos",
            "get_task_result",
            "list_active_tasks",
            "cleanup_temp_files",
            "get_server_info"
        ]
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "active_tasks": len(results),
        "temp_dirs": len(temp_dirs)
    }


@app.get("/tasks")
async def get_all_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€"""
    with result_condition:
        return {
            "total_tasks": len(results),
            "tasks": {
                task_id: {
                    "status": result.get("status"),
                    "function_name": result.get("function_name"),
                    "started_at": result.get("started_at"),
                    "processing_time": result.get("processing_time")
                }
                for task_id, result in results.items()
            }
        }


# ==================== æŒ‚è½½MCP SSEåº”ç”¨ ====================

# å°†MCPçš„SSEåº”ç”¨æŒ‚è½½åˆ°FastAPI
app.mount("/", mcp.sse_app())

# ==================== å¯åŠ¨é…ç½® ====================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="AI Video Editing MCP Server with SSE")
    parser.add_argument("--host", default="127.0.0.1", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind to")
    parser.add_argument("--reload", action="store_true", help="Enable auto-reload")
    parser.add_argument("--log-level", default="info", help="Log level")

    args = parser.parse_args()

    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print(f"""
ğŸ¬ AI Video Editing MCP Server with SSE
=======================================
ğŸŒ Host: {args.host}
ğŸ”Œ Port: {args.port}
ğŸ”„ Reload: {args.reload}
ğŸ“ Log Level: {args.log_level}

ğŸ“¡ SSE Endpoint: http://{args.host}:{args.port}/sse
ğŸ”— Connect URL: http://{args.host}:{args.port}/sse

ğŸ› ï¸ Available MCP Tools:
  ğŸ“¹ analyze_videos - æ™ºèƒ½è§†é¢‘åˆ†æ
  ğŸ“Š get_task_result - è·å–ä»»åŠ¡ç»“æœ
  ğŸ“ list_active_tasks - åˆ—å‡ºæ´»è·ƒä»»åŠ¡
  ğŸ—‘ï¸ cleanup_temp_files - æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  â„¹ï¸ get_server_info - è·å–æœåŠ¡å™¨ä¿¡æ¯

ğŸš€ Starting server...
    """)

    uvicorn.run(
        "ai_video_editing_mcp_sse:app",
        host=args.host,
        port=args.port,
        reload=args.reload,
        log_level=args.log_level
    )