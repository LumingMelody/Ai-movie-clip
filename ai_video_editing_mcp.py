# -*- coding: utf-8 -*-
# @Time    : 2025/6/14 13:55
# @Author  : è”é¸£éœ¸éœ¸
# @FileName: ai_video_editing_fastapi_mcp.py
# @Software: PyCharm
# @Blog    ï¼šåªå› ä½ å¤ªç¾

"""
AIè§†é¢‘å‰ªè¾‘FastAPI-MCPæœåŠ¡å™¨
é€šè¿‡è‡ªç„¶è¯­è¨€å¯¹è¯è¿›è¡Œè§†é¢‘åˆ†æå’Œå‰ªè¾‘
"""

import asyncio
import json
import logging
import os
import sys
import threading
import queue
import time
import uuid
import tempfile
import shutil
from typing import Any, Dict, List, Optional, Union
from threading import Condition

from fastapi import FastAPI, HTTPException
from fastmcp import FastMCP
import uvicorn

from core.ai.ai_model_caller import AIModelCaller
from core.analyzer.video_analyzer import VideoAnalyzer

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥è§†é¢‘å¤„ç†æ¨¡å—
try:


    from core.orchestrator.workflow_orchestrator import VideoEditingOrchestrator, create_orchestrator_from_analysis
except ImportError as e:
    print(f"è­¦å‘Š: å¯¼å…¥æ¨¡å—å¤±è´¥ {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æ¨¡å—éƒ½åœ¨æ­£ç¡®çš„è·¯å¾„ä¸­")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(title="AI Video Editing Server", version="1.0.0")
# åˆ›å»ºFastMCPå®ä¾‹
mcp = FastMCP(name="AI Video Editing MCP Server")
# å…¨å±€å˜é‡
task_queue = queue.Queue()
results = {}
result_condition = Condition()
temp_dirs = []  # å­˜å‚¨ä¸´æ—¶ç›®å½•ï¼Œç”¨äºæ¸…ç†


class VideoEditingError(Exception):
    """è‡ªå®šä¹‰å¼‚å¸¸ç±»"""
    pass


# ==================== æ ¸å¿ƒè§†é¢‘å¤„ç†åŠŸèƒ½ ====================

def get_api_key_from_file(file_name="api_key.txt"):
    """ä»æœ¬åœ°æ–‡ä»¶è¯»å–API Key"""
    try:
        base_path = os.path.abspath(os.path.dirname(__file__))
        file_path = os.path.join(base_path, file_name)

        if not os.path.exists(file_path):
            return None

        with open(file_path, "r", encoding="utf-8") as f:
            api_key = f.read().strip()

        return api_key if api_key else None
    except Exception as e:
        logger.error(f"è¯»å–API Keyå¤±è´¥: {e}")
        return None


def is_url(string: str) -> bool:
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæœ‰æ•ˆçš„URL"""
    import urllib.parse
    try:
        result = urllib.parse.urlparse(string)
        return all([result.scheme, result.netloc])
    except:
        return False


def download_video_from_url(url: str) -> str:
    """ä»URLä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶ç›®å½•"""
    try:
        import requests
        import urllib.parse

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp(prefix="ai_video_download_")
        temp_dirs.append(temp_dir)  # è®°å½•ç”¨äºæ¸…ç†

        # è·å–æ–‡ä»¶å
        parsed_url = urllib.parse.urlparse(url)
        filename = os.path.basename(parsed_url.path)
        if not filename or '.' not in filename:
            filename = f"downloaded_video_{int(time.time())}.mp4"

        output_path = os.path.join(temp_dir, filename)

        # ä¸‹è½½æ–‡ä»¶
        logger.info(f"æ­£åœ¨ä¸‹è½½è§†é¢‘: {url}")
        response = requests.get(url, stream=True, timeout=60)
        response.raise_for_status()

        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        logger.info(f"ä¸‹è½½å®Œæˆ: {output_path}")
        return output_path

    except Exception as e:
        raise VideoEditingError(f"ä¸‹è½½è§†é¢‘å¤±è´¥: {str(e)}")


def collect_video_files(paths: List[str]) -> List[str]:
    """æ”¶é›†è§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶å’ŒURL"""
    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm')
    video_files = []

    for path in paths:
        try:
            if is_url(path):
                # å¤„ç†URL
                if any(ext in path.lower() for ext in
                       video_extensions) or 'youtube' in path.lower() or 'bilibili' in path.lower():
                    try:
                        downloaded_path = download_video_from_url(path)
                        video_files.append(downloaded_path)
                        logger.info(f"æˆåŠŸä¸‹è½½è§†é¢‘: {path}")
                    except Exception as e:
                        logger.error(f"ä¸‹è½½å¤±è´¥: {path}, é”™è¯¯: {e}")
                        continue
                else:
                    logger.warning(f"ä¸æ”¯æŒçš„URLç±»å‹: {path}")

            elif os.path.isfile(path):
                # å¤„ç†æœ¬åœ°æ–‡ä»¶
                if path.lower().endswith(video_extensions):
                    video_files.append(path)
                    logger.info(f"æ‰¾åˆ°æœ¬åœ°è§†é¢‘: {path}")
                else:
                    logger.warning(f"è·³è¿‡éè§†é¢‘æ–‡ä»¶: {path}")

            elif os.path.isdir(path):
                # å¤„ç†ç›®å½•
                found_count = 0
                for file in os.listdir(path):
                    if file.lower().endswith(video_extensions):
                        video_files.append(os.path.join(path, file))
                        found_count += 1
                logger.info(f"ç›®å½•ä¸­æ‰¾åˆ° {found_count} ä¸ªè§†é¢‘æ–‡ä»¶: {path}")

            else:
                logger.warning(f"è·¯å¾„ä¸å­˜åœ¨: {path}")

        except Exception as e:
            logger.error(f"å¤„ç†è·¯å¾„ {path} æ—¶å‡ºé”™: {e}")

    return video_files


def cleanup_temp_dirs():
    """æ¸…ç†ä¸´æ—¶ç›®å½•"""
    global temp_dirs
    for temp_dir in temp_dirs:
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
        except Exception as e:
            logger.error(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
    temp_dirs.clear()


# ==================== ä»»åŠ¡å¤„ç†ç³»ç»Ÿ ====================

def process_task(task):
    """å¤„ç†ä»»åŠ¡çš„æ ¸å¿ƒå‡½æ•°"""
    task_id = task["task_id"]
    func_name = task["func_name"]
    args = task["args"]

    start_time = time.time()

    try:
        # è®¾ç½®åˆå§‹çŠ¶æ€
        with result_condition:
            results[task_id] = {
                "status": "processing",
                "started_at": start_time,
                "current_step": "å¼€å§‹æ‰§è¡Œ",
                "progress": "0%"
            }
            result_condition.notify_all()

        func = globals().get(func_name)
        if not func:
            raise VideoEditingError(f"Function {func_name} not found")

        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}, å‡½æ•°: {func_name}")

        # æ‰§è¡Œå®é™…ä»»åŠ¡
        result = func(**args)

        end_time = time.time()
        processing_time = round(end_time - start_time, 2)

        with result_condition:
            results[task_id] = {
                "status": "completed",
                "result": result,
                "timestamp": end_time,
                "started_at": start_time,
                "processing_time": processing_time,
                "function_name": func_name
            }
            result_condition.notify_all()

    except Exception as e:
        end_time = time.time()
        processing_time = round(end_time - start_time, 2)

        logger.error(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        error_traceback = traceback.format_exc()

        with result_condition:
            results[task_id] = {
                "status": "failed",
                "error": str(e),
                "error_type": type(e).__name__,
                "traceback": error_traceback,
                "timestamp": end_time,
                "started_at": start_time,
                "processing_time": processing_time,
                "function_name": func_name
            }
            result_condition.notify_all()


def worker():
    """åå°å·¥ä½œçº¿ç¨‹"""
    while True:
        task = task_queue.get()
        try:
            process_task(task)
        finally:
            task_queue.task_done()


# å¯åŠ¨å·¥ä½œçº¿ç¨‹
worker_thread = threading.Thread(target=worker, daemon=True)
worker_thread.start()


async def execute_task_async(func_name: str, args: dict, mode: str = "async"):
    """å¼‚æ­¥æ‰§è¡Œä»»åŠ¡"""
    task_id = str(uuid.uuid4())
    task_data = {
        "task_id": task_id,
        "func_name": func_name,
        "args": args
    }

    if mode == "sync":
        task_queue.put(task_data)
        timeout_seconds = 1800  # 30åˆ†é’Ÿè¶…æ—¶

        start_time = time.time()
        with result_condition:
            while True:
                elapsed_time = time.time() - start_time
                remaining_time = timeout_seconds - elapsed_time

                if remaining_time <= 0:
                    return {
                        "error": "ä»»åŠ¡æ‰§è¡Œè¶…æ—¶",
                        "timeout": True,
                        "task_id": task_id
                    }

                if task_id in results:
                    result = results[task_id]
                    if result["status"] in ["completed", "failed"]:
                        break

                result_condition.wait(timeout=min(10, remaining_time))

            final_result = results.pop(task_id)

        if final_result["status"] == "completed":
            return final_result["result"]
        elif final_result["status"] == "failed":
            raise VideoEditingError(final_result.get("error", "Unknown error occurred"))
    else:
        task_queue.put(task_data)
        return {"task_id": task_id}


# ==================== æ ¸å¿ƒè§†é¢‘å¤„ç†å‡½æ•° ====================

def analyze_videos_intelligent(video_paths: List[str]) -> Dict[str, Any]:
    """æ™ºèƒ½åˆ†æè§†é¢‘å†…å®¹"""
    logger.info(f"å¼€å§‹æ™ºèƒ½åˆ†æ {len(video_paths)} ä¸ªè§†é¢‘")

    try:
        analyzer = VideoAnalyzer()
    except Exception as e:
        raise VideoEditingError(f"æ— æ³•åˆ›å»ºè§†é¢‘åˆ†æå™¨: {e}")

    results = []

    for i, video_path in enumerate(video_paths):
        logger.info(f"åˆ†æè§†é¢‘ {i + 1}/{len(video_paths)}: {os.path.basename(video_path)}")

        try:
            result = analyzer.analyze_video(video_path)
            result['file_path'] = video_path
            results.append(result)

            # è¾“å‡ºåˆ†ææ‘˜è¦
            metadata = result.get('metadata', {})
            classification = result.get('classification', {})
            highlights = result.get('highlights', [])

            logger.info(f"  æ—¶é•¿: {metadata.get('duration', 0):.1f}ç§’")
            logger.info(f"  å†…å®¹ç±»å‹: {classification.get('content_type', 'æœªçŸ¥')}")
            logger.info(f"  ç²¾å½©ç‰‡æ®µ: {len(highlights)}ä¸ª")

        except Exception as e:
            logger.error(f"åˆ†æè§†é¢‘å¤±è´¥: {video_path}, é”™è¯¯: {e}")
            results.append({
                'file_path': video_path,
                'error': str(e),
                'status': 'failed'
            })

    return {
        "analysis_results": results,
        "total_videos": len(video_paths),
        "successful_analyses": len([r for r in results if 'error' not in r]),
        "failed_analyses": len([r for r in results if 'error' in r])
    }


def edit_videos_with_ai_strategy(video_paths: List[str], user_requirements: str,
                                 target_duration: int = 30, use_local_ai: bool = False) -> Dict[str, Any]:
    """ä½¿ç”¨AIç­–ç•¥å‰ªè¾‘è§†é¢‘"""
    logger.info(f"å¼€å§‹AIå‰ªè¾‘ {len(video_paths)} ä¸ªè§†é¢‘")
    logger.info(f"ç”¨æˆ·éœ€æ±‚: {user_requirements}")
    logger.info(f"ç›®æ ‡æ—¶é•¿: {target_duration}ç§’")

    # è·å–APIå¯†é’¥
    api_key = None
    if not use_local_ai:
        api_key = get_api_key_from_file()
        if not api_key:
            logger.warning("æ— æ³•è¯»å–APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°AIæ¨¡å¼")
            use_local_ai = True

    # è§£æç”¨æˆ·éœ€æ±‚ä¸ºç»“æ„åŒ–é€‰é¡¹
    user_options = parse_user_requirements(user_requirements, target_duration)

    try:
        # åˆ›å»ºå·¥ä½œæµç¨‹ç¼–æ’å™¨
        output_dir = tempfile.mkdtemp(prefix="ai_video_edit_")
        temp_dirs.append(output_dir)

        orchestrator = VideoEditingOrchestrator(
            video_files=video_paths,
            output_dir=output_dir
        )

        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
        result = orchestrator.run_complete_workflow(
            user_options=user_options,
            api_key=api_key,
            use_local_ai=use_local_ai,
            merge_videos=True
        )

        return result

    except Exception as e:
        raise VideoEditingError(f"AIå‰ªè¾‘å¤±è´¥: {str(e)}")


def edit_videos_from_analysis(analysis_file_path: str, user_requirements: str,
                              target_duration: int = 30, use_local_ai: bool = False) -> Dict[str, Any]:
    """ä»åˆ†æç»“æœæ–‡ä»¶è¿›è¡Œå‰ªè¾‘"""
    logger.info(f"ä½¿ç”¨åˆ†æç»“æœè¿›è¡Œå‰ªè¾‘: {analysis_file_path}")

    if not os.path.exists(analysis_file_path):
        raise VideoEditingError(f"åˆ†ææ–‡ä»¶ä¸å­˜åœ¨: {analysis_file_path}")

    # è·å–APIå¯†é’¥
    api_key = None
    if not use_local_ai:
        api_key = get_api_key_from_file()
        if not api_key:
            use_local_ai = True

    # è§£æç”¨æˆ·éœ€æ±‚
    user_options = parse_user_requirements(user_requirements, target_duration)

    try:
        # ä»åˆ†æç»“æœåˆ›å»ºç¼–æ’å™¨
        output_dir = tempfile.mkdtemp(prefix="ai_video_edit_from_analysis_")
        temp_dirs.append(output_dir)

        orchestrator = create_orchestrator_from_analysis(
            analysis_file_path,
            output_dir
        )

        # æ‰§è¡Œå‰ªè¾‘
        result = orchestrator.run_complete_workflow(
            user_options=user_options,
            api_key=api_key,
            use_local_ai=use_local_ai,
            merge_videos=True
        )

        return result

    except Exception as e:
        raise VideoEditingError(f"ä»åˆ†æç»“æœå‰ªè¾‘å¤±è´¥: {str(e)}")


def generate_ai_editing_strategy(video_analysis: Dict[str, Any], user_requirements: str,
                                 target_duration: int = 30) -> Dict[str, Any]:
    """ç”ŸæˆAIå‰ªè¾‘ç­–ç•¥ï¼ˆä¸æ‰§è¡Œå‰ªè¾‘ï¼‰"""
    logger.info("ç”ŸæˆAIå‰ªè¾‘ç­–ç•¥")

    # è·å–APIå¯†é’¥
    api_key = get_api_key_from_file()

    if not api_key:
        logger.warning("æ— æ³•è¯»å–APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°ç­–ç•¥ç”Ÿæˆ")
        return generate_local_strategy(video_analysis, user_requirements, target_duration)

    try:
        # ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆç­–ç•¥
        caller = AIModelCaller(api_key=api_key, model="qwen-plus")

        # æ„å»ºprompt
        prompt = build_strategy_prompt(video_analysis, user_requirements, target_duration)

        # ç”Ÿæˆç­–ç•¥
        strategy = caller.generate_editing_plan(prompt, use_local=False)

        return {
            "strategy": strategy,
            "strategy_type": "AIç”Ÿæˆ",
            "user_requirements": user_requirements,
            "target_duration": target_duration
        }

    except Exception as e:
        logger.error(f"AIç­–ç•¥ç”Ÿæˆå¤±è´¥: {e}")
        return generate_local_strategy(video_analysis, user_requirements, target_duration)


def parse_user_requirements(user_requirements: str, target_duration: int) -> Dict[str, Any]:
    """è§£æç”¨æˆ·éœ€æ±‚ä¸ºç»“æ„åŒ–é€‰é¡¹"""
    user_options = {
        "target_duration": target_duration,
        "target_style": "æ™ºèƒ½",
        "target_purpose": "é€šç”¨"
    }

    # ç®€å•çš„å…³é”®è¯åŒ¹é…
    requirements_lower = user_requirements.lower()

    # é£æ ¼è¯†åˆ«
    if any(word in requirements_lower for word in ["æŠ–éŸ³", "çŸ­è§†é¢‘", "ç«–å±"]):
        user_options["target_style"] = "æŠ–éŸ³é£"
    elif any(word in requirements_lower for word in ["ç”µå½±", "å½±é™¢", "æ¨ªå±"]):
        user_options["target_style"] = "ç”µå½±é£"
    elif any(word in requirements_lower for word in ["vlog", "ç”Ÿæ´»", "æ—¥å¸¸"]):
        user_options["target_style"] = "VLOGé£"

    # ç”¨é€”è¯†åˆ«
    if any(word in requirements_lower for word in ["è¥é”€", "æ¨å¹¿", "å®£ä¼ "]):
        user_options["target_purpose"] = "è¥é”€æ¨å¹¿"
    elif any(word in requirements_lower for word in ["æ•™å­¦", "æ•™è‚²", "å­¦ä¹ "]):
        user_options["target_purpose"] = "æ•™è‚²åŸ¹è®­"
    elif any(word in requirements_lower for word in ["å¨±ä¹", "æç¬‘", "è¶£å‘³"]):
        user_options["target_purpose"] = "å¨±ä¹å†…å®¹"

    return user_options


def build_strategy_prompt(video_analysis: Dict[str, Any], user_requirements: str, target_duration: int) -> str:
    """æ„å»ºAIç­–ç•¥ç”Ÿæˆçš„prompt"""
    analysis_summary = ""
    if isinstance(video_analysis, dict) and "analysis_results" in video_analysis:
        results = video_analysis["analysis_results"]
        analysis_summary = json.dumps(results, indent=2, ensure_ascii=False)
    else:
        analysis_summary = json.dumps(video_analysis, indent=2, ensure_ascii=False)

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘AIåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘åˆ†æç»“æœå’Œç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆè¯¦ç»†çš„å‰ªè¾‘ç­–ç•¥ã€‚

ã€è§†é¢‘åˆ†æç»“æœã€‘:
{analysis_summary}

ã€ç”¨æˆ·éœ€æ±‚ã€‘:
{user_requirements}

ã€ç›®æ ‡æ—¶é•¿ã€‘:
{target_duration}ç§’

è¯·è¾“å‡ºJSONæ ¼å¼çš„å‰ªè¾‘ç­–ç•¥ï¼ŒåŒ…å«å…·ä½“çš„å‰ªè¾‘æ“ä½œå’Œæ€è·¯è¯´æ˜ã€‚
"""
    return prompt


def generate_local_strategy(video_analysis: Dict[str, Any], user_requirements: str, target_duration: int) -> Dict[
    str, Any]:
    """ç”Ÿæˆæœ¬åœ°ç­–ç•¥ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    return {
        "strategy": {
            "actions": [
                {
                    "function": "cut",
                    "start": 0,
                    "end": target_duration,
                    "reason": f"æ ¹æ®ç”¨æˆ·éœ€æ±‚'{user_requirements}'è¿›è¡Œæ™ºèƒ½å‰ªåˆ‡"
                }
            ],
            "target_duration": target_duration,
            "metadata": {
                "description": f"æœ¬åœ°ç”Ÿæˆçš„å‰ªè¾‘ç­–ç•¥ï¼Œæ»¡è¶³ç”¨æˆ·éœ€æ±‚: {user_requirements}"
            }
        },
        "strategy_type": "æœ¬åœ°ç”Ÿæˆ",
        "user_requirements": user_requirements,
        "target_duration": target_duration
    }


# ==================== MCPå·¥å…·å®šä¹‰ ====================

@mcp.tool()
async def analyze_videos(
        video_paths: List[str],
        mode: str = "async"
) -> str:
    """
    æ™ºèƒ½åˆ†æè§†é¢‘å†…å®¹ï¼Œè¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œå†…å®¹ç‰¹å¾

    Args:
        video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–URLåˆ—è¡¨
        mode: æ‰§è¡Œæ¨¡å¼ï¼Œ'sync'åŒæ­¥æ‰§è¡Œï¼Œ'async'å¼‚æ­¥æ‰§è¡Œ

    Returns:
        åˆ†æç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    if not video_paths:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›è‡³å°‘ä¸€ä¸ªè§†é¢‘è·¯å¾„"

    # æ”¶é›†è§†é¢‘æ–‡ä»¶
    collected_videos = collect_video_files(video_paths)

    if not collected_videos:
        return f"âŒ é”™è¯¯: åœ¨æä¾›çš„è·¯å¾„ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶\næä¾›çš„è·¯å¾„: {video_paths}"

    res = await execute_task_async("analyze_videos_intelligent", {"video_paths": collected_videos}, mode)

    if mode == "sync":
        if isinstance(res, dict) and "analysis_results" in res:
            successful = res["successful_analyses"]
            total = res["total_videos"]

            analysis_text = f"âœ… è§†é¢‘åˆ†æå®Œæˆï¼\n"
            analysis_text += f"ğŸ“Š æˆåŠŸåˆ†æ: {successful}/{total} ä¸ªè§†é¢‘\n\n"

            for i, result in enumerate(res["analysis_results"]):
                if "error" not in result:
                    metadata = result.get("metadata", {})
                    classification = result.get("classification", {})
                    highlights = result.get("highlights", [])

                    analysis_text += f"ğŸ“¹ è§†é¢‘ {i + 1}: {os.path.basename(result.get('file_path', ''))}\n"
                    analysis_text += f"  â±ï¸ æ—¶é•¿: {metadata.get('duration', 0):.1f}ç§’\n"
                    analysis_text += f"  ğŸ“º åˆ†è¾¨ç‡: {metadata.get('width', 0)}x{metadata.get('height', 0)}\n"
                    analysis_text += f"  ğŸµ éŸ³é¢‘: {'âœ…' if metadata.get('has_audio') else 'âŒ'}\n"
                    analysis_text += f"  ğŸ­ å†…å®¹ç±»å‹: {classification.get('content_type', 'æœªçŸ¥')}\n"
                    analysis_text += f"  ğŸ˜Š æƒ…ç»ªæ°›å›´: {classification.get('mood', 'æœªçŸ¥')}\n"
                    analysis_text += f"  ğŸ¨ é£æ ¼ç±»å‹: {classification.get('style', 'æœªçŸ¥')}\n"
                    analysis_text += f"  â­ ç²¾å½©ç‰‡æ®µ: {len(highlights)}ä¸ª\n\n"

            return analysis_text
        else:
            return f"âŒ åˆ†æå¤±è´¥: {res.get('error', 'æœªçŸ¥é”™è¯¯')}"
    else:
        return f"âœ… è§†é¢‘åˆ†æä»»åŠ¡å·²æäº¤\nğŸ“‹ ä»»åŠ¡ID: {res['task_id']}\nğŸ” æ­£åœ¨åˆ†æ {len(collected_videos)} ä¸ªè§†é¢‘æ–‡ä»¶\nğŸ“± ä½¿ç”¨ get_task_result å·¥å…·æŸ¥è¯¢ç»“æœ"


@mcp.tool()
async def edit_videos_with_requirements(
        video_paths: List[str],
        user_requirements: str,
        target_duration: int = 30,
        use_local_ai: bool = False,
        mode: str = "async"
) -> str:
    """
    æ ¹æ®è‡ªç„¶è¯­è¨€éœ€æ±‚æ™ºèƒ½å‰ªè¾‘è§†é¢‘

    Args:
        video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–URLåˆ—è¡¨
        user_requirements: ç”¨æˆ·çš„å‰ªè¾‘éœ€æ±‚ï¼Œç”¨è‡ªç„¶è¯­è¨€æè¿°ï¼Œä¾‹å¦‚ï¼š'åˆ¶ä½œä¸€ä¸ª30ç§’çš„æŠ–éŸ³é£æ ¼çŸ­è§†é¢‘ï¼Œçªå‡ºäº§å“ç‰¹ç‚¹'
        target_duration: ç›®æ ‡è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        use_local_ai: æ˜¯å¦ä½¿ç”¨æœ¬åœ°AIï¼ˆä¸è°ƒç”¨åœ¨çº¿æ¨¡å‹ï¼‰
        mode: æ‰§è¡Œæ¨¡å¼ï¼Œ'sync'åŒæ­¥æ‰§è¡Œï¼Œ'async'å¼‚æ­¥æ‰§è¡Œ

    Returns:
        å‰ªè¾‘ç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    if not video_paths:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›è‡³å°‘ä¸€ä¸ªè§†é¢‘è·¯å¾„"

    if not user_requirements:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›ç”¨æˆ·éœ€æ±‚æè¿°"

    # æ”¶é›†è§†é¢‘æ–‡ä»¶
    collected_videos = collect_video_files(video_paths)

    if not collected_videos:
        return f"âŒ é”™è¯¯: åœ¨æä¾›çš„è·¯å¾„ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶\næä¾›çš„è·¯å¾„: {video_paths}"

    res = await execute_task_async("edit_videos_with_ai_strategy", {
        "video_paths": collected_videos,
        "user_requirements": user_requirements,
        "target_duration": target_duration,
        "use_local_ai": use_local_ai
    }, mode)

    if mode == "sync":
        if isinstance(res, dict) and res.get("status") == "success":
            result_text = f"ğŸ‰ AIè§†é¢‘å‰ªè¾‘å®Œæˆï¼\n\n"
            result_text += f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {res.get('output_video', 'æœªçŸ¥')}\n"
            result_text += f"ğŸ“Š æ–‡ä»¶å¤§å°: {res.get('file_size_mb', 0)}MB\n"
            result_text += f"â±ï¸ å¤„ç†æ—¶é—´: {res.get('processing_time', 0)}ç§’\n\n"

            video_info = res.get('video_info', {})
            result_text += f"ğŸ“¹ å¤„ç†è¯¦æƒ…:\n"
            result_text += f"  è¾“å…¥æ–‡ä»¶æ•°: {video_info.get('input_count', 1)}\n"
            result_text += f"  æœ€ç»ˆæ—¶é•¿: {video_info.get('duration', 0):.1f}ç§’\n"
            result_text += f"  åˆ†è¾¨ç‡: {video_info.get('resolution', 'æœªçŸ¥')}\n\n"
            result_text += f"ğŸ¯ ç”¨æˆ·éœ€æ±‚: {user_requirements}\n"
            result_text += f"ğŸ¤– AIæ¨¡å¼: {'æœ¬åœ°AI' if use_local_ai else 'åœ¨çº¿AI'}"

            return result_text
        else:
            return f"âŒ å‰ªè¾‘å¤±è´¥: {res.get('error', 'æœªçŸ¥é”™è¯¯')}"
    else:
        return f"ğŸ¬ AIè§†é¢‘å‰ªè¾‘ä»»åŠ¡å·²æäº¤\nğŸ“‹ ä»»åŠ¡ID: {res['task_id']}\nğŸ¯ ç”¨æˆ·éœ€æ±‚: {user_requirements}\nâ±ï¸ ç›®æ ‡æ—¶é•¿: {target_duration}ç§’\nğŸ¥ å¤„ç†è§†é¢‘: {len(collected_videos)}ä¸ª\nğŸ“± ä½¿ç”¨ get_task_result å·¥å…·æŸ¥è¯¢ç»“æœ"


@mcp.tool()
async def edit_from_analysis(
        analysis_file_path: str,
        user_requirements: str,
        target_duration: int = 30,
        use_local_ai: bool = False,
        mode: str = "async"
) -> str:
    """
    ä»å·²æœ‰çš„åˆ†æç»“æœè¿›è¡Œè§†é¢‘å‰ªè¾‘

    Args:
        analysis_file_path: åˆ†æç»“æœæ–‡ä»¶è·¯å¾„
        user_requirements: ç”¨æˆ·çš„å‰ªè¾‘éœ€æ±‚
        target_duration: ç›®æ ‡è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        use_local_ai: æ˜¯å¦ä½¿ç”¨æœ¬åœ°AI
        mode: æ‰§è¡Œæ¨¡å¼ï¼Œ'sync'åŒæ­¥æ‰§è¡Œï¼Œ'async'å¼‚æ­¥æ‰§è¡Œ

    Returns:
        å‰ªè¾‘ç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    if not analysis_file_path:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›åˆ†æç»“æœæ–‡ä»¶è·¯å¾„"

    if not user_requirements:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›ç”¨æˆ·éœ€æ±‚æè¿°"

    res = await execute_task_async("edit_videos_from_analysis", {
        "analysis_file_path": analysis_file_path,
        "user_requirements": user_requirements,
        "target_duration": target_duration,
        "use_local_ai": use_local_ai
    }, mode)

    if mode == "sync":
        if isinstance(res, dict) and res.get("status") == "success":
            result_text = f"ğŸ‰ åŸºäºåˆ†æç»“æœçš„å‰ªè¾‘å®Œæˆï¼\n\n"
            result_text += f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {res.get('output_video', 'æœªçŸ¥')}\n"
            result_text += f"ğŸ“Š æ–‡ä»¶å¤§å°: {res.get('file_size_mb', 0)}MB\n"
            result_text += f"â±ï¸ å¤„ç†æ—¶é—´: {res.get('processing_time', 0)}ç§’\n\n"
            result_text += f"ğŸ“‹ åˆ†ææ–‡ä»¶: {os.path.basename(analysis_file_path)}\n"
            result_text += f"ğŸ¯ ç”¨æˆ·éœ€æ±‚: {user_requirements}"

            return result_text
        else:
            return f"âŒ å‰ªè¾‘å¤±è´¥: {res.get('error', 'æœªçŸ¥é”™è¯¯')}"
    else:
        return f"ğŸ“‹ åŸºäºåˆ†æç»“æœçš„å‰ªè¾‘ä»»åŠ¡å·²æäº¤\nğŸ“‹ ä»»åŠ¡ID: {res['task_id']}\nğŸ“„ åˆ†ææ–‡ä»¶: {os.path.basename(analysis_file_path)}\nğŸ¯ ç”¨æˆ·éœ€æ±‚: {user_requirements}\nğŸ“± ä½¿ç”¨ get_task_result å·¥å…·æŸ¥è¯¢ç»“æœ"


@mcp.tool()
async def generate_editing_strategy(
        video_analysis: Dict[str, Any],
        user_requirements: str,
        target_duration: int = 30,
        mode: str = "sync"
) -> str:
    """
    ä»…ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼Œä¸æ‰§è¡Œå®é™…å‰ªè¾‘

    Args:
        video_analysis: è§†é¢‘åˆ†æç»“æœ
        user_requirements: ç”¨æˆ·éœ€æ±‚æè¿°
        target_duration: ç›®æ ‡æ—¶é•¿
        mode: æ‰§è¡Œæ¨¡å¼ï¼Œ'sync'åŒæ­¥æ‰§è¡Œï¼Œ'async'å¼‚æ­¥æ‰§è¡Œ

    Returns:
        ç­–ç•¥ç”Ÿæˆç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    if not video_analysis:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›è§†é¢‘åˆ†æç»“æœ"

    if not user_requirements:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›ç”¨æˆ·éœ€æ±‚æè¿°"

    res = await execute_task_async("generate_ai_editing_strategy", {
        "video_analysis": video_analysis,
        "user_requirements": user_requirements,
        "target_duration": target_duration
    }, mode)

    if mode == "sync":
        if isinstance(res, dict) and "strategy" in res:
            strategy_text = f"ğŸ§  AIå‰ªè¾‘ç­–ç•¥ç”Ÿæˆå®Œæˆï¼\n\n"
            strategy_text += f"ğŸ¯ ç”¨æˆ·éœ€æ±‚: {res.get('user_requirements', '')}\n"
            strategy_text += f"â±ï¸ ç›®æ ‡æ—¶é•¿: {res.get('target_duration', 0)}ç§’\n"
            strategy_text += f"ğŸ¤– ç­–ç•¥ç±»å‹: {res.get('strategy_type', 'æœªçŸ¥')}\n\n"

            strategy = res.get('strategy', {})
            actions = strategy.get('actions', [])

            strategy_text += f"ğŸ“‹ å‰ªè¾‘æ“ä½œ ({len(actions)}ä¸ª):\n"
            for i, action in enumerate(actions, 1):
                func = action.get('function', 'æœªçŸ¥')
                reason = action.get('reason', 'æ— è¯´æ˜')
                strategy_text += f"  {i}. {func}: {reason}\n"

            metadata = strategy.get('metadata', {})
            if 'description' in metadata:
                strategy_text += f"\nğŸ’¡ ç­–ç•¥è¯´æ˜: {metadata['description']}"

            return strategy_text
        else:
            return f"âŒ ç­–ç•¥ç”Ÿæˆå¤±è´¥: {res.get('error', 'æœªçŸ¥é”™è¯¯')}"
    else:
        return f"ğŸ§  ç­–ç•¥ç”Ÿæˆä»»åŠ¡å·²æäº¤\nğŸ“‹ ä»»åŠ¡ID: {res['task_id']}\nğŸ“± ä½¿ç”¨ get_task_result å·¥å…·æŸ¥è¯¢ç»“æœ"


@mcp.tool()
async def get_task_result(
        task_id: str,
        remove: bool = False
) -> str:
    """
    è·å–å¼‚æ­¥ä»»åŠ¡ç»“æœ

    Args:
        task_id: ä»»åŠ¡ID
        remove: æ˜¯å¦ç§»é™¤ç»“æœ

    Returns:
        ä»»åŠ¡ç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    if not task_id:
        return "âŒ é”™è¯¯: å¿…é¡»æä¾›ä»»åŠ¡ID"

    with result_condition:
        if task_id not in results:
            return f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}\nå¯èƒ½å·²è¢«åˆ é™¤æˆ–ä»»åŠ¡IDé”™è¯¯"

        if remove:
            result = results.pop(task_id)
        else:
            result = results[task_id]

        task_status = result.get("status", "unknown")
        function_name = result.get("function_name", "unknown")

        if task_status == "completed":
            task_result = result.get("result", {})
            processing_time = result.get("processing_time", 0)

            result_text = f"âœ… ä»»åŠ¡å®Œæˆ: {task_id[:8]}...\n"
            result_text += f"ğŸ”§ åŠŸèƒ½: {function_name}\n"
            result_text += f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time}ç§’\n\n"

            # æ ¹æ®ä¸åŒåŠŸèƒ½æ˜¾ç¤ºä¸åŒçš„ç»“æœæ ¼å¼
            if function_name == "analyze_videos_intelligent":
                if isinstance(task_result, dict) and "analysis_results" in task_result:
                    successful = task_result["successful_analyses"]
                    total = task_result["total_videos"]
                    result_text += f"ğŸ“Š åˆ†æç»“æœ: {successful}/{total} ä¸ªè§†é¢‘åˆ†ææˆåŠŸ"
                else:
                    result_text += f"ğŸ“Š åˆ†æç»“æœ: {json.dumps(task_result, indent=2, ensure_ascii=False)}"

            elif function_name in ["edit_videos_with_ai_strategy", "edit_videos_from_analysis"]:
                if isinstance(task_result, dict) and task_result.get("status") == "success":
                    result_text += f"ğŸ¬ å‰ªè¾‘å®Œæˆ!\n"
                    result_text += f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {task_result.get('output_video', 'æœªçŸ¥')}\n"
                    result_text += f"ğŸ“Š æ–‡ä»¶å¤§å°: {task_result.get('file_size_mb', 0)}MB"
                else:
                    result_text += f"âŒ å‰ªè¾‘å¤±è´¥: {task_result.get('error', 'æœªçŸ¥é”™è¯¯')}"

            elif function_name == "generate_ai_editing_strategy":
                if isinstance(task_result, dict) and "strategy" in task_result:
                    strategy = task_result.get('strategy', {})
                    actions = strategy.get('actions', [])
                    result_text += f"ğŸ§  ç­–ç•¥ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {len(actions)} ä¸ªå‰ªè¾‘æ“ä½œ"
                else:
                    result_text += f"ğŸ§  ç­–ç•¥ç»“æœ: {json.dumps(task_result, indent=2, ensure_ascii=False)}"

            else:
                result_text += f"ğŸ“‹ ç»“æœ: {json.dumps(task_result, indent=2, ensure_ascii=False)}"

            return result_text

        elif task_status == "failed":
            error = result.get("error", "æœªçŸ¥é”™è¯¯")
            error_type = result.get("error_type", "Unknown")
            processing_time = result.get("processing_time", 0)

            return f"âŒ ä»»åŠ¡å¤±è´¥: {task_id[:8]}...\nğŸ”§ åŠŸèƒ½: {function_name}\nğŸ’¥ é”™è¯¯: {error}\nğŸ·ï¸ é”™è¯¯ç±»å‹: {error_type}\nâ±ï¸ å¤„ç†æ—¶é—´: {processing_time}ç§’"

        elif task_status == "processing":
            progress = result.get("progress", "æœªçŸ¥")
            current_step = result.get("current_step", "æœªçŸ¥")
            started_at = result.get("started_at", 0)
            elapsed = time.time() - started_at if started_at else 0

            return f"ğŸ”„ ä»»åŠ¡å¤„ç†ä¸­: {task_id[:8]}...\nğŸ”§ åŠŸèƒ½: {function_name}\nğŸ“Š è¿›åº¦: {progress}\nğŸ“ å½“å‰æ­¥éª¤: {current_step}\nâ±ï¸ å·²ç”¨æ—¶é—´: {elapsed:.1f}ç§’"

        else:
            return f"â“ ä»»åŠ¡çŠ¶æ€æœªçŸ¥: {task_id[:8]}...\nğŸ”§ åŠŸèƒ½: {function_name}\nğŸ“Š çŠ¶æ€: {task_status}"


@mcp.tool()
async def list_active_tasks() -> str:
    """
    åˆ—å‡ºæ‰€æœ‰æ´»è·ƒçš„ä»»åŠ¡

    Returns:
        æ´»è·ƒä»»åŠ¡åˆ—è¡¨çš„å­—ç¬¦ä¸²æè¿°
    """
    with result_condition:
        if not results:
            return "ğŸ“‹ å½“å‰æ²¡æœ‰æ´»è·ƒçš„ä»»åŠ¡"

        task_list = []
        for task_id, result in results.items():
            status = result.get("status", "unknown")
            function_name = result.get("function_name", "unknown")
            started_at = result.get("started_at", 0)
            elapsed = time.time() - started_at if started_at else 0

            # çŠ¶æ€å›¾æ ‡
            status_icon = {
                "completed": "âœ…",
                "failed": "âŒ",
                "processing": "ğŸ”„"
            }.get(status, "â“")

            task_info = f"{status_icon} {task_id[:8]}... | {function_name} | {status}"

            if status == "processing":
                progress = result.get("progress", "")
                task_info += f" | {progress} | {elapsed:.1f}s"
            elif status in ["completed", "failed"]:
                processing_time = result.get("processing_time", 0)
                task_info += f" | {processing_time:.1f}s"

            task_list.append(task_info)

        task_text = f"ğŸ“‹ æ´»è·ƒä»»åŠ¡åˆ—è¡¨ ({len(results)} ä¸ª):\n\n"
        task_text += "\n".join(task_list)

        return task_text


@mcp.tool()
async def cleanup_temp_files() -> str:
    """
    æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç›®å½•

    Returns:
        æ¸…ç†ç»“æœçš„å­—ç¬¦ä¸²æè¿°
    """
    cleanup_temp_dirs()
    return "ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆï¼\nå·²æ¸…ç†æ‰€æœ‰ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶å’Œä¸´æ—¶ç›®å½•ã€‚"


# ==================== FastAPIè·¯ç”± ====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›æœåŠ¡ä¿¡æ¯"""
    return {
        "service": "AI Video Editing Server",
        "version": "1.0.0",
        "status": "running",
        "description": "AIè§†é¢‘å‰ªè¾‘æœåŠ¡å™¨ï¼Œæ”¯æŒæ™ºèƒ½åˆ†æå’Œå‰ªè¾‘"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "active_tasks": len(results),
        "temp_dirs": len(temp_dirs)
    }


@app.get("/tasks")
async def get_all_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€"""
    with result_condition:
        return {
            "total_tasks": len(results),
            "tasks": {
                task_id: {
                    "status": result.get("status"),
                    "function_name": result.get("function_name"),
                    "started_at": result.get("started_at"),
                    "processing_time": result.get("processing_time")
                }
                for task_id, result in results.items()
            }
        }


# ==================== å¯åŠ¨é…ç½® ====================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="AI Video Editing FastAPI-MCP Server")
    parser.add_argument("--host", default="0.0.0.0", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind to")
    parser.add_argument("--reload", action="store_true", help="Enable auto-reload")
    parser.add_argument("--log-level", default="info", help="Log level")

    args = parser.parse_args()

    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print(f"""
ğŸ¬ AI Video Editing FastAPI-MCP Server
=====================================
ğŸŒ Host: {args.host}
ğŸ”Œ Port: {args.port}
ğŸ”„ Reload: {args.reload}
ğŸ“ Log Level: {args.log_level}
ğŸš€ Starting server...
    """)

    uvicorn.run(
        "ai_video_editing_mcp:app",
        host=args.host,
        port=args.port,
        reload=args.reload,
        log_level=args.log_level
    )