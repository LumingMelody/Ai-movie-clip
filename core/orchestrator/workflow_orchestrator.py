# orchestrator/workflow_orchestrator.py - é‡æ„ç‰ˆæœ¬
# -*- coding: utf-8 -*-
"""
è§†é¢‘å‰ªè¾‘å·¥ä½œæµç¨‹ç¼–æ’å™¨ - é‡æ„ç‰ˆæœ¬
åŠŸèƒ½ï¼šåè°ƒè§†é¢‘åˆ†æã€AIç­–ç•¥ç”Ÿæˆå’Œè§†é¢‘å‰ªè¾‘çš„å®Œæ•´æµç¨‹
"""

import json
import os
import time
from typing import Dict, Any, List, Optional

from moviepy import VideoFileClip, concatenate_videoclips

from core.ai.ai_model_caller import AIModelCaller
from core.utils.config_manager import config, ErrorHandler, PathHelper
from core.utils.video_utils import video_processor

# è®¾ç½®Pythonè·¯å¾„
config.setup_python_path()

print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"é¡¹ç›®è·¯å¾„ä¿¡æ¯: {config.get_project_paths()}")


class VideoEditingOrchestrator:
    """è§†é¢‘å‰ªè¾‘å·¥ä½œæµç¨‹ç¼–æ’å™¨ - é‡æ„ç‰ˆæœ¬"""

    def __init__(self, video_files: List[str], output_dir: str = None, analysis_results: List[Dict] = None):
        self.video_files = video_files
        self.output_dir = output_dir or config.video_config['default_output_dir']
        self.analysis_results = analysis_results or []
        self.editing_strategies = []
        self.start_time = None
        self.video_config = config.get_config('video')
        self.output_config = config.get_config('output')

        # å¯¼å…¥è½¬åœºå’Œç‰¹æ•ˆæ¨¡å—
        self._import_effects_modules()

    def _import_effects_modules(self):
        """å¯¼å…¥è½¬åœºå’Œç‰¹æ•ˆæ¨¡å—"""
        try:
            from core.clipeffects.easy_clip_effects import vignette
            self.effects = {'vignette': vignette}
            ErrorHandler.log_success("æˆåŠŸå¯¼å…¥ç‰¹æ•ˆæ¨¡å—")
        except ImportError as e:
            ErrorHandler.handle_import_error("ç‰¹æ•ˆæ¨¡å—", e, "ä½¿ç”¨åŸºç¡€åŠŸèƒ½")
            self.effects = {}

    def run_complete_workflow(self, user_options: Dict[str, Any] = None, api_key: str = None,
                              use_local_ai: bool = False, merge_videos: bool = True):
        """è¿è¡Œå®Œæ•´çš„å‰ªè¾‘å·¥ä½œæµç¨‹"""
        workflow_steps = [
            ("è§†é¢‘è¯†åˆ«ä¸é¢„å¤„ç†", self._step1_video_identification),
            ("å†…å®¹åˆ†æä¸åˆ†ç±»", self._step2_content_analysis_wrapper),
            ("å‰ªè¾‘ç­–ç•¥ç”Ÿæˆ", lambda: self._step3_generate_editing_strategy(user_options, api_key, use_local_ai)),
            ("æ‰§è¡Œå‰ªè¾‘æ“ä½œ", self._step4_execute_editing),
            ("è¾“å‡ºæœ€ç»ˆè§†é¢‘", lambda edited_clips: self._step5_output_final_video(edited_clips, merge_videos))
        ]
        
        return self._execute_workflow_steps(workflow_steps)
    
    def _execute_workflow_steps(self, steps: List[tuple]) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµç¨‹æ­¥éª¤"""
        self.start_time = time.time()
        print("ğŸš€ å¼€å§‹AIè§†é¢‘è‡ªåŠ¨å‰ªè¾‘æµç¨‹...")
        
        try:
            results = {}
            
            # æ‰§è¡Œå‰4ä¸ªæ­¥éª¤
            for i, (step_name, step_func) in enumerate(steps[:-1]):
                print(f"\nğŸ“‹ æ­¥éª¤{i+1}: {step_name}")
                if i == 0:
                    results['processed_videos'] = step_func()
                elif i == 1:
                    step_func()  # åˆ†ææ­¥éª¤
                elif i == 2:
                    step_func()  # ç­–ç•¥ç”Ÿæˆæ­¥éª¤
                elif i == 3:
                    results['edited_clips'] = step_func()
            
            # éªŒè¯å‰ªè¾‘ç»“æœ
            edited_clips = [clip for clip in results['edited_clips'] if clip is not None]
            if not edited_clips:
                raise ValueError("æ‰€æœ‰å‰ªè¾‘å†…å®¹å‡ä¸ºNoneï¼Œæ— æ³•ç”Ÿæˆè§†é¢‘")
            
            # æ‰§è¡Œæœ€åæ­¥éª¤ï¼ˆè¾“å‡ºï¼‰
            final_step_name, final_step_func = steps[-1]
            print(f"\nğŸ“‹ æ­¥éª¤5: {final_step_name}")
            final_result = final_step_func(edited_clips)
            
            # æ·»åŠ å¤„ç†æ—¶é—´
            processing_time = time.time() - self.start_time
            final_result["processing_time"] = round(processing_time, 2)
            
            return final_result
            
        except Exception as e:
            return self._handle_workflow_error(e)

    def _step1_video_identification(self):
        """æ­¥éª¤1: è§†é¢‘æ•°é‡è¯†åˆ«ä¸é¢„å¤„ç†"""
        video_count = len(self.video_files)
        if video_count == 1:
            print(f"  å•ä¸ªè§†é¢‘: {os.path.basename(self.video_files[0])}")
        else:
            print(f"  å¤šä¸ªè§†é¢‘: {video_count}ä¸ªæ–‡ä»¶")
        return self.video_files
    
    def _step2_content_analysis_wrapper(self):
        """æ­¥éª¤2åŒ…è£…å™¨: å†…å®¹åˆ†æä¸åˆ†ç±»"""
        if not self.analysis_results:
            print("\nğŸ” æ²¡æœ‰æä¾›åˆ†æç»“æœï¼Œå¼€å§‹é‡æ–°åˆ†æ...")
            self._step2_content_analysis()
        else:
            print(f"\nâœ… ä½¿ç”¨ç°æœ‰åˆ†æç»“æœ ({len(self.analysis_results)} ä¸ªè§†é¢‘)")
            self._print_existing_analysis()
    
    def _handle_workflow_error(self, error: Exception) -> Dict[str, Any]:
        """å¤„ç†å·¥ä½œæµç¨‹é”™è¯¯"""
        ErrorHandler.handle_api_error("å·¥ä½œæµç¨‹", error)
        import traceback
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return {
            "status": "failed",
            "error": str(error),
            "processing_time": time.time() - self.start_time if self.start_time else 0
        }

    def _print_existing_analysis(self):
        """æ‰“å°ç°æœ‰åˆ†æç»“æœçš„æ‘˜è¦"""
        for i, analysis in enumerate(self.analysis_results):
            video_name = os.path.basename(analysis.get('file_path', f'è§†é¢‘{i + 1}'))
            classification = analysis.get('classification', {})
            metadata = analysis.get('metadata', {})

            print(f"  ğŸ“¹ {video_name}")
            print(f"    æ—¶é•¿: {metadata.get('duration', 0):.1f}ç§’")
            print(f"    å†…å®¹ç±»å‹: {classification.get('content_type', 'æœªçŸ¥')}")

    def _step2_content_analysis(self):
        """æ­¥éª¤2: å†…å®¹åˆ†æä¸åˆ†ç±»åˆ¤æ–­"""
        analyzer = self._import_video_analyzer()
        
        for video_path in self.video_files:
            print(f"  åˆ†æè§†é¢‘: {os.path.basename(video_path)}")
            analysis_result = analyzer.analyze_video(video_path)
            self.analysis_results.append(analysis_result)
            
            classification = analysis_result.get('classification', {})
            print(f"    å†…å®¹ç±»å‹: {classification.get('content_type', 'æœªçŸ¥')}")
    
    def _import_video_analyzer(self):
        """å¯¼å…¥è§†é¢‘åˆ†æå™¨"""
        import_attempts = [
            ('analyzer.video_analyzer', lambda: __import__('analyzer.video_analyzer', fromlist=['VideoAnalyzer']).VideoAnalyzer()),
            ('core.analyzer.video_analyzer', lambda: __import__('core.analyzer.video_analyzer', fromlist=['VideoAnalyzer']).VideoAnalyzer()),
        ]
        
        for import_path, import_func in import_attempts:
            try:
                print(f"    å°è¯•å¯¼å…¥: {import_path}")
                analyzer = import_func()
                ErrorHandler.log_success(f"æˆåŠŸå¯¼å…¥: {import_path}")
                return analyzer
            except ImportError as e:
                ErrorHandler.handle_import_error(import_path, e)
                continue
        
        raise ImportError("æ— æ³•æ‰¾åˆ° VideoAnalyzer")

    def _step3_generate_editing_strategy(self, user_options: Dict[str, Any], api_key: str, use_local_ai: bool):
        """æ­¥éª¤3: ç­–ç•¥ç”Ÿæˆ"""
        user_options = self._prepare_user_options(user_options)
        
        for i, analysis in enumerate(self.analysis_results):
            print(f"  ä¸ºè§†é¢‘ {i + 1} ç”Ÿæˆç­–ç•¥...")
            strategy = self._generate_single_strategy(analysis, user_options, api_key, use_local_ai)
            self.editing_strategies.append(strategy)
            
            actions = strategy.get('actions', [])
            print(f"    ğŸ“Š ç­–ç•¥ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {len(actions)} ä¸ªæ“ä½œ")
    
    def _prepare_user_options(self, user_options: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡ç”¨æˆ·é€‰é¡¹"""
        default_options = {
            "target_duration": self.video_config['default_target_duration'],
            "target_style": "æŠ–éŸ³é£",
            "target_purpose": "ç¤¾äº¤åª’ä½“"
        }
        return {**default_options, **(user_options or {})}
    
    def _generate_single_strategy(self, analysis: Dict[str, Any], user_options: Dict[str, Any], 
                                api_key: str, use_local_ai: bool) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªè§†é¢‘ç”Ÿæˆç­–ç•¥"""
        if use_local_ai or not api_key:
            if not api_key:
                ErrorHandler.log_warning("æœªæä¾›API keyï¼Œä½¿ç”¨æœ¬åœ°ç­–ç•¥")
            return self._generate_local_strategy(analysis, user_options)
        
        print(f"    ğŸ¤– ä½¿ç”¨AIç­–ç•¥ç”Ÿæˆ")
        return self._generate_ai_multi_segment_strategy(analysis, user_options, api_key)
    
    def _generate_local_strategy(self, analysis: Dict[str, Any], user_options: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ¬åœ°ç­–ç•¥"""
        # ç®€åŒ–çš„æœ¬åœ°ç­–ç•¥ç”Ÿæˆé€»è¾‘
        target_duration = user_options.get('target_duration', 30)
        return {
            "target_duration": target_duration,
            "strategy_type": "single_segment",
            "actions": [{
                "function": "cut",
                "start": 0,
                "end": target_duration,
                "reason": "æœ¬åœ°ç­–ç•¥ç®€å•å‰ªè¾‘"
            }],
            "metadata": {
                "source": "local",
                "confidence": 0.6
            }
        }

    def _generate_ai_multi_segment_strategy(self, analysis: Dict[str, Any], user_options: Dict[str, Any],
                                            api_key: str) -> Dict[str, Any]:
        """ä½¿ç”¨AIç”Ÿæˆç­–ç•¥"""
        try:
            prompt = self._build_enhanced_prompt(analysis, user_options)
            ai_caller = AIModelCaller(api_key=api_key)
            strategy = ai_caller.generate_editing_plan(prompt, use_local=False)

            if strategy.get('strategy_type') in ['multi_segment', 'single_segment']:
                print("    âœ… AIç­–ç•¥ç”ŸæˆæˆåŠŸ")
                return strategy
            else:
                print("    âŒ AIç­–ç•¥æ ¼å¼ä¸ç¬¦ï¼Œç”Ÿæˆå¤±è´¥")
                raise Exception("AIç­–ç•¥æ ¼å¼æ— æ•ˆ")

        except Exception as e:
            print(f"    âŒ AIç­–ç•¥ç”Ÿæˆå¤±è´¥: {e}")
            raise Exception(f"AIç­–ç•¥ç”Ÿæˆå¤±è´¥: {e}")

    def _build_enhanced_prompt(self, analysis: Dict[str, Any], user_options: Dict[str, Any]) -> str:
        """æ„å»ºAIæç¤ºè¯"""
        metadata = analysis.get('metadata', {})
        classification = analysis.get('classification', {})

        simplified_input = {
            "metadata": {
                "duration": metadata.get('duration', 0),
                "content_type": classification.get('content_type', ''),
                "has_audio": metadata.get('has_audio', True)
            }
        }

        user_requirements = {
            "target_duration": user_options.get('target_duration', 30),
            "target_style": user_options.get('target_style', 'æŠ–éŸ³é£'),
            "target_purpose": user_options.get('target_purpose', 'ç¤¾äº¤åª’ä½“')
        }

        prompt = f"""è¯·ä¸ºä»¥ä¸‹è§†é¢‘ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ï¼š

è§†é¢‘ä¿¡æ¯ï¼š
æ—¶é•¿: {simplified_input['metadata']['duration']:.1f}ç§’
å†…å®¹ç±»å‹: {simplified_input['metadata']['content_type']}

ç”¨æˆ·éœ€æ±‚ï¼š
ç›®æ ‡æ—¶é•¿: {user_requirements['target_duration']}ç§’
é£æ ¼: {user_requirements['target_style']}
ç”¨é€”: {user_requirements['target_purpose']}

è¯·ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ã€‚"""

        return prompt

    def _step4_execute_editing(self):
        """æ­¥éª¤4: æ‰§è¡Œå‰ªè¾‘æ“ä½œ"""
        edited_clips = []
        
        for i, (video_path, strategy) in enumerate(zip(self.video_files, self.editing_strategies)):
            print(f"  å‰ªè¾‘è§†é¢‘ {i + 1}: {os.path.basename(video_path)}")
            
            try:
                final_clip = self._safe_video_editing(video_path, strategy)
                edited_clips.append(final_clip)
                print(f"    âœ… å®Œæˆå‰ªè¾‘ï¼Œæœ€ç»ˆæ—¶é•¿: {final_clip.duration:.1f}ç§’")
            except Exception as e:
                ErrorHandler.handle_file_error("å‰ªè¾‘", video_path, e)
                # å¯ä»¥é€‰æ‹©ç»§ç»­æˆ–æŠ›å‡ºå¼‚å¸¸
                raise
        
        return edited_clips

    def _safe_video_editing(self, video_path: str, strategy: Dict[str, Any]):
        """å®‰å…¨çš„è§†é¢‘å‰ªè¾‘æ–¹æ³•"""
        print(f"    ğŸ“¥ å®‰å…¨åŠ è½½è§†é¢‘: {os.path.basename(video_path)}")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„è§†é¢‘å¤„ç†å™¨åŠ è½½è§†é¢‘
        clip, has_audio = video_processor.safe_load_video(video_path)
        if clip is None:
            raise ValueError(f"æ— æ³•åŠ è½½è§†é¢‘: {video_path}")
        
        try:
            actions = strategy.get('actions', [])
            strategy_type = strategy.get('strategy_type', 'single_segment')
            
            print(f"    ğŸ“‹ ç­–ç•¥ç±»å‹: {strategy_type}")
            print(f"    ğŸ“‹ æ“ä½œæ•°é‡: {len(actions)}")
            
            # æ ¹æ®ç­–ç•¥ç±»å‹å¤„ç†
            if strategy_type == 'multi_segment':
                return self._execute_multi_segment_strategy_safe(clip, actions, has_audio)
            else:
                return self._execute_single_segment_strategy(clip, actions, has_audio)
        
        except Exception as e:
            clip.close()
            raise e

    def _execute_single_segment_strategy(self, clip, actions, has_audio):
        """æ‰§è¡Œå•ç‰‡æ®µç­–ç•¥ - å®Œå…¨å®‰å…¨ç‰ˆæœ¬"""
        print(f"    âœ‚ï¸ æ‰§è¡Œå•ç‰‡æ®µç­–ç•¥")

        # æŸ¥æ‰¾cutæ“ä½œ
        cut_actions = [a for a in actions if a.get('function') == 'cut']

        if not cut_actions:
            print(f"    âš ï¸ æ²¡æœ‰æ‰¾åˆ°cutæ“ä½œï¼Œä½¿ç”¨åŸè§†é¢‘")
            return clip

        # æ‰§è¡Œç¬¬ä¸€ä¸ªcutæ“ä½œ
        action = cut_actions[0]
        start = action.get('start', 0)
        end = action.get('end', clip.duration)

        # ç¡®ä¿æ—¶é—´èŒƒå›´æœ‰æ•ˆ
        start = max(0, start)
        end = min(end, clip.duration)

        print(f"    ğŸ”§ æ‰§è¡Œå‰ªè¾‘: {start:.1f}s - {end:.1f}s (æ—¶é•¿: {end - start:.1f}s)")

        if start < end and (end - start) > 0.5:
            try:
                # ğŸ”¥ å…³é”®ä¿®å¤3: å…ˆå¤„ç†è§†é¢‘ï¼Œå†å®‰å…¨å¤„ç†éŸ³é¢‘
                if has_audio:
                    try:
                        # æ–¹æ³•1: å°è¯•åŒæ—¶å‰ªè¾‘è§†é¢‘å’ŒéŸ³é¢‘
                        clipped = clip.subclipped(start, end)

                        # ğŸ”¥ å…³é”®ä¿®å¤4: éªŒè¯éŸ³é¢‘å‰ªè¾‘æ˜¯å¦æˆåŠŸ
                        if clipped.audio is not None:
                            try:
                                # æµ‹è¯•éŸ³é¢‘æ˜¯å¦å¯ç”¨
                                _ = clipped.audio.duration
                                print(f"    âœ… å•ç‰‡æ®µå‰ªè¾‘æˆåŠŸ (å«éŸ³é¢‘): {clipped.duration:.1f}s")
                                return clipped
                            except Exception as audio_error:
                                print(f"    âš ï¸ éŸ³é¢‘å‰ªè¾‘åä¸å¯ç”¨ï¼Œç§»é™¤éŸ³é¢‘: {audio_error}")
                                clipped = clipped.without_audio()

                        print(f"    âœ… å•ç‰‡æ®µå‰ªè¾‘æˆåŠŸ (æ— éŸ³é¢‘): {clipped.duration:.1f}s")
                        return clipped

                    except Exception as e:
                        print(f"    âš ï¸ å«éŸ³é¢‘å‰ªè¾‘å¤±è´¥ï¼Œå°è¯•æ— éŸ³é¢‘å‰ªè¾‘: {e}")
                        # æ–¹æ³•2: å¦‚æœéŸ³é¢‘å‰ªè¾‘å¤±è´¥ï¼Œå…ˆç§»é™¤éŸ³é¢‘å†å‰ªè¾‘
                        video_only = clip.without_audio()
                        clipped = video_only.subclipped(start, end)
                        print(f"    âœ… å•ç‰‡æ®µå‰ªè¾‘æˆåŠŸ (æ— éŸ³é¢‘å¤‡ç”¨æ–¹æ¡ˆ): {clipped.duration:.1f}s")
                        return clipped
                else:
                    # æ— éŸ³é¢‘ï¼Œç›´æ¥å‰ªè¾‘
                    clipped = clip.subclipped(start, end)
                    print(f"    âœ… å•ç‰‡æ®µå‰ªè¾‘æˆåŠŸ (æ— éŸ³é¢‘): {clipped.duration:.1f}s")
                    return clipped

            except Exception as e:
                print(f"    âŒ å‰ªè¾‘æ“ä½œå¤±è´¥: {e}")
                print(f"    ğŸ”„ ä½¿ç”¨åŸè§†é¢‘ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
                return clip.without_audio() if has_audio else clip
        else:
            print(f"    âš ï¸ å‰ªè¾‘èŒƒå›´æ— æ•ˆï¼Œä½¿ç”¨åŸè§†é¢‘")
            return clip.without_audio() if has_audio else clip

    def _execute_multi_segment_strategy_safe(self, clip, actions, has_audio):
        """æ‰§è¡Œå¤šç‰‡æ®µç­–ç•¥ - å®Œå…¨å®‰å…¨ç‰ˆæœ¬"""
        print(f"    ğŸ¬ æ‰§è¡Œå¤šç‰‡æ®µç­–ç•¥")

        # æå–æ‰€æœ‰extract_segmentæ“ä½œ
        extract_actions = [a for a in actions if a.get('action') == 'extract_segment']

        if not extract_actions:
            print(f"    âš ï¸ æ²¡æœ‰æ‰¾åˆ°extract_segmentæ“ä½œï¼Œä½¿ç”¨åŸè§†é¢‘")
            return clip.without_audio() if has_audio else clip

        print(f"    ğŸ”ª æ‰¾åˆ° {len(extract_actions)} ä¸ªç‰‡æ®µè¦æå–:")

        segment_clips = []

        try:
            for i, action in enumerate(extract_actions):
                start = action.get('start', 0)
                end = action.get('end', clip.duration)
                reason = action.get('reason', f'ç‰‡æ®µ{i + 1}')

                # ç¡®ä¿æ—¶é—´èŒƒå›´æœ‰æ•ˆ
                start = max(0, start)
                end = min(end, clip.duration)

                print(f"      {i + 1}. æå– {start:.1f}s - {end:.1f}s ({end - start:.1f}s) - {reason}")

                if start < end and (end - start) > 0.5:
                    try:
                        # ğŸ”¥ å…³é”®ä¿®å¤5: å¯¹å¤šç‰‡æ®µä¹Ÿåº”ç”¨å®‰å…¨çš„éŸ³é¢‘å¤„ç†
                        if has_audio:
                            try:
                                subclipped = clip.subclipped(start, end)
                                # éªŒè¯éŸ³é¢‘
                                if subclipped.audio is not None:
                                    _ = subclipped.audio.duration
                                segment_clips.append(subclipped)
                                print(f"        âœ… ç‰‡æ®µ{i + 1}æå–æˆåŠŸ (å«éŸ³é¢‘): {subclipped.duration:.1f}s")
                            except Exception as audio_error:
                                print(f"        âš ï¸ ç‰‡æ®µ{i + 1}éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨æ— éŸ³é¢‘ç‰ˆæœ¬: {audio_error}")
                                subclipped = clip.without_audio().subclipped(start, end)
                                segment_clips.append(subclipped)
                                print(f"        âœ… ç‰‡æ®µ{i + 1}æå–æˆåŠŸ (æ— éŸ³é¢‘): {subclipped.duration:.1f}s")
                        else:
                            subclipped = clip.subclipped(start, end)
                            segment_clips.append(subclipped)
                            print(f"        âœ… ç‰‡æ®µ{i + 1}æå–æˆåŠŸ: {subclipped.duration:.1f}s")

                    except Exception as e:
                        print(f"        âŒ ç‰‡æ®µ{i + 1}æå–å¤±è´¥: {e}")
                else:
                    print(f"        âš ï¸ è·³è¿‡æ— æ•ˆç‰‡æ®µ{i + 1}: æ—¶é•¿{end - start:.1f}s")

            if not segment_clips:
                print(f"    âŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰‡æ®µï¼Œä½¿ç”¨åŸè§†é¢‘")
                return clip.without_audio() if has_audio else clip

            # åˆå¹¶ç‰‡æ®µ - ä½¿ç”¨chainæ–¹æ³•ç¡®ä¿å…¼å®¹æ€§
            print(f"    ğŸ”— åˆå¹¶ {len(segment_clips)} ä¸ªç‰‡æ®µ...")
            combined_clip = concatenate_videoclips(segment_clips, method="chain")
            print(f"    âœ… å¤šç‰‡æ®µåˆå¹¶æˆåŠŸ: {combined_clip.duration:.1f}s")

            return combined_clip

        except Exception as e:
            print(f"    âŒ å¤šç‰‡æ®µå¤„ç†å¤±è´¥: {e}")
            return clip.without_audio() if has_audio else clip

    def _step5_output_final_video(self, edited_clips, merge_videos: bool):
        """æ­¥éª¤5: è¾“å‡ºæœ€ç»ˆè§†é¢‘"""
        PathHelper.ensure_dir_exists(self.output_dir)
        output_filename = "edited_video.mp4"
        output_path = os.path.join(self.output_dir, output_filename)

        # æ›´å®‰å…¨çš„åˆå¹¶æ–¹å¼
        valid_clips = [clip for clip in edited_clips if clip is not None]
        if not valid_clips:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„å‰ªè¾‘å†…å®¹")

        # ğŸ”¥ å…³é”®ä¿®å¤: å¤šè§†é¢‘åˆå¹¶å‰ç»Ÿä¸€è§†é¢‘æ ¼å¼ï¼Œé˜²æ­¢æ’•è£‚
        if len(valid_clips) == 1:
            final_clip = valid_clips[0]
        else:
            print(f"  ğŸ”§ ç»Ÿä¸€ {len(valid_clips)} ä¸ªè§†é¢‘çš„æ ¼å¼å‚æ•°...")
            
            # è·å–æ‰€æœ‰è§†é¢‘çš„æ ¼å¼ä¿¡æ¯
            clip_info = []
            for i, clip in enumerate(valid_clips):
                info = {
                    'clip': clip,
                    'w': clip.w,
                    'h': clip.h,
                    'fps': clip.fps or 24,
                    'duration': clip.duration
                }
                clip_info.append(info)
                print(f"    è§†é¢‘{i+1}: {info['w']}x{info['h']} @{info['fps']}fps, {info['duration']:.1f}s")
            
            # è®¡ç®—ç»Ÿä¸€çš„ç›®æ ‡æ ¼å¼ï¼ˆä½¿ç”¨æœ€å°å…¬çº¦æ•°ç¡®ä¿å…¼å®¹æ€§ï¼‰
            target_w = min(info['w'] for info in clip_info)
            target_h = min(info['h'] for info in clip_info)
            target_fps = 24  # ç»Ÿä¸€ä½¿ç”¨24fps
            
            # ç¡®ä¿åˆ†è¾¨ç‡æ˜¯å¶æ•°ï¼ˆè§†é¢‘ç¼–ç è¦æ±‚ï¼‰
            target_w = target_w - (target_w % 2)
            target_h = target_h - (target_h % 2)
            
            print(f"    ğŸ¯ ç›®æ ‡æ ¼å¼: {target_w}x{target_h} @{target_fps}fps")
            
            # æ ‡å‡†åŒ–æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
            standardized_clips = []
            for i, info in enumerate(clip_info):
                clip = info['clip']
                try:
                    # ç»Ÿä¸€åˆ†è¾¨ç‡å’Œå¸§ç‡
                    if (clip.w != target_w or clip.h != target_h or clip.fps != target_fps):
                        print(f"    ğŸ”„ æ ‡å‡†åŒ–è§†é¢‘{i+1}: {clip.w}x{clip.h}@{clip.fps}fps -> {target_w}x{target_h}@{target_fps}fps")
                        standardized_clip = clip.resized((target_w, target_h)).with_fps(target_fps)
                    else:
                        standardized_clip = clip
                        print(f"    âœ… è§†é¢‘{i+1}æ ¼å¼å·²ç¬¦åˆè¦æ±‚")
                    
                    standardized_clips.append(standardized_clip)
                    
                except Exception as e:
                    print(f"    âš ï¸ è§†é¢‘{i+1}æ ‡å‡†åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸè§†é¢‘: {e}")
                    standardized_clips.append(clip)
            
            # ä½¿ç”¨chainæ–¹æ³•åˆå¹¶ï¼Œé¿å…æ ¼å¼å†²çª
            print(f"    ğŸ”— åˆå¹¶æ ‡å‡†åŒ–åçš„è§†é¢‘ç‰‡æ®µ...")
            final_clip = concatenate_videoclips(standardized_clips, method="chain")

        print(f"  ğŸ“Š è¾“å‡ºå‰æ£€æŸ¥:")
        print(f"    - æ—¶é•¿: {final_clip.duration:.1f}ç§’")
        print(f"    - åˆ†è¾¨ç‡: {final_clip.w}x{final_clip.h}")
        print(f"    - FPS: {final_clip.fps}")
        print(f"    - éŸ³é¢‘: {'æœ‰' if final_clip.audio else 'æ— '}")

        # ğŸ”¥ å…³é”®ä¿®å¤6: å½»åº•ä¿®å¤è¾“å‡ºå‚æ•°å’ŒéŸ³é¢‘å¤„ç†
        try:
            print("  ğŸ”„ å¼€å§‹å®‰å…¨è¾“å‡º...")

            # ç¡®ä¿åŸºæœ¬å±æ€§
            if not hasattr(final_clip, 'fps') or final_clip.fps is None:
                final_clip.fps = 24

            # ğŸ”¥ å…³é”®ä¿®å¤7: ä¼˜åŒ–è¾“å‡ºå‚æ•°ï¼Œé¿å…éŸ³é¢‘é—®é¢˜
            write_params = {
                "fps": final_clip.fps,
                "codec": "libx264",
                "preset": "medium",  # æ”¹ä¸ºmediumæé«˜å…¼å®¹æ€§
                "threads": 1,  # ä½¿ç”¨å•çº¿ç¨‹é¿å…æ­»é”
                "logger": None,
                "temp_audiofile": 'temp-audio.m4a',  # æŒ‡å®šä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                "remove_temp": True  # è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            }

            # ğŸ”¥ å…³é”®ä¿®å¤8: æ›´å®‰å…¨çš„éŸ³é¢‘å¤„ç†
            if final_clip.audio is not None:
                try:
                    # éªŒè¯éŸ³é¢‘å¯ç”¨æ€§
                    _ = final_clip.audio.duration
                    write_params["audio_codec"] = "aac"
                    write_params["audio_bitrate"] = "128k"
                    print("  ğŸµ éŸ³é¢‘è¾“å‡ºå·²å¯ç”¨")
                except Exception as audio_error:
                    print(f"  âš ï¸ éŸ³é¢‘è¾“å‡ºå¤±è´¥ï¼Œç§»é™¤éŸ³é¢‘: {audio_error}")
                    final_clip = final_clip.without_audio()
                    print("  ğŸ”‡ æ”¹ä¸ºæ— éŸ³é¢‘è¾“å‡º")

            # æ‰§è¡Œè¾“å‡º
            final_clip.write_videofile(output_path, **write_params)
            print("  âœ… è§†é¢‘è¾“å‡ºæˆåŠŸï¼")

            # éªŒè¯è¾“å‡º
            if os.path.exists(output_path):
                file_size = round(os.path.getsize(output_path) / (1024 * 1024), 2)
                print(f"\n  ğŸ“ å®Œå…¨ä¿®å¤ç‰ˆè¾“å‡ºéªŒè¯:")
                print(f"    - æ–‡ä»¶: {output_path}")
                print(f"    - å¤§å°: {file_size}MB")

                result = {
                    "status": "success",
                    "output_video": output_path,
                    "file_size_mb": file_size,
                    "video_info": {
                        "duration": final_clip.duration,
                        "resolution": f"{final_clip.w}x{final_clip.h}",
                        "fps": final_clip.fps,
                        "has_audio": final_clip.audio is not None
                    }
                }
                return result
            else:
                raise Exception("è¾“å‡ºæ–‡ä»¶æœªæˆåŠŸç”Ÿæˆ")

        except Exception as e:
            print(f"  âŒ è¾“å‡ºå¤±è´¥: {e}")
            raise e

        finally:
            # ç¡®ä¿èµ„æºé‡Šæ”¾
            try:
                final_clip.close()
            except:
                pass
            for clip in edited_clips:
                try:
                    if clip:
                        clip.close()
                except:
                    pass

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        pass


# ä»åˆ†æç»“æœåˆ›å»ºå·¥ä½œæµç¨‹çš„ä¾¿æ·å‡½æ•°
def create_orchestrator_from_analysis(analysis_file: str, output_dir: str = None):
    """ä»åˆ†æç»“æœæ–‡ä»¶åˆ›å»ºå·¥ä½œæµç¨‹ç¼–æ’å™¨"""

    with open(analysis_file, 'r', encoding='utf-8') as f:
        analysis_results = json.load(f)

    video_files = []
    for result in analysis_results:
        path = result.get('file_path') or result.get('filepath') or result.get('metadata', {}).get('filepath')
        if path and os.path.exists(path):
            video_files.append(path)

    if not video_files:
        raise ValueError("åˆ†æç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„")

    print(f"ä»åˆ†æç»“æœä¸­æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")

    return VideoEditingOrchestrator(
        video_files=video_files,
        output_dir=output_dir,
        analysis_results=analysis_results
    )
