import numpy as np
from moviepy import ImageClip,VideoClip,CompositeVideoClip,concatenate_videoclips,ColorClip,VideoFileClip,TextClip,vfx
from math import sqrt, sin, cos, radians
import math
import os
import cv2
import random
from scipy.ndimage import gaussian_filter
from PIL import Image

def ease_in_out_quad(t):
    """å¹³æ»‘åŠ é€Ÿå’Œå‡é€Ÿ"""
    return 2 * t * t if t < 0.5 else 1 - (-2 * t + 2) ** 2 / 2

def ease_in_quad(t):
    """åŠ é€Ÿå¼€å§‹"""
    return t * t

def ease_out_quad(t):
    """å‡é€Ÿç»“æŸ"""
    return 1 - (1 - t) ** 2

def linear(t):
    """çº¿æ€§è¿åŠ¨ï¼ˆæ— ç¼“åŠ¨ï¼‰"""
    return t


def calculate_scale_for_rotation(angle):
    """æ ¹æ®æ—‹è½¬è§’åº¦è®¡ç®—ç¼©æ”¾å› å­ä»¥é¿å…é»‘è¾¹"""
    angle_rad = radians(angle)
    return 1 / (cos(angle_rad) + abs(sin(angle_rad)))

# # å‡è®¾ease_in_out_quadå·²ç»å®šä¹‰
# def ease_in_out_quad(t):
#     if t < 0.5:
#         return 2 * t * t
#     else:
#         return -1 + (4 - 2 * t) * t


##TODO: éœ€è¦ä¼˜åŒ–æŒ‰ç…§å›ºå®šç‚¹ä½ç¼©æ”¾ï¼Œè½¬ç°åº¦å›¾ç”¨opencvè¿›è¡Œå®šä½ï¼Œç„¶åç”¨äººè„¸é¢ç§¯æ‰¾åˆ°æœ€å¤§çš„é‚£å¼ è„¸ï¼Œä»¥é‚£å¼ è„¸ä¸ºä¸­å¿ƒç¼©æ”¾ï¼Œå¦èµ·ä¸€ä¸ªå‡½æ•°zoom_in_face
def zoom_in(clip: VideoClip, duration=2, intensity=0.3, easing=ease_in_out_quad):
    """
    åˆ›å»ºä¸€ä¸ªä»ä¸­å¿ƒé€æ¸æ”¾å¤§çš„è§†é¢‘æ•ˆæœï¼Œé¿å…ç”»é¢æ‹‰ä¼¸æˆ–æ—‹è½¬ã€‚
    
    å‚æ•°:
        clip (VideoClip): è¾“å…¥è§†é¢‘å‰ªè¾‘ã€‚
        duration (float): åŠ¨ç”»æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
        intensity (float): æ”¾å¤§å¼ºåº¦ï¼Œå¦‚ 0.5 è¡¨ç¤ºæ”¾å¤§åˆ° 1.5 å€ã€‚
        easing (function): æ’å€¼å‡½æ•°ï¼Œè¾“å…¥ [0,1] è¾“å‡º [0,1]
        
    è¿”å›:
        VideoClip: æ”¾å¤§åŠ¨ç”»è§†é¢‘ã€‚
    """
    w, h = clip.size
    start_scale = 1.0
    end_scale = 1.0 + intensity

    # é¢„æ”¾å¤§åˆ°æœ€å¤§å°ºå¯¸ï¼Œé¿å…é»‘è¾¹
    # pre_zoomed_clip = clip.with_effects([vfx.Resize(end_scale)])
    pre_zoomed_clip = clip
    # å®šä¹‰æ¯å¸§çš„ç¼©æ”¾å‡½æ•°
    def scale_func(t):
        if t >= duration:
            return end_scale
        progress = t / duration
        scale_progress = easing(progress)
        return start_scale + (end_scale - start_scale) * scale_progress

    # åŠ¨æ€ç¼©æ”¾å‰ªè¾‘ï¼Œè®¾ç½®å›ºå®šå¤§å°å¹¶å±…ä¸­æ˜¾ç¤º
    animated_clip = (
        pre_zoomed_clip
        .with_effects([vfx.Resize(lambda t: scale_func(t))])
        .with_position(("center", "center"))  # ç¡®ä¿å§‹ç»ˆå±…ä¸­
    )

    # åˆ›å»ºä¸€ä¸ªå›ºå®šå¤§å°çš„åˆæˆèƒŒæ™¯ï¼Œé˜²æ­¢ç”»é¢å˜å½¢
    final_clip = CompositeVideoClip(
        [animated_clip],
        size=clip.size,
        bg_color=(0, 0, 0)  # å¯é€‰é»‘åº•ï¼Œä¹Ÿå¯ä»¥é€æ˜
    ).with_duration(clip.duration)  # ä¿æŒåŸå§‹ç‰‡æ®µæ—¶é•¿

    return final_clip


def zoom_out(clip: VideoClip, duration=2, intensity=0.3, easing=ease_in_out_quad):
    """
    åˆ›å»ºä¸€ä¸ªä»åŸå§‹å¤§å°é€æ¸ç¼©å°çš„è§†é¢‘æ•ˆæœï¼Œé¿å…ç”»é¢æ‹‰ä¼¸æˆ–é”™ä½ã€‚
    
    å‚æ•°:
        clip (VideoClip): è¾“å…¥è§†é¢‘å‰ªè¾‘ã€‚
        duration (float): åŠ¨ç”»æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
        intensity (float): ç¼©å°å¼ºåº¦ï¼Œå¦‚ 0.3 è¡¨ç¤ºç¼©å°åˆ° 0.7 å€ã€‚
        easing (function): æ’å€¼å‡½æ•°ï¼Œè¾“å…¥ [0,1] è¾“å‡º [0,1]
        
    è¿”å›:
        VideoClip: ç¼©å°åŠ¨ç”»è§†é¢‘ã€‚
    """
    w, h = clip.size
    start_scale = 1.0
    end_scale = 1.0 - intensity

    # é¢„æ”¾å¤§ä»¥é˜²æ­¢ç¼©å°æ—¶å†…å®¹è¶…å‡ºè¾¹ç•Œï¼ˆå¯é€‰ï¼‰
    pre_scaled_clip = clip.with_effects([vfx.Resize(1/end_scale)])

    def scale_func(t):
        if t >= duration:
            return end_scale
        progress = t / duration
        scale_progress = easing(progress)
        return start_scale + (end_scale - start_scale) * scale_progress

    animated_clip = (
        pre_scaled_clip
        .with_effects([vfx.Resize(lambda t: scale_func(t))])
        .with_position(("center", "center"))  # ç¡®ä¿å§‹ç»ˆå±…ä¸­
    )

    final_clip = CompositeVideoClip(
        [animated_clip],
        size=clip.size,
        bg_color=(0, 0, 0)  # å¯é€‰é»‘åº•ï¼Œä¹Ÿå¯ä»¥é€æ˜èƒŒæ™¯
    ).with_duration(clip.duration)  # ä¿æŒåŸå§‹ç‰‡æ®µæ—¶é•¿

    return final_clip

def pan(clip: VideoClip, duration=2, intensity=100, direction='left', easing=ease_in_out_quad):
    """
    åˆ›å»ºä¸€ä¸ªå¸¦æœ‰å¹³ç§»åŠ¨ç”»çš„è§†é¢‘æ•ˆæœï¼Œæ”¯æŒä¸Šä¸‹å·¦å³æ–¹å‘ã€‚
    
    å‚æ•°:
        clip (VideoClip): è¾“å…¥è§†é¢‘å‰ªè¾‘ã€‚
        duration (float): åŠ¨ç”»æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
        intensity (int/float): å¹³ç§»è·ç¦»ï¼ˆåƒç´ ï¼‰ã€‚
        direction (str): å¹³ç§»æ–¹å‘ï¼Œæ”¯æŒ 'left', 'right', 'up', 'down'ã€‚
        easing (function): æ’å€¼å‡½æ•°ï¼Œè¾“å…¥ [0,1] è¾“å‡º [0,1]
        
    è¿”å›:
        VideoClip: å¸¦å¹³ç§»åŠ¨ç”»çš„è§†é¢‘å‰ªè¾‘ã€‚
    """
    w, h = clip.size
    original_size = (w, h)

    # é¢„æ”¾å¤§ä»¥é¿å…å¹³ç§»æ—¶éœ²å‡ºé»‘è¾¹
    zoom_scale = 1.5  # å¯æ ¹æ®éœ€è¦è°ƒæ•´
    pre_zoomed_clip = clip.resized(zoom_scale)

    # è·å–æ”¾å¤§åçš„çœŸå®å°ºå¯¸
    zoomed_w, zoomed_h = pre_zoomed_clip.size

    def position_func(t):
        if t > duration:
            return ("center", "center")
        progress = easing(t / duration)
        offset = intensity * progress

        if direction == 'left':
            x = -offset
        elif direction == 'right':
            x = offset
        elif direction == 'up':
            x = 0
            y = -offset
            return ("center", y)
        elif direction == 'down':
            x = 0
            y = offset
            return ("center", y)
        else:
            x = 0

        return (x, "center")

    animated_clip = (
        pre_zoomed_clip
        .with_position(position_func)  # è®¾ç½®åŠ¨æ€ä½ç½®
        .with_duration(clip.duration)  # ä¿æŒåŸå§‹ç‰‡æ®µæ—¶é•¿
    )

    # å›ºå®šè¾“å‡ºåˆ†è¾¨ç‡ä¸ºåŸè§†é¢‘å¤§å°
    final_clip = CompositeVideoClip(
        [animated_clip],
        size=original_size,
        bg_color=None  # æˆ–è€…è®¾ç½®æˆ (0,0,0) é»‘è‰²èƒŒæ™¯
    ).with_duration(clip.duration)  # ä¿æŒåŸå§‹ç‰‡æ®µæ—¶é•¿

    return final_clip



# def move(clip:VideoClip, duration=2, intensity=100, direction='up', easing=ease_in_out_quad):
#     def pos_func(t):
#         y_offset = intensity * easing(t / duration)
#         if direction == 'up':
#             return ('center', 'center') if y_offset > clip.h/2 else ('center', -y_offset)
#         elif direction == 'down':
#             return ('center', 'center') if y_offset > clip.h/2 else ('center', clip.h - y_offset)
#         else:
#             return ('center', 'center')
#     scaled_clip = clip.resized(1.5)  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´æ”¾å¤§æ¯”ä¾‹
#     return scaled_clip.with_position(pos_func).with_duration(duration)

def calculate_scale_for_rotation(angle_degrees, width, height):
    """
    è®¡ç®—ä¸ºé¿å…æ—‹è½¬æ—¶éœ²å‡ºé»‘è¾¹æ‰€éœ€çš„æœ€å°æ”¾å¤§æ¯”ä¾‹ã€‚
    """
    angle_rad = math.radians(angle_degrees % 360)
    # è·å–åŸå§‹å®½é«˜æ¯”
    original_ratio = float(width) / height
    
    # æ ¹æ®æ—‹è½¬è§’åº¦è°ƒæ•´å®½é«˜æ¯”
    if angle_degrees % 180 == 90:
        new_ratio = 1.0 / original_ratio
    else:
        new_ratio = original_ratio

    # è®¡ç®—æ–°çš„å®½åº¦å’Œé«˜åº¦ï¼Œä»¥ç¡®ä¿æ—‹è½¬åä¸ä¼šå‡ºç°é»‘è¾¹
    diagonal = math.sqrt(width ** 2 + height ** 2)
    scale_factor = diagonal / min(width, height)

    return scale_factor

def rotate(clip: VideoClip, duration=2, degrees=360, easing=ease_in_out_quad):
    """
    åˆ›å»ºä¸€ä¸ªå¹³æ»‘æ—‹è½¬çš„è§†é¢‘æ•ˆæœï¼Œå¹¶é€šè¿‡é¢„æ”¾å¤§é˜²æ­¢æ—‹è½¬æ—¶éœ²å‡ºé»‘è¾¹ã€‚
    
    å‚æ•°:
        clip (VideoClip): è¾“å…¥è§†é¢‘å‰ªè¾‘ã€‚
        duration (float): åŠ¨ç”»æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
        degrees (float): æ€»å…±æ—‹è½¬çš„è§’åº¦ï¼ˆå¦‚ 90, 180, 360ï¼‰ã€‚
        easing (function): æ’å€¼å‡½æ•°ï¼Œè¾“å…¥ [0,1] è¾“å‡º [0,1]
        
    è¿”å›:
        VideoClip: æ—‹è½¬åŠ¨ç”»è§†é¢‘ã€‚
    """
    w, h = clip.size
    original_size = (w, h)

    # è®¡ç®—æ—‹è½¬æ‰€éœ€æœ€å°æ”¾å¤§å€æ•°
    scale_factor = calculate_scale_for_rotation(degrees, w, h)
    
    # é¢„æ”¾å¤§å›¾åƒä»¥é˜²æ­¢æ—‹è½¬æ—¶éœ²å‡ºé»‘è¾¹
    pre_scaled_clip = clip.with_effects([vfx.Resize(scale_factor)])

    # å®šä¹‰åŠ¨æ€æ—‹è½¬å‡½æ•°
    def rotation_func(t):
        if t >= duration:
            return degrees
        progress = easing(t / duration)
        return degrees * progress

    # åˆ›å»ºæ—‹è½¬åŠ¨ç”»å‰ªè¾‘
    animated_clip = (
        pre_scaled_clip
        .rotated(lambda t: rotation_func(t))  # ä½¿ç”¨è‡ªå®šä¹‰æ—‹è½¬å‡½æ•°
        .with_position(("center", "center"))   # ç¡®ä¿å±…ä¸­æ—‹è½¬
        .with_duration(clip.duration)  # ä¿æŒåŸå§‹ç‰‡æ®µæ—¶é•¿
    )

    # å°†æ—‹è½¬åçš„å‰ªè¾‘æ”¾å…¥å›ºå®šå°ºå¯¸çš„åˆæˆå‰ªè¾‘ä¸­ï¼Œé˜²æ­¢ç”»é¢å˜å½¢
    final_clip = CompositeVideoClip(
        [animated_clip],
        size=original_size,
        bg_color=None  # å¯é€‰é»‘è‰²èƒŒæ™¯æˆ–è€…é€æ˜èƒŒæ™¯
    ).with_duration(clip.duration)  # ä¿æŒåŸå§‹ç‰‡æ®µæ—¶é•¿

    return final_clip




# def follow(clip:VideoClip, duration=2, path_function=lambda t: (100 * t, 100 * t), easing=ease_in_out_quad):
#     def pos_func(t):
#         x, y = path_function(easing(t / duration))
#         return (x, y)
#     # å¯¹äºå¤æ‚è·¯å¾„å¯èƒ½éœ€è¦é¢„å…ˆæ”¾å¤§å›¾åƒ
#     scaled_clip = clip.resized(1.5)  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´æ”¾å¤§æ¯”ä¾‹
#     return scaled_clip.with_position(pos_func).with_duration(duration)


def fisheye_distortion(image, strength=0.5):
    """Apply fisheye effect to an image."""
    height, width = image.shape[:2]
    map_x = np.zeros((height, width), dtype=np.float32)
    map_y = np.zeros((height, width), dtype=np.float32)

    center_x, center_y = width // 2, height // 2
    radius = min(center_x, center_y)

    for y in range(height):
        for x in range(width):
            dx = x - center_x
            dy = y - center_y
            distance = np.sqrt(dx**2 + dy**2)
            angle = np.arctan2(dy, dx)
            
            # Apply fish-eye transformation.
            factor = 1.0 + (strength * distance / radius)
            new_distance = distance * factor
            
            new_x = int(round(new_distance * np.cos(angle))) + center_x
            new_y = int(round(new_distance * np.sin(angle))) + center_y
            
            if 0 <= new_x < width and 0 <= new_y < height:
                map_x[y, x] = new_x
                map_y[y, x] = new_y
            else:
                map_x[y, x] = x
                map_y[y, x] = y
    
    fisheye_image = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR)
    return fisheye_image

def apply_fisheye_and_pan(clip: VideoClip, duration=2, intensity=100, direction='left', easing=ease_in_out_quad):
    """
    å¯¹è§†é¢‘å‰ªè¾‘å…ˆåº”ç”¨é±¼çœ¼ç„¶åå†åº”ç”¨ç§»åŠ¨ï¼Œæ¥æ¨¡æ‹Ÿæ‘„åƒæœºçš„ç»•zè½´æ—‹è½¬æ‹æ‘„ã€‚
    
    å‚æ•°:
        clip (VideoClip): è¦å¤„ç†çš„è§†é¢‘å‰ªè¾‘ã€‚
        duration (int/float): æ—¶é•¿ã€‚
        intensity (int/float): å¹³ç§»å¼ºåº¦ï¼Œå•ä½ä¸ºåƒç´ ã€‚
        direction (str): å¹³ç§»æ–¹å‘ï¼Œæ”¯æŒ 'left', 'right'ã€‚
        
    è¿”å›:
        VideoClip: æ¨¡æ‹Ÿæ‘„åƒæœºçš„ç»•zè½´æ—‹è½¬çš„æ–°è§†é¢‘å‰ªè¾‘ã€‚
    """
    w, h = clip.size
    original_size = (w, h)

    def make_frame(t):
        frame = clip.get_frame(t)
        frame = fisheye_distortion(frame)  # åº”ç”¨é±¼çœ¼æ•ˆæœ
        
        # è®¡ç®—å¹³ç§»è·ç¦»
        progress = easing(t / duration)
        offset = intensity * progress
        
        if direction == 'left':
            x_offset = -offset
        elif direction == 'right':
            x_offset = offset
        else:
            x_offset = 0

        # ç¡®ä¿ x_offset æ˜¯æ•´æ•°
        x_offset_int = int(round(x_offset))

        # åˆ›å»ºç©ºç™½èƒŒæ™¯ï¼Œé˜²æ­¢é»‘è¾¹
        background = np.zeros((h, w * 2, 3), dtype=np.uint8)  # å®½åº¦æ”¾å¤§ä¸€å€ä»¥å®¹çº³å¹³ç§»

        # è®¡ç®—æºå’Œç›®æ ‡åŒºåŸŸ
        src_start = max(0, -x_offset_int)
        src_end = min(w, w - x_offset_int)
        dst_start = max(0, x_offset_int)
        dst_end = dst_start + (src_end - src_start)

        # åªæœ‰åœ¨èŒƒå›´å†…æ‰å¤åˆ¶å›¾åƒ
        if src_start < src_end and dst_start < background.shape[1]:
            background[:, dst_start:dst_end, :] = frame[:, src_start:src_end, :]

        # è£å‰ªå›åŸå§‹å¤§å°
        final_frame = background[:, w//2:w//2 + w, :]

        return final_frame

    animated_clip = VideoClip(make_frame, duration=duration)
    final_clip = CompositeVideoClip([animated_clip], size=original_size).with_duration(duration)
    
    return final_clip




def blur(clip, sigma=3):
    """
    å¯¹è§†é¢‘å‰ªè¾‘ä¸­çš„æ¯ä¸€å¸§åº”ç”¨é«˜æ–¯æ¨¡ç³Šã€‚
    
    å‚æ•°:
        clip (VideoClip): è¦å¤„ç†çš„è§†é¢‘å‰ªè¾‘ã€‚
        sigma (int/float): é«˜æ–¯æ¨¡ç³Šçš„æ ‡å‡†å·®ï¼Œå€¼è¶Šå¤§è¶Šæ¨¡ç³Šã€‚
        
    è¿”å›:
        VideoClip: ç»è¿‡é«˜æ–¯æ¨¡ç³Šå¤„ç†çš„æ–°è§†é¢‘å‰ªè¾‘ã€‚
    """
    def blurred_frame(t):
        frame = clip.get_frame(t)
        # ä½¿ç”¨OpenCVè¿›è¡Œé«˜æ–¯æ¨¡ç³Š
        return cv2.GaussianBlur(frame, (0, 0), sigmaX=sigma)
    blurred_clip = VideoClip(
        frame_function=blurred_frame,
        duration=clip.duration,
    )

    return blurred_clip




def radial_blur(clip, center=None, max_sigma=10):
    """
    å¯¹è§†é¢‘å‰ªè¾‘ä¸­çš„æ¯ä¸€å¸§åº”ç”¨å¾„å‘æ¨¡ç³Šã€‚
    æ¨¡ç³Šå¼ºåº¦éšè·ç¦»ä¸­å¿ƒç‚¹çš„è·ç¦»è€Œå˜åŒ–ã€‚
    
    å‚æ•°:
        clip (VideoClip): è¦å¤„ç†çš„è§†é¢‘å‰ªè¾‘ã€‚
        center (tuple): æ¨¡ç³Šä¸­å¿ƒç‚¹ (x, y)ï¼Œé»˜è®¤ä¸ºå›¾åƒä¸­å¿ƒã€‚
        max_sigma (int/float): æœ€å¤§æ¨¡ç³Šå¼ºåº¦ï¼ˆæ ‡å‡†å·®ï¼‰ã€‚
        
    è¿”å›:
        VideoClip: åº”ç”¨äº†å¾„å‘æ¨¡ç³Šçš„æ–°è§†é¢‘å‰ªè¾‘ã€‚
    """
    def blurred_frame(t):
        frame = clip.get_frame(t)
        h, w, _ = frame.shape

        # é»˜è®¤ä½¿ç”¨ç”»é¢ä¸­å¿ƒ
        if center is None:
            cx, cy = w // 2, h // 2
        else:
            cx, cy = center

        # åˆ›å»ºç½‘æ ¼åæ ‡
        x = np.arange(w)
        y = np.arange(h)
        X, Y = np.meshgrid(x, y)
        
        # è®¡ç®—æ¯ä¸ªåƒç´ åˆ°ä¸­å¿ƒçš„è·ç¦»
        dist = np.sqrt((X - cx) ** 2 + (Y - cy) ** 2)
        dist_normalized = dist / np.max(dist)
        
        # æ¯ä¸ªåƒç´ çš„æ¨¡ç³Šç¨‹åº¦å–å†³äºå…¶ä¸ä¸­å¿ƒçš„è·ç¦»
        sigma_map = max_sigma * dist_normalized

        # åˆ†é€šé“å¤„ç†ï¼ˆå› ä¸ºOpenCVçš„GaussianBlurä¸æ”¯æŒé€åƒç´ sigmaï¼‰
        blurred_channels = []
        for i in range(3):
            # blurred_channel = gaussian_filter(frame[:, :, i], sigma=sigma_map)
            # blurred_channels.append(blurred_channel)
            channel = frame[:, :, i].copy()
            # ä½¿ç”¨ OpenCV çš„é«˜æ–¯æ¨¡ç³Šï¼Œæ¨¡æ‹Ÿå±€éƒ¨æ¨¡ç³Šï¼ˆè™½ç„¶ä¸æ˜¯ä¸¥æ ¼çš„é€åƒç´ ä¸åŒï¼‰
            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æœ€å¤§ sigma åšä¸€æ¬¡æ¨¡ç³Šï¼Œç„¶åæ ¹æ® sigma_map ç¼©æ”¾æ¨¡ç³Šç»“æœ
            # æˆ–è€…ä½ å¯ä»¥åšå¤šå°ºåº¦æ¨¡ç³Šåˆæˆ
            blurred_full = cv2.GaussianBlur(channel, (0, 0), max_sigma)
            # ç®€å•åŠ æƒæ··åˆåŸå›¾å’Œæ¨¡ç³Šå›¾ï¼ˆå¯æ›¿æ¢ä¸ºæ›´å¤æ‚æ–¹å¼ï¼‰
            alpha = sigma_map / max_sigma
            blurred_channel = (channel * (1 - alpha) + blurred_full * alpha).astype(np.uint8)
            blurred_channels.append(blurred_channel)
        
        blurred = np.stack(blurred_channels, axis=-1).astype(np.uint8)
        return blurred

    return VideoClip(
        frame_function=blurred_frame,
        duration=clip.duration,
        is_mask=clip.is_mask
    )




def directional_blur(
    clip: VideoClip,
    angle: float = 0.0,     # æ¨¡ç³Šæ–¹å‘ï¼ˆè§’åº¦ï¼‰ï¼Œ0 è¡¨ç¤ºæ°´å¹³å‘å³
    blur_len: int = 15      # æ¨¡ç³Šé•¿åº¦ï¼ˆåƒç´ æ•°ï¼‰
) -> VideoClip:
    """
    å¯¹è§†é¢‘å¸§åº”ç”¨æ–¹å‘æ¨¡ç³Šï¼Œæ¨¡æ‹Ÿè¿åŠ¨è½¨è¿¹æ•ˆæœã€‚
    
    å‚æ•°:
        clip (VideoClip): åŸå§‹è§†é¢‘å‰ªè¾‘ã€‚
        angle (float): æ¨¡ç³Šæ–¹å‘ï¼Œå•ä½ä¸ºåº¦ï¼ˆ0~360ï¼‰ã€‚
        blur_len (int): æ¨¡ç³Šé•¿åº¦ï¼Œå€¼è¶Šå¤§è¶Šæ¨¡ç³Šã€‚
        
    è¿”å›:
        VideoClip: åº”ç”¨äº†æ–¹å‘æ¨¡ç³Šçš„æ–°è§†é¢‘å‰ªè¾‘ã€‚
    """
    def make_frame(t):
        frame = clip.get_frame(t)

        # åˆ›å»ºä¸€ä¸ªçº¿æ€§è¿åŠ¨æ¨¡ç³Šçš„æ ¸ï¼ˆkernelï¼‰
        kernel_size = blur_len
        kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)
        center = (kernel_size - 1) // 2

        # è®¡ç®—æ¨¡ç³Šæ–¹å‘çš„è§’åº¦å¯¹åº”çš„æ­£ä½™å¼¦
        rad = np.deg2rad(angle)
        x = np.cos(rad)
        y = np.sin(rad)

        # åœ¨ kernel ä¸Šç»˜åˆ¶ä¸€æ¡çº¿ï¼ˆæ¨¡æ‹Ÿè¿åŠ¨è½¨è¿¹ï¼‰
        for i in range(kernel_size):
            px = int(np.round(x * i)) + center
            py = int(np.round(y * i)) + center
            if 0 <= px < kernel_size and 0 <= py < kernel_size:
                kernel[py, px] = 1

        kernel = kernel / kernel.sum()  # å½’ä¸€åŒ–

        # å¯¹æ¯ä¸ªé€šé“åº”ç”¨å·ç§¯æ¨¡ç³Š
        blurred = cv2.filter2D(frame, -1, kernel)

        return blurred

    return VideoClip(make_frame, duration=clip.duration)



def pixelate(clip: VideoClip, block_size=10) -> VideoClip:
    """
    å°†ç”»é¢åƒç´ åŒ–ï¼Œæ¨¡æ‹Ÿé©¬èµ›å…‹æ•ˆæœã€‚
    
    å‚æ•°:
        clip (VideoClip): åŸå§‹è§†é¢‘å‰ªè¾‘ã€‚
        block_size (int): æ¯ä¸ªåƒç´ å—çš„å¤§å°ã€‚
        
    è¿”å›:
        VideoClip: åƒç´ åŒ–åçš„è§†é¢‘ã€‚
    """
    def make_frame(t):
        frame = clip.get_frame(t)  # frame æ˜¯ numpy.ndarrayï¼Œshape=(h, w, 3)
        img = Image.fromarray(frame)
        w, h = img.size  # PIL ä½¿ç”¨ .size è·å–å®½é«˜
        
        # ç¼©å°å†æ”¾å¤§å®ç°é©¬èµ›å…‹æ•ˆæœ
        small = img.resize((w // block_size, h // block_size), Image.NEAREST)
        mosaic = small.resize((w, h), Image.NEAREST)
        
        # è½¬æ¢å› numpy array
        return np.array(mosaic)  # âœ… å…³é”®ï¼šè½¬ä¸º ndarray

    return VideoClip(make_frame, duration=clip.duration)




def edge_detect(clip: VideoClip) -> VideoClip:
    """
    å¯¹è§†é¢‘å¸§åº”ç”¨è¾¹ç¼˜æ£€æµ‹æ»¤é•œï¼ˆç°åº¦å›¾åƒï¼‰ã€‚æ•ˆæœæŒºéœ‡æ’¼ã€‚ç±»ä¼¼é›•ç‰ˆå°åˆ·
    
    å‚æ•°:
        clip (VideoClip): åŸå§‹è§†é¢‘å‰ªè¾‘ã€‚
        
    è¿”å›:
        VideoClip: è¾¹ç¼˜æ£€æµ‹åçš„è§†é¢‘ã€‚
    """
    def make_frame(t):
        frame = clip.get_frame(t)
        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, threshold1=50, threshold2=150)
        return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

    return VideoClip(make_frame, duration=clip.duration)



def posterize(clip: VideoClip, levels=4) -> VideoClip:
    """
    å‡å°‘é¢œè‰²å±‚æ¬¡ï¼Œä½¿ç”»é¢å…·æœ‰â€œæµ·æŠ¥â€é£æ ¼ã€‚
    
    å‚æ•°:
        clip (VideoClip): åŸå§‹è§†é¢‘å‰ªè¾‘ã€‚
        levels (int): é¢œè‰²å±‚çº§æ•°ã€‚
        
    è¿”å›:
        VideoClip: æµ·æŠ¥é£æ ¼è§†é¢‘ã€‚
    """
    def make_frame(t):
        frame = clip.get_frame(t)
        return np.floor(frame / 256 * levels) * (256 // levels)

    return VideoClip(make_frame, duration=clip.duration)


def shake(clip: VideoClip, intensity=5) -> VideoClip:
    """
    è®©ç”»é¢éšæœºè½»å¾®æŠ–åŠ¨ï¼Œæ¨¡æ‹Ÿæ‰‹æŒæ‹æ‘„æ•ˆæœã€‚
    
    å‚æ•°:
        clip (VideoClip): åŸå§‹è§†é¢‘å‰ªè¾‘ã€‚
        intensity (int): æŠ–åŠ¨æœ€å¤§åç§»é‡ã€‚
        
    è¿”å›:
        VideoClip: æŠ–åŠ¨æ•ˆæœçš„è§†é¢‘ã€‚
    """
    def make_frame(t):
        frame = clip.get_frame(t)
        dx = random.randint(-intensity, intensity)
        dy = random.randint(-intensity, intensity)
        return np.roll(frame, shift=(dy, dx), axis=(0, 1))

    # ğŸ”¥ é‡è¦ï¼šä¿ç•™åŸå§‹éŸ³é¢‘
    shake_clip = VideoClip(make_frame, duration=clip.duration)
    
    # å¦‚æœåŸå§‹ç‰‡æ®µæœ‰éŸ³é¢‘ï¼Œä¿ç•™å®ƒ
    if hasattr(clip, 'audio') and clip.audio is not None:
        shake_clip = shake_clip.with_audio(clip.audio)
    
    return shake_clip



def glitch(clip: VideoClip, intensity=3) -> VideoClip:
    """
    ç®€å•æ¨¡æ‹Ÿæ¨ªå‘é”™ä½çš„æ•°ç æ•…éšœæ•ˆæœã€‚ç±»ä¼¼ç”»é¢æŠ–åŠ¨
    
    å‚æ•°:
        clip (VideoClip): åŸå§‹è§†é¢‘ã€‚
        intensity (int): é”™ä½å¼ºåº¦ã€‚
        
    è¿”å›:
        VideoClip: æ•…éšœé£è§†é¢‘ã€‚
    """
    def make_frame(t):
        frame = clip.get_frame(t)
        h, w, d = frame.shape
        offset = random.randint(-intensity, intensity)
        new_frame = frame.copy()
        if offset > 0:
            new_frame[:, :w - offset] = frame[:, offset:]
        elif offset < 0:
            new_frame[:, -offset:] = frame[:, :w + offset]
        return new_frame

    # ğŸ”¥ é‡è¦ï¼šä¿ç•™åŸå§‹éŸ³é¢‘
    glitch_clip = VideoClip(make_frame, duration=clip.duration)
    
    # å¦‚æœåŸå§‹ç‰‡æ®µæœ‰éŸ³é¢‘ï¼Œä¿ç•™å®ƒ
    if hasattr(clip, 'audio') and clip.audio is not None:
        glitch_clip = glitch_clip.with_audio(clip.audio)
    
    return glitch_clip


def vignette(clip: VideoClip, strength=0.5) -> VideoClip:
    """
    æ·»åŠ æš—è§’æ•ˆæœï¼Œçªå‡ºç”»é¢ä¸­å¿ƒã€‚
    
    å‚æ•°:
        clip (VideoClip): åŸå§‹è§†é¢‘ã€‚
        strength (float): æš—è§’å¼ºåº¦ [0~1]ã€‚
        
    è¿”å›:
        VideoClip: æ·»åŠ æš—è§’çš„è§†é¢‘ã€‚
    """
    def make_frame(t):
        frame = clip.get_frame(t)
        h, w, _ = frame.shape
        x = np.linspace(-1, 1, w)
        y = np.linspace(-1, 1, h)
        X, Y = np.meshgrid(x, y)
        dist = 1 - (X ** 2 + Y ** 2)
        mask = np.clip(dist, 0, 1)
        mask = 1 - strength * (1 - mask)
        return (frame * mask[..., np.newaxis]).astype(np.uint8)

    # ğŸ”¥ é‡è¦ï¼šä¿ç•™åŸå§‹éŸ³é¢‘
    vignette_clip = VideoClip(make_frame, duration=clip.duration)
    
    # å¦‚æœåŸå§‹ç‰‡æ®µæœ‰éŸ³é¢‘ï¼Œä¿ç•™å®ƒ
    if hasattr(clip, 'audio') and clip.audio is not None:
        vignette_clip = vignette_clip.with_audio(clip.audio)
    
    return vignette_clip

# åˆ›å»ºå¸¦é»‘è‰²åŠé€æ˜é®ç½©çš„å¤åˆè§†é¢‘
def apply_black_overlay(clip, opacity=50):
    """
    åœ¨è§†é¢‘ä¸Šå åŠ ä¸€ä¸ªé»‘è‰²åŠé€æ˜é®ç½©ã€‚
    
    å‚æ•°:
        clip: åŸå§‹è§†é¢‘å‰ªè¾‘ã€‚
        opacity: é€æ˜åº¦ (0 å®Œå…¨é€æ˜, 100å®Œå…¨ä¸é€æ˜)
        
    è¿”å›:
        æ–°çš„åˆæˆè§†é¢‘å‰ªè¾‘
    """
    opacity=int(opacity/100*255)
    overlay = ColorClip(size=clip.size, color=(0, 0, 0,opacity), duration=clip.duration)
    # overlay = overlay.set_opacity(opacity)  # è®¾ç½®é€æ˜åº¦
    return CompositeVideoClip([clip, overlay])




def wave_frame(img, t):
    """
    å¯¹å•å¸§å›¾åƒåº”ç”¨æ°´æ³¢æŠ–åŠ¨æ•ˆæœ
    :param img: numpy array æ ¼å¼çš„å›¾åƒ (H, W, C)
    :param t: å½“å‰æ—¶é—´
    :return: å¤„ç†åçš„å›¾åƒ
    """
    height, width = img.shape[:2]

    # åˆ›å»ºä¸€ä¸ªä¸åŸå›¾å¤§å°ç›¸åŒçš„ç©ºç™½å›¾åƒ
    distorted = np.zeros_like(img)

    # åˆ›å»ºç½‘æ ¼åæ ‡
    x, y = np.meshgrid(np.arange(width), np.arange(height))

    # æ·»åŠ æ­£å¼¦æ‰°åŠ¨
    dx = 5 * np.sin(2 * np.pi * t + y / 20)  # æ°´å¹³æ–¹å‘æ³¢åŠ¨
    dy = 3 * np.cos(2 * np.pi * t + x / 20)  # å‚ç›´æ–¹å‘æ³¢åŠ¨

    map_x = (x + dx).astype(np.float32)
    map_y = (y + dy).astype(np.float32)

    # åº”ç”¨é‡æ˜ å°„ï¼ˆremapï¼‰
    distorted = cv2.remap(img, map_x, map_y, interpolation=cv2.INTER_LINEAR,
                          borderMode=cv2.BORDER_REFLECT)

    return distorted

def make_wavy_image_func(clip):
    def func(get_frame, t):
        frame = get_frame(t)
        return wave_frame(frame, t)
    return func

# ä½¿ç”¨ç¤ºä¾‹
# ==================== è½¬åœºæ•ˆæœå®ç° ====================
# å®ç°ç«å±±å¼•æ“çš„æ‰€æœ‰è½¬åœºæ•ˆæœï¼Œä½¿ç”¨çº¯Pythonä»£ç 

def leaf_flip_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """å¶ç‰‡ç¿»è½¬è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œè¿”å›åŸclip
    if clip2 is None:
        return clip1
    
    def make_frame(t):
        if t < duration / 2:
            # å‰åŠæ®µï¼šclip1ç¿»è½¬æ¶ˆå¤±
            progress = t / (duration / 2)
            angle = progress * 90
            # æ¨¡æ‹Ÿ3Dç¿»è½¬æ•ˆæœ
            scale_x = cos(radians(angle))
            if scale_x > 0:
                frame = clip1.get_frame(clip1.duration - duration + t)
                h, w = frame.shape[:2]
                # æ°´å¹³å‹ç¼©æ¨¡æ‹Ÿç¿»è½¬
                new_w = int(w * scale_x)
                if new_w > 0:
                    resized = cv2.resize(frame, (new_w, h))
                    # å±…ä¸­æ˜¾ç¤º
                    result = np.zeros_like(frame)
                    x_offset = (w - new_w) // 2
                    result[:, x_offset:x_offset+new_w] = resized
                    return result
        else:
            # ååŠæ®µï¼šclip2ç¿»è½¬å‡ºç°
            progress = (t - duration / 2) / (duration / 2)
            angle = 90 - progress * 90
            scale_x = cos(radians(angle))
            if scale_x > 0:
                frame = clip2.get_frame(t - duration / 2)
                h, w = frame.shape[:2]
                new_w = int(w * scale_x)
                if new_w > 0:
                    resized = cv2.resize(frame, (new_w, h))
                    result = np.zeros_like(frame)
                    x_offset = (w - new_w) // 2
                    result[:, x_offset:x_offset+new_w] = resized
                    return result
        
        # é»˜è®¤è¿”å›é»‘å¸§
        return np.zeros_like(clip1.get_frame(0))
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def blinds_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0, num_blinds=10):
    """ç™¾å¶çª—è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œè¿”å›åŸclip
    if clip2 is None:
        return clip1
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        frame1 = clip1.get_frame(clip1.duration - duration + t)
        frame2 = clip2.get_frame(t)
        
        h, w = frame1.shape[:2]
        blind_height = h // num_blinds
        result = frame1.copy()
        
        for i in range(num_blinds):
            y_start = i * blind_height
            y_end = min((i + 1) * blind_height, h)
            blind_progress = min(progress * num_blinds - i, 1.0)
            
            if blind_progress > 0:
                cut_point = int(w * blind_progress)
                result[y_start:y_end, :cut_point] = frame2[y_start:y_end, :cut_point]
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def wind_blow_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """é£å¹è½¬åœºæ•ˆæœ - æ¨¡æ‹Ÿé£å¹æ•£æ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œè¿”å›åŸclip
    if clip2 is None:
        return clip1
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        frame1 = clip1.get_frame(clip1.duration - duration + t)
        frame2 = clip2.get_frame(t)
        
        h, w = frame1.shape[:2]
        result = frame2.copy()
        
        # åˆ›å»ºæ³¢æµªå½¢è¿‡æ¸¡
        for y in range(h):
            # é£å¹çš„æ³¢æµªåç§»
            wave_offset = sin(y * 0.02) * 50
            transition_x = int(w * progress + wave_offset)
            
            if transition_x > 0:
                result[y, :min(transition_x, w)] = frame1[y, :min(transition_x, w)]
        
        # æ·»åŠ æ¨¡ç³Šè¾¹ç¼˜
        if 0.2 < progress < 0.8:
            blur_width = 20
            for y in range(h):
                wave_offset = sin(y * 0.02) * 50
                transition_x = int(w * progress + wave_offset)
                if blur_width < transition_x < w - blur_width:
                    alpha = np.linspace(1, 0, blur_width)
                    for i in range(blur_width):
                        if transition_x - blur_width + i < w:
                            result[y, transition_x - blur_width + i] = (
                                frame1[y, transition_x - blur_width + i] * alpha[i] +
                                frame2[y, transition_x - blur_width + i] * (1 - alpha[i])
                            ).astype(np.uint8)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def rotate_zoom_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """æ—‹è½¬æ”¾å¤§è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œä½¿ç”¨æ—‹è½¬æ•ˆæœ
    if clip2 is None:
        return rotate(clip1, duration=min(duration, clip1.duration), degrees=360)
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        
        # æ—‹è½¬è§’åº¦å’Œç¼©æ”¾
        angle = progress * 360
        scale = 1 + progress * 0.5
        
        if progress < 0.5:
            frame = clip1.get_frame(clip1.duration - duration + t)
            alpha = 1 - progress * 2
        else:
            frame = clip2.get_frame(t)
            alpha = (progress - 0.5) * 2
        
        h, w = frame.shape[:2]
        center = (w // 2, h // 2)
        
        # åˆ›å»ºæ—‹è½¬çŸ©é˜µ
        M = cv2.getRotationMatrix2D(center, angle, scale)
        rotated = cv2.warpAffine(frame, M, (w, h))
        
        # æ·¡å…¥æ·¡å‡º
        result = (rotated * alpha).astype(np.uint8)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def hexagon_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """å…­è§’å½¢è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œè¿”å›åŸclip
    if clip2 is None:
        return clip1
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        frame1 = clip1.get_frame(clip1.duration - duration + t)
        frame2 = clip2.get_frame(t)
        
        h, w = frame1.shape[:2]
        center_x, center_y = w // 2, h // 2
        
        # åˆ›å»ºå…­è§’å½¢é®ç½©
        max_radius = int(sqrt(w**2 + h**2) / 2)
        current_radius = int(max_radius * progress)
        
        # å…­è§’å½¢é¡¶ç‚¹
        angles = [i * 60 for i in range(6)]
        points = []
        for angle in angles:
            x = center_x + current_radius * cos(radians(angle))
            y = center_y + current_radius * sin(radians(angle))
            points.append([int(x), int(y)])
        
        # åˆ›å»ºé®ç½©
        mask = np.zeros((h, w), dtype=np.uint8)
        if len(points) > 0 and current_radius > 0:
            cv2.fillPoly(mask, [np.array(points)], 255)
        
        # åº”ç”¨é®ç½©
        mask_3channel = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        result = np.where(mask_3channel > 0, frame2, frame1)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def circle_open_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """åœ†å½¢æ‰“å¼€è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œè¿”å›åŸclip
    if clip2 is None:
        return clip1
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        frame1 = clip1.get_frame(clip1.duration - duration + t)
        frame2 = clip2.get_frame(t)
        
        h, w = frame1.shape[:2]
        center_x, center_y = w // 2, h // 2
        
        # è®¡ç®—åœ†å½¢åŠå¾„
        max_radius = int(sqrt(w**2 + h**2) / 2)
        current_radius = int(max_radius * progress)
        
        # åˆ›å»ºåœ†å½¢é®ç½©
        mask = np.zeros((h, w), dtype=np.uint8)
        cv2.circle(mask, (center_x, center_y), current_radius, 255, -1)
        
        # åº”ç”¨é®ç½©
        mask_3channel = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        result = np.where(mask_3channel > 0, frame2, frame1)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def heart_open_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """å¿ƒå½¢æ‰“å¼€è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œè¿”å›åŸclip
    if clip2 is None:
        return clip1
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        frame1 = clip1.get_frame(clip1.duration - duration + t)
        frame2 = clip2.get_frame(t)
        
        h, w = frame1.shape[:2]
        center_x, center_y = w // 2, h // 2
        
        # åˆ›å»ºå¿ƒå½¢é®ç½©
        mask = np.zeros((h, w), dtype=np.uint8)
        scale = progress * 2
        
        # å¿ƒå½¢å‚æ•°æ–¹ç¨‹
        points = []
        for theta in np.linspace(0, 2 * np.pi, 100):
            x = 16 * (sin(theta) ** 3)
            y = -(13 * cos(theta) - 5 * cos(2*theta) - 2 * cos(3*theta) - cos(4*theta))
            x = int(center_x + x * scale * 5)
            y = int(center_y + y * scale * 5)
            if 0 <= x < w and 0 <= y < h:
                points.append([x, y])
        
        if len(points) > 2:
            cv2.fillPoly(mask, [np.array(points)], 255)
        
        # åº”ç”¨é®ç½©
        mask_3channel = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        result = np.where(mask_3channel > 0, frame2, frame1)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def dream_zoom_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """æ¢¦å¹»æ”¾å¤§è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œä½¿ç”¨zoom_inæ•ˆæœ
    if clip2 is None:
        return zoom_in(clip1, duration=min(duration, clip1.duration), intensity=0.5)
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        
        if progress < 0.5:
            frame = clip1.get_frame(clip1.duration - duration + t)
            scale = 1 + progress * 2
            blur_strength = progress * 10
        else:
            frame = clip2.get_frame(t)
            scale = 3 - progress * 2
            blur_strength = (1 - progress) * 10
        
        h, w = frame.shape[:2]
        
        # ç¼©æ”¾
        new_h, new_w = int(h * scale), int(w * scale)
        scaled = cv2.resize(frame, (new_w, new_h))
        
        # è£å‰ªä¸­å¿ƒéƒ¨åˆ†
        y_start = (new_h - h) // 2
        x_start = (new_w - w) // 2
        result = scaled[y_start:y_start+h, x_start:x_start+w]
        
        # æ·»åŠ æ¨¡ç³Šæ•ˆæœ
        if blur_strength > 0:
            result = cv2.GaussianBlur(result, (int(blur_strength) * 2 + 1, int(blur_strength) * 2 + 1), 0)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def glitch_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """æ•…éšœè½¬æ¢è½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œä½¿ç”¨glitchæ•ˆæœ
    if clip2 is None:
        return glitch(clip1, intensity=3)
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        
        if progress < 0.5:
            frame = clip1.get_frame(clip1.duration - duration + t)
        else:
            frame = clip2.get_frame(t)
        
        h, w = frame.shape[:2]
        result = frame.copy()
        
        # åœ¨è½¬åœºä¸­é—´æ·»åŠ æ•…éšœæ•ˆæœ
        if 0.3 < progress < 0.7:
            # éšæœºRGBé€šé“åç§»
            glitch_intensity = sin((progress - 0.3) * np.pi / 0.4) * 20
            
            # RGBé€šé“åˆ†ç¦»å’Œåç§»
            if len(frame.shape) == 3:
                r, g, b = cv2.split(result)
                
                # éšæœºåç§»
                shift_r = int(random.uniform(-glitch_intensity, glitch_intensity))
                shift_g = int(random.uniform(-glitch_intensity, glitch_intensity))
                shift_b = int(random.uniform(-glitch_intensity, glitch_intensity))
                
                r = np.roll(r, shift_r, axis=1)
                g = np.roll(g, shift_g, axis=1)
                b = np.roll(b, shift_b, axis=1)
                
                result = cv2.merge([r, g, b])
            
            # æ·»åŠ éšæœºå™ªç‚¹
            noise = np.random.randint(0, 50, (h, w, 3), dtype=np.uint8)
            result = cv2.add(result, noise)
            
            # éšæœºæ¨ªæ¡
            for _ in range(int(glitch_intensity)):
                y = random.randint(0, h - 10)
                result[y:y+random.randint(1, 5), :] = random.randint(0, 255)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

def clock_sweep_transition(clip1: VideoClip, clip2: VideoClip=None, duration=1.0):
    """æ—¶é’Ÿæ‰«æè½¬åœºæ•ˆæœ"""
    # å•ä¸ªclipæ—¶ï¼Œè¿”å›åŸclip
    if clip2 is None:
        return clip1
    
    def make_frame(t):
        progress = min(t / duration, 1.0)
        frame1 = clip1.get_frame(clip1.duration - duration + t)
        frame2 = clip2.get_frame(t)
        
        h, w = frame1.shape[:2]
        center_x, center_y = w // 2, h // 2
        
        # åˆ›å»ºæ‰‡å½¢é®ç½©
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # è®¡ç®—æ‰«æè§’åº¦
        sweep_angle = int(progress * 360)
        
        # åˆ›å»ºæ‰‡å½¢
        axes = (int(max(w, h)), int(max(w, h)))
        cv2.ellipse(mask, (center_x, center_y), axes, -90, 0, sweep_angle, 255, -1)
        
        # åº”ç”¨é®ç½©
        mask_3channel = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        result = np.where(mask_3channel > 0, frame2, frame1)
        
        return result
    
    return VideoClip(make_frame, duration=clip1.duration + clip2.duration - duration)

# è½¬åœºæ•ˆæœæ˜ å°„å­—å…¸
TRANSITIONS = {
    "leaf_flip": leaf_flip_transition,
    "å¶ç‰‡ç¿»è½¬": leaf_flip_transition,
    "blinds": blinds_transition,
    "ç™¾å¶çª—": blinds_transition,
    "wind_blow": wind_blow_transition,
    "é£å¹": wind_blow_transition,
    "rotate_zoom": rotate_zoom_transition,
    "æ—‹è½¬æ”¾å¤§": rotate_zoom_transition,
    "hexagon": hexagon_transition,
    "å…­è§’å½¢": hexagon_transition,
    "circle_open": circle_open_transition,
    "åœ†å½¢æ‰“å¼€": circle_open_transition,
    "heart_open": heart_open_transition,
    "å¿ƒå½¢æ‰“å¼€": heart_open_transition,
    "dream_zoom": dream_zoom_transition,
    "æ¢¦å¹»æ”¾å¤§": dream_zoom_transition,
    "glitch": glitch_transition,
    "æ•…éšœ": glitch_transition,
    "clock_sweep": clock_sweep_transition,
    "æ—¶é’Ÿæ‰«æ": clock_sweep_transition,
}

def apply_transition(clip1: VideoClip, clip2: VideoClip, transition_name: str, duration=1.0):
    """åº”ç”¨æŒ‡å®šçš„è½¬åœºæ•ˆæœ"""
    if transition_name in TRANSITIONS:
        return TRANSITIONS[transition_name](clip1, clip2, duration)
    else:
        print(f"æœªçŸ¥çš„è½¬åœºæ•ˆæœ: {transition_name}")
        # é»˜è®¤ä½¿ç”¨æ·¡å…¥æ·¡å‡º
        return concatenate_videoclips([clip1, clip2], method="compose")

if __name__ == '__main__':


    # # å›¾ç‰‡è·¯å¾„
    # image_path = "7A9D4C44D6474DE877C49012B777D11A.jpg"
    # clip=ImageClip(image_path)

    # # åˆ›å»ºå¤šä¸ªé•œå¤´æ•ˆæœç‰‡æ®µ
    # zoom = zoom_in(clip, duration=2, intensity=0.5)
    # pan_left = pan(clip, duration=2, intensity=150, direction='left')
    # # swing_clip = swing(clip, duration=2, amplitude=80, frequency=1.5)
    # rotate_clip = rotate(clip, duration=2, degrees=360)
    # follow_curve = follow(
    #     clip,
    #     duration=2,
    #     path_function=lambda t: (200 * t, 100 * np.sin(np.pi * t)),  # è´å¡å°”æ›²çº¿
    # )

    # # åˆæˆåˆ°ä¸€ä¸ªè§†é¢‘ä¸­
    # final_video = concatenate_videoclips([zoom, pan_left,  rotate_clip, follow_curve],method='compose')

    # # å¯¼å‡ºè§†é¢‘
    # final_video.write_videofile("dynamic_effects.mp4", fps=24,codec="libx264")
    video = VideoFileClip("cliptest/video3.mp4")

    # å¾„å‘æ¨¡ç³Šï¼Œä¸­å¿ƒåœ¨ (320, 240)ï¼Œæœ€å¤§æ¨¡ç³Šå¼ºåº¦ä¸º10
    radial_blurred_video = rotate(video)
    radial_blurred_video.write_videofile("cliptest/t1/radial_blur_output.mp4",fps=24, codec="libx264")