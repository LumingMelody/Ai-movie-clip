# -*- coding: utf-8 -*-
"""
å·¥ä½œæµåŸºç¡€ç±»æ¨¡å—
ä¸ºä¸åŒç±»å‹çš„è§†é¢‘ç”Ÿæˆå·¥ä½œæµæä¾›ç»Ÿä¸€çš„åŸºç¡€æ¡†æ¶
"""

import os
import uuid
import warnings
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, Union
from moviepy import (
    VideoFileClip, AudioFileClip, ImageClip, TextClip,
    CompositeVideoClip, concatenate_videoclips, CompositeAudioClip,
    afx
)
from moviepy.tools import close_all_clips

from config import get_user_data_dir
from .coze_client import CozeClient
from .font_manager import FontManager, TextClipCreator, check_font_environment
from .video_utils import (
    FileDownloader, AudioProcessor, VideoClipManager, ProjectManager,
    download_file, safe_load_audio, resolve_video_materials
)
from .digital_human import DigitalHumanGenerator

# å¿½ç•¥ MoviePy çš„èµ„æºæ¸…ç†è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="moviepy")


class BaseVideoWorkflow(ABC):
    """è§†é¢‘å·¥ä½œæµåŸºç¡€ç±»"""
    
    def __init__(self, user_data_dir: str = None):
        """
        åˆå§‹åŒ–åŸºç¡€å·¥ä½œæµ
        
        Args:
            user_data_dir: ç”¨æˆ·æ•°æ®ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.user_data_dir = user_data_dir or get_user_data_dir()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.font_manager = FontManager()
        self.text_creator = TextClipCreator(self.font_manager)
        self.coze_client = CozeClient()
        self.file_downloader = FileDownloader()
        self.audio_processor = AudioProcessor()
        self.video_manager = VideoClipManager()
        self.digital_human = DigitalHumanGenerator()
        
        # é¡¹ç›®ç®¡ç†
        self.project_id = str(uuid.uuid1())
        self.project_manager = ProjectManager(self.user_data_dir)
        self.project_path = self.project_manager.create_project_directory(self.project_id)
        
        # èµ„æºè·Ÿè¸ª
        self.video_clips = []
        self.audio_clips = []
        self.temp_files = []
        
        # åˆå§‹åŒ–å­—ä½“ç¯å¢ƒ
        check_font_environment()
    
    @abstractmethod
    def get_workflow_id(self) -> str:
        """è·å–Cozeå·¥ä½œæµID"""
        pass
    
    @abstractmethod
    def prepare_workflow_parameters(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡å·¥ä½œæµå‚æ•°"""
        pass
    
    @abstractmethod
    def process_workflow_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å·¥ä½œæµå“åº”"""
        pass
    
    @abstractmethod
    def create_video_clips(self, data: Dict[str, Any]) -> List[VideoFileClip]:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ"""
        pass
    
    def setup_materials_directories(self, subdirs: List[str]) -> Dict[str, str]:
        """
        è®¾ç½®ç´ æç›®å½•
        
        Args:
            subdirs: å­ç›®å½•åˆ—è¡¨ï¼Œå¦‚ ['moderator', 'enterprise']
            
        Returns:
            ç›®å½•è·¯å¾„å­—å…¸
        """
        directories = {}
        for subdir in subdirs:
            directories[subdir] = self.project_manager.create_materials_directory(subdir)
        return directories
    
    def download_resources(self, data: Dict[str, Any]) -> Dict[str, str]:
        """
        ä¸‹è½½åŸºç¡€èµ„æº
        
        Args:
            data: åŒ…å«èµ„æºURLçš„æ•°æ®
            
        Returns:
            ä¸‹è½½åçš„æœ¬åœ°è·¯å¾„å­—å…¸
        """
        resources = {}
        
        # ä¸‹è½½èƒŒæ™¯å›¾
        if 'data' in data and data['data']:
            try:
                bg_path = download_file(data['data'], "background.png", self.project_path)
                resources['background'] = bg_path
                print(f"âœ… èƒŒæ™¯å›¾ä¸‹è½½å®Œæˆ: {bg_path}")
            except Exception as e:
                print(f"âš ï¸ èƒŒæ™¯å›¾ä¸‹è½½å¤±è´¥: {e}")
        
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
        if 'audio_urls' in data and data['audio_urls']:
            audio_paths = []
            for i, url in enumerate(data['audio_urls']):
                try:
                    audio_path = download_file(url, f"audio_{i}.mp3", self.project_path)
                    audio_clip = safe_load_audio(audio_path)
                    if audio_clip:
                        self.audio_clips.append(audio_clip)
                        audio_paths.append(audio_path)
                        print(f"âœ… éŸ³é¢‘ {i} ä¸‹è½½å®Œæˆ: {audio_path}")
                    else:
                        print(f"âš ï¸ éŸ³é¢‘ {i} åŠ è½½å¤±è´¥: {audio_path}")
                except Exception as e:
                    print(f"âš ï¸ éŸ³é¢‘ {i} ä¸‹è½½å¤±è´¥: {e}")
            resources['audio_paths'] = audio_paths
        
        # ä¸‹è½½èƒŒæ™¯éŸ³ä¹
        if 'bgm' in data and data['bgm']:
            try:
                bgm_path = download_file(data['bgm'], "bgm.mp3", self.project_path)
                bgm_clip = safe_load_audio(bgm_path)
                if bgm_clip:
                    resources['bgm_clip'] = bgm_clip
                    resources['bgm_path'] = bgm_path
                    print(f"âœ… èƒŒæ™¯éŸ³ä¹ä¸‹è½½å®Œæˆ: {bgm_path}")
                else:
                    print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹åŠ è½½å¤±è´¥")
            except Exception as e:
                print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹ä¸‹è½½å¤±è´¥: {e}")
        
        return resources
    
    def create_text_clip(self, text: str, duration: float, is_title: bool = False) -> TextClip:
        """åˆ›å»ºæ–‡æœ¬ç‰‡æ®µ"""
        return self.text_creator.create_text_clip_safe(text, duration, is_title)
    
    def process_background_music(self, bgm_clip: AudioFileClip, final_video: VideoFileClip, volume: float = 0.3) -> CompositeAudioClip:
        """
        å¤„ç†èƒŒæ™¯éŸ³ä¹
        
        Args:
            bgm_clip: èƒŒæ™¯éŸ³ä¹ç‰‡æ®µ
            final_video: æœ€ç»ˆè§†é¢‘
            volume: èƒŒæ™¯éŸ³ä¹éŸ³é‡ï¼ˆ0-1ï¼‰
            
        Returns:
            åˆæˆåçš„éŸ³é¢‘
        """
        try:
            # è°ƒæ•´èƒŒæ™¯éŸ³ä¹é•¿åº¦åŒ¹é…è§†é¢‘
            if bgm_clip.duration < final_video.duration:
                try:
                    bgm_clip = bgm_clip.with_effects([afx.AudioLoop(duration=final_video.duration)])
                except:
                    # æ‰‹åŠ¨å¾ªç¯
                    print("âš ï¸ AudioLoopä¸å¯ç”¨ï¼Œä½¿ç”¨æ‰‹åŠ¨å¾ªç¯")
                    from moviepy import concatenate_audioclips
                    loops_needed = int(final_video.duration / bgm_clip.duration) + 1
                    bgm_clips = [bgm_clip] * loops_needed
                    bgm_clip = concatenate_audioclips(bgm_clips).subclipped(0, final_video.duration)
            else:
                bgm_clip = bgm_clip.subclipped(0, final_video.duration)
            
            # æ··åˆéŸ³é¢‘
            try:
                final_audio = CompositeAudioClip([
                    final_video.audio,
                    bgm_clip.with_effects([afx.MultiplyVolume(volume)])
                ])
            except:
                # å¦‚æœMultiplyVolumeä¸å¯ç”¨ï¼Œä½¿ç”¨volumex
                print("âš ï¸ MultiplyVolumeä¸å¯ç”¨ï¼Œä½¿ç”¨volumex")
                final_audio = CompositeAudioClip([
                    final_video.audio,
                    bgm_clip.volumex(volume)
                ])
            
            print("âœ… èƒŒæ™¯éŸ³ä¹æ··åˆæˆåŠŸ")
            return final_audio
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ··åˆå¤±è´¥: {e}")
            print("ä½¿ç”¨åŸå§‹éŸ³é¢‘...")
            return final_video.audio
    
    def generate_video(self, data: Dict[str, Any], **kwargs) -> str:
        """
        ç”Ÿæˆè§†é¢‘çš„ä¸»è¦æµç¨‹
        
        Args:
            data: è¾“å…¥æ•°æ®
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            ç”Ÿæˆçš„è§†é¢‘è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        """
        try:
            print(f"ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘ï¼Œé¡¹ç›®ID: {self.project_id}")
            
            # 1. ä¸‹è½½åŸºç¡€èµ„æº
            print("ğŸ“¥ ä¸‹è½½åŸºç¡€èµ„æº...")
            resources = self.download_resources(data)
            
            # 2. è°ƒç”¨Cozeå·¥ä½œæµï¼ˆå¦‚æœéœ€è¦ï¼‰
            if hasattr(self, 'use_coze_workflow') and self.use_coze_workflow:
                print("ğŸš€ è°ƒç”¨Cozeå·¥ä½œæµ...")
                workflow_params = self.prepare_workflow_parameters(data)
                workflow_response = self.coze_client.run_workflow(self.get_workflow_id(), workflow_params)
                processed_data = self.process_workflow_response(workflow_response)
                data.update(processed_data)
            
            # 3. åˆ›å»ºè§†é¢‘ç‰‡æ®µ
            print("ğŸï¸ åˆ›å»ºè§†é¢‘ç‰‡æ®µ...")
            video_clips = self.create_video_clips(data)
            self.video_clips.extend(video_clips)
            
            # 4. æ‹¼æ¥è§†é¢‘
            print("ğŸ”— æ‹¼æ¥è§†é¢‘ç‰‡æ®µ...")
            final_video = concatenate_videoclips(video_clips, method="compose")
            
            # 5. å¤„ç†èƒŒæ™¯éŸ³ä¹
            if 'bgm_clip' in resources:
                print("ğŸµ å¤„ç†èƒŒæ™¯éŸ³ä¹...")
                final_audio = self.process_background_music(resources['bgm_clip'], final_video)
                final_video = final_video.with_audio(final_audio)
            
            # 6. è¾“å‡ºè§†é¢‘
            output_path = os.path.join(self.project_path, "final_video.mp4")
            print(f"ğŸ’¾ å¼€å§‹ç”Ÿæˆè§†é¢‘: {output_path}")
            
            final_video.write_videofile(
                output_path,
                codec="libx264",
                fps=24,
                audio_codec="aac",
                threads=4,
                logger='bar'
            )
            
            # 7. è¿”å›ç›¸å¯¹è·¯å¾„
            relative_path = self.project_manager.get_relative_path(output_path)
            print(f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ: {relative_path}")
            
            return relative_path
            
        except Exception as e:
            print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            import traceback
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise
        
        finally:
            # æ¸…ç†èµ„æº
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†è§†é¢‘ç‰‡æ®µ
            for clip in self.video_clips:
                try:
                    clip.close()
                except:
                    pass
            
            # æ¸…ç†éŸ³é¢‘ç‰‡æ®µ
            for clip in self.audio_clips:
                try:
                    clip.close()
                except:
                    pass
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self.project_manager.cleanup_temp_files()
            self.digital_human.cleanup()
            
            # ä½¿ç”¨MoviePyçš„å…¨å±€æ¸…ç†
            close_all_clips()
            
            print("ğŸ—‘ï¸ èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ èµ„æºæ¸…ç†å¤±è´¥: {e}")


class AdvertisementWorkflow(BaseVideoWorkflow):
    """å¹¿å‘Šè§†é¢‘å·¥ä½œæµ"""
    
    def __init__(self, use_digital_host: bool = False, **kwargs):
        super().__init__(**kwargs)
        self.use_digital_host = use_digital_host
        self.use_coze_workflow = True
    
    def get_workflow_id(self) -> str:
        return '7499113029830049819'
    
    def prepare_workflow_parameters(self, data: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "company_name": data.get("company_name", ""),
            "service": data.get("service", ""),
            "topic": data.get("topic", ""),
            "content": data.get("content"),
            "need_change": data.get("need_change", False)
        }
    
    def process_workflow_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        # è¿™é‡Œå¤„ç†Cozeå·¥ä½œæµçš„å“åº”
        return response
    
    def create_video_clips(self, data: Dict[str, Any]) -> List[VideoFileClip]:
        """åˆ›å»ºå¹¿å‘Šè§†é¢‘ç‰‡æ®µ"""
        video_clips = []
        
        # è®¾ç½®ç´ æç›®å½•
        materials = self.setup_materials_directories(['moderator', 'enterprise'])
        
        # è·å–èƒŒæ™¯å›¾
        bg_image_path = os.path.join(self.project_path, "background.png")
        if not os.path.exists(bg_image_path):
            raise FileNotFoundError("èƒŒæ™¯å›¾ç‰‡æœªæ‰¾åˆ°")
        
        bg_image = ImageClip(bg_image_path)
        
        # å¤„ç†æ•°å­—äººè§†é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        start_clip = end_clip = None
        if self.use_digital_host:
            moderator_files = self.video_manager.get_video_files(materials['moderator'])
            if moderator_files:
                import random
                from core.clipgenerate.tongyi_get_online_url import get_online_url
                from core.clipgenerate.tongyi_get_videotalk import get_videotalk
                
                selected_host = random.choice([os.path.join(materials['moderator'], f) for f in moderator_files])
                host_url, _ = get_online_url(selected_host)
                
                # ç”Ÿæˆå¼€åœºå’Œç»“å°¾æ•°å­—äººè§†é¢‘
                start_url = get_videotalk(host_url, data["audio_urls"][0])
                end_url = get_videotalk(host_url, data["audio_urls"][-1])
                
                start_clip = VideoFileClip(download_file(start_url, "start.mp4", self.project_path))
                end_clip = VideoFileClip(download_file(end_url, "end.mp4", self.project_path))
        
        # è·å–ä¼ä¸šç´ æ
        enterprise_files = self.video_manager.get_video_files(materials['enterprise'])
        
        # åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        for i, (text, audio_clip) in enumerate(zip(data["output"], self.audio_clips)):
            print(f"ğŸ¬ åˆ›å»ºç¬¬ {i + 1} ä¸ªç‰‡æ®µ...")
            
            bg = bg_image.with_duration(audio_clip.duration)
            
            if self.use_digital_host:
                if i == 0:
                    # å¼€åœºç‰‡æ®µ
                    company_name = data.get("company_name", "å…¬å¸åç§°")
                    title_clip = self.create_text_clip(company_name, audio_clip.duration, is_title=True)
                    text_clip = self.create_text_clip(text, audio_clip.duration)
                    
                    composite = CompositeVideoClip([
                        bg,
                        start_clip.with_position(("center", "center")),
                        title_clip.with_position(("center", 0.2), relative=True),
                        text_clip.with_position(("center", 0.8), relative=True)
                    ]).with_audio(audio_clip)
                
                elif i == len(data["output"]) - 1:
                    # ç»“å°¾ç‰‡æ®µ
                    text_clip = self.create_text_clip(text, audio_clip.duration)
                    
                    composite = CompositeVideoClip([
                        bg,
                        end_clip.with_position(("center", "center")),
                        text_clip.with_position(("center", 0.8), relative=True)
                    ]).with_audio(audio_clip)
                
                else:
                    # ä¸­é—´ç‰‡æ®µï¼ˆä¼ä¸šè§†é¢‘ï¼‰
                    enterprise_video_index = i - 1
                    
                    if enterprise_video_index < len(enterprise_files):
                        # å¤„ç†ä¼ä¸šè§†é¢‘
                        video_path = os.path.join(materials['enterprise'], enterprise_files[enterprise_video_index])
                        video_clip = VideoFileClip(video_path).resized((1280, 720))
                        
                        # è°ƒæ•´è§†é¢‘æ—¶é•¿
                        video_clip = self.video_manager.smart_clip_duration(video_clip, audio_clip.duration)
                        text_clip = self.create_text_clip(text, audio_clip.duration)
                        
                        composite = CompositeVideoClip([
                            bg,
                            video_clip.with_position(("center", "center")),
                            text_clip.with_position(("center", 0.8), relative=True)
                        ]).with_audio(audio_clip)
                    else:
                        # æ²¡æœ‰è¶³å¤Ÿçš„ä¼ä¸šè§†é¢‘ï¼Œä½¿ç”¨èƒŒæ™¯å›¾ç‰‡
                        text_clip = self.create_text_clip(text, audio_clip.duration)
                        composite = CompositeVideoClip([
                            bg,
                            text_clip.with_position(("center", "center"), relative=True)
                        ]).with_audio(audio_clip)
            else:
                # ä¸ä½¿ç”¨æ•°å­—äºº
                text_clip = self.create_text_clip(text, audio_clip.duration)
                composite = CompositeVideoClip([
                    bg,
                    text_clip.with_position(("center", "center"), relative=True)
                ]).with_audio(audio_clip)
            
            video_clips.append(composite)
            print(f"âœ… ç¬¬ {i + 1} ä¸ªç‰‡æ®µåˆ›å»ºå®Œæˆ")
        
        return video_clips


class ClothesSceneWorkflow(BaseVideoWorkflow):
    """æœè£…åœºæ™¯è§†é¢‘å·¥ä½œæµ"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.use_coze_workflow = True
    
    def get_workflow_id(self) -> str:
        return '7494924152006295571'
    
    def prepare_workflow_parameters(self, data: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "has_figure": data.get("has_figure", False),
            "clothes": data.get("clothes"),
            "description": data.get("description", ""),
            "is_down": data.get("is_down", True),
        }
    
    def process_workflow_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        # å¤„ç†æœè£…åœºæ™¯å·¥ä½œæµçš„å“åº”
        return response
    
    def create_video_clips(self, data: Dict[str, Any]) -> List[VideoFileClip]:
        """åˆ›å»ºæœè£…åœºæ™¯è§†é¢‘ç‰‡æ®µ"""
        # è¿™é‡Œå®ç°æœè£…åœºæ™¯ç‰¹æœ‰çš„è§†é¢‘åˆ›å»ºé€»è¾‘
        video_clips = []
        # TODO: å®ç°å…·ä½“é€»è¾‘
        return video_clips


class DigitalHumanWorkflow(BaseVideoWorkflow):
    """æ•°å­—äººè§†é¢‘å·¥ä½œæµ"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.use_coze_workflow = False  # æ•°å­—äººå·¥ä½œæµä¸ä½¿ç”¨Coze
    
    def get_workflow_id(self) -> str:
        return ""  # æ•°å­—äººä¸ä½¿ç”¨å·¥ä½œæµ
    
    def prepare_workflow_parameters(self, data: Dict[str, Any]) -> Dict[str, Any]:
        return {}
    
    def process_workflow_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        return {}
    
    def create_video_clips(self, data: Dict[str, Any]) -> List[VideoFileClip]:
        """åˆ›å»ºæ•°å­—äººè§†é¢‘ç‰‡æ®µ"""
        # ç›´æ¥è°ƒç”¨æ•°å­—äººç”Ÿæˆå™¨
        result_path = self.digital_human.generate_digital_human_video(
            video_input=data.get("video_input"),
            topic=data.get("topic"),
            content=data.get("content"),
            audio_input=data.get("audio_input")
        )
        
        # è¿”å›ç”Ÿæˆçš„è§†é¢‘ä½œä¸ºç‰‡æ®µ
        if result_path and os.path.exists(os.path.join(self.user_data_dir, result_path)):
            full_path = os.path.join(self.user_data_dir, result_path)
            return [VideoFileClip(full_path)]
        else:
            raise Exception("æ•°å­—äººè§†é¢‘ç”Ÿæˆå¤±è´¥")


# å·¥ä½œæµå·¥å‚
class WorkflowFactory:
    """å·¥ä½œæµå·¥å‚ç±»"""
    
    @staticmethod
    def create_workflow(workflow_type: str, **kwargs) -> BaseVideoWorkflow:
        """
        åˆ›å»ºå·¥ä½œæµå®ä¾‹
        
        Args:
            workflow_type: å·¥ä½œæµç±»å‹ ('advertisement', 'clothes_scene', 'digital_human')
            **kwargs: å·¥ä½œæµå‚æ•°
            
        Returns:
            å·¥ä½œæµå®ä¾‹
        """
        workflows = {
            'advertisement': AdvertisementWorkflow,
            'clothes_scene': ClothesSceneWorkflow,
            'digital_human': DigitalHumanWorkflow,
        }
        
        if workflow_type not in workflows:
            raise ValueError(f"ä¸æ”¯æŒçš„å·¥ä½œæµç±»å‹: {workflow_type}")
        
        return workflows[workflow_type](**kwargs)


# ä¾¿æ·å‡½æ•°
def generate_advertisement_video(data: Dict[str, Any], use_digital_host: bool = False, **kwargs) -> str:
    """ç”Ÿæˆå¹¿å‘Šè§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    workflow = WorkflowFactory.create_workflow('advertisement', use_digital_host=use_digital_host, **kwargs)
    return workflow.generate_video(data)

def generate_clothes_scene_video(data: Dict[str, Any], **kwargs) -> str:
    """ç”Ÿæˆæœè£…åœºæ™¯è§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    workflow = WorkflowFactory.create_workflow('clothes_scene', **kwargs)
    return workflow.generate_video(data)

def generate_digital_human_video(data: Dict[str, Any], **kwargs) -> str:
    """ç”Ÿæˆæ•°å­—äººè§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    workflow = WorkflowFactory.create_workflow('digital_human', **kwargs)
    return workflow.generate_video(data)