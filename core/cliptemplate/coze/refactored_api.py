# -*- coding: utf-8 -*-
"""
é‡æ„åçš„ç»Ÿä¸€APIæ¥å£
æä¾›æ‰€æœ‰è§†é¢‘ç”ŸæˆåŠŸèƒ½çš„ç»Ÿä¸€è®¿é—®å…¥å£
åŒ…å« Coze è§†é¢‘ç”Ÿæˆ + Tongyi Wanxiang å›¾åƒ/è§†é¢‘ç”Ÿæˆ
"""
from typing import List

from core.cliptemplate.coze.base.video_generator import generate_video, VideoGeneratorFactory

# Coze è§†é¢‘ç”Ÿæˆæ¨¡å—
from core.cliptemplate.coze.video_advertsment_refactored import get_video_advertisement_refactored
from core.cliptemplate.coze.video_clicktype_refactored import get_video_clicktype_refactored
from core.cliptemplate.coze.video_digital_human_easy_refactored import get_video_digital_human_easy_refactored
from core.cliptemplate.coze.video_clothes_diffrenent_scene_refactored import get_video_clothes_diffrent_scene_refactored
from core.cliptemplate.coze.video_big_word_refactored import get_video_big_word_refactored
from core.cliptemplate.coze.video_catmeme_refactored import get_video_catmeme_refactored
from core.cliptemplate.coze.video_incitment_refactored import get_video_incitment_refactored
from core.cliptemplate.coze.video_introduction_refactored import get_video_introduction_refactored
from core.cliptemplate.coze.video_sinology_refactored import get_video_sinology_refactored
from core.cliptemplate.coze.video_stickman_refactored import get_video_stickman_refactored
from core.cliptemplate.coze.video_generate_live_refactored import get_video_generate_live_refactored

# Tongyi Wanxiang å›¾åƒ/è§†é¢‘ç”Ÿæˆæ¨¡å—
from core.clipgenerate.tongyi_wangxiang import (
    # æ–‡ç”Ÿå›¾ç³»åˆ—
    get_text_to_image_v2, get_text_to_image_v1,
    # å›¾åƒç¼–è¾‘ç³»åˆ—
    get_image_background_edit,
    # è™šæ‹Ÿæ¨¡ç‰¹ç³»åˆ—
    get_virtual_model_v1, get_virtual_model_v2, get_shoe_model,
    get_creative_poster, get_background_generation,
    # AIè¯•è¡£ç³»åˆ—
    get_ai_tryon_basic, get_ai_tryon_plus, get_ai_tryon_enhance,
    get_ai_tryon_segment,
    # è§†é¢‘ç”Ÿæˆç³»åˆ—
    get_image_to_video_advanced,
    # æ•°å­—äººè§†é¢‘ç³»åˆ—
    get_animate_anyone, get_emo_video, get_live_portrait,
    # è§†é¢‘é£æ ¼é‡ç»˜
    get_video_style_transform,
)

# å…¶ä»–è§†é¢‘å¤„ç†åŠŸèƒ½
from core.cliptemplate.coze.video_generate_live import process_single_video_by_url
from core.clipgenerate.interface_function import get_smart_clip_video
from core.cliptemplate.coze.video_dgh_img_insert import get_video_dgh_img_insert
from core.cliptemplate.coze.videos_clothes_fast_change import get_videos_clothes_fast_change


class UnifiedVideoAPI:
    """ç»Ÿä¸€çš„è§†é¢‘ç”ŸæˆAPIç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–API"""
        self.factory = VideoGeneratorFactory()
    
    def generate_advertisement(self, company_name: str, service: str, topic: str, **kwargs) -> str:
        """ç”Ÿæˆå¹¿å‘Šè§†é¢‘"""
        return get_video_advertisement_refactored(company_name, service, topic, **kwargs)
    
    def generate_clicktype(self, title: str, content: str, **kwargs) -> str:
        """ç”Ÿæˆç‚¹å‡»ç±»è§†é¢‘"""
        return get_video_clicktype_refactored(title, content, **kwargs)
    
    def generate_digital_human(self, video_url: str, title: str, **kwargs) -> str:
        """ç”Ÿæˆæ•°å­—äººè§†é¢‘"""
        from core.cliptemplate.coze.video_digital_human_easy import get_video_digital_huamn_easy_local
        # Extract parameters to match the original function signature
        content = kwargs.get('content', None)
        audio_input = kwargs.get('audio_input', None)
        add_subtitle = kwargs.get('add_subtitle', True)  # è·å–å­—å¹•å‚æ•°ï¼Œé»˜è®¤ä¸ºTrue
        return get_video_digital_huamn_easy_local(video_url, title, content, audio_input, add_subtitle)
    
    def generate_clothes_scene(self, has_figure: bool, clothes_url: str, description: str, **kwargs) -> str:
        """ç”Ÿæˆæœè£…åœºæ™¯è§†é¢‘"""
        return get_video_clothes_diffrent_scene_refactored(has_figure, clothes_url, description, **kwargs)
    
    def generate_big_word(self, text: str = None, company_name: str = None, title: str = None, 
                         product: str = None, description: str = None, content: str = None, **kwargs) -> str:
        """ç”Ÿæˆå¤§å­—æŠ¥è§†é¢‘"""
        # Map parameters to the original function expectations
        from core.cliptemplate.coze.video_big_word import get_big_word
        
        # Extract parameters - prioritize direct arguments, then kwargs, then defaults
        final_company_name = company_name or kwargs.get('company_name') or text or 'Company'
        final_title = title or kwargs.get('title') or text or 'Title' 
        final_product = product or kwargs.get('product') or 'Product'
        final_description = description or kwargs.get('description') or 'Description'
        final_content = content or kwargs.get('content', None)
        
        # ğŸ”¥ æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” [generate_big_word] è°ƒç”¨å‰å‚æ•°:")
        print(f"   final_company_name: {final_company_name}")
        print(f"   final_title: {final_title}")
        print(f"   final_product: {final_product}")
        print(f"   final_description: {final_description}")
        print(f"   final_content: {final_content}")
        
        return get_big_word(final_company_name, final_title, final_product, final_description, final_content)

    def generate_catmeme(self, dialogue: str = None, author: str = None, content: str = None, **kwargs) -> str:
        """ç”ŸæˆçŒ«å’ªè¡¨æƒ…åŒ…è§†é¢‘"""
        # Map parameters to the original function expectations
        from core.cliptemplate.coze.video_catmeme import get_video_catmeme
        
        # Use dialogue as title if provided, otherwise use kwargs
        title = dialogue or kwargs.get('title', '')
        author = author or kwargs.get('author', 'user')
        content = content or kwargs.get('content', None)
        
        return get_video_catmeme(author, title, content)
    
    def generate_incitement(self, theme: str, **kwargs) -> str:
        """ç”Ÿæˆç…½åŠ¨ç±»è§†é¢‘"""
        return get_video_incitment_refactored(theme, **kwargs)
    
    def generate_introduction(self, subject: str, details: str, **kwargs) -> str:
        """ç”Ÿæˆä»‹ç»ç±»è§†é¢‘"""
        return get_video_introduction_refactored(subject, details, **kwargs)
    
    def generate_sinology(self, classic: str, interpretation: str, **kwargs) -> str:
        """ç”Ÿæˆå›½å­¦ç±»è§†é¢‘"""
        return get_video_sinology_refactored(classic, interpretation, **kwargs)
    
    def generate_stickman(self, story: str, **kwargs) -> str:
        """ç”Ÿæˆç«æŸ´äººè§†é¢‘"""
        return get_video_stickman_refactored(story, **kwargs)
    
    def generate_live(self, live_content: str, **kwargs) -> str:
        """ç”Ÿæˆç›´æ’­è§†é¢‘"""
        return get_video_generate_live_refactored(live_content, **kwargs)
    
    def generate_video_by_type(self, video_type: str, **kwargs) -> str:
        """æ ¹æ®ç±»å‹ç”Ÿæˆè§†é¢‘ï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
        return generate_video(generator_type=video_type, **kwargs)
    
    def get_supported_types(self) -> list:
        """è·å–æ”¯æŒçš„è§†é¢‘ç±»å‹"""
        return self.factory.get_supported_types()
    
    # ========== æ•°å­—äººè§†é¢‘ç”Ÿæˆ ==========
    def process_video_by_url(self, video_url: str, **kwargs) -> str:
        """é€šè¿‡URLå¤„ç†å•ä¸ªè§†é¢‘"""
        return process_single_video_by_url(video_url, **kwargs)
    
    def get_smart_clip(self, video_path: str, **kwargs) -> str:
        """æ™ºèƒ½è§†é¢‘å‰ªè¾‘"""
        return get_smart_clip_video(video_path, **kwargs)
    
    # ========== Tongyi Wanxiang æ–‡ç”Ÿå›¾ç³»åˆ— ==========
    def text_to_image_v2(self, prompt: str, **kwargs) -> str:
        """é€šä¹‰ä¸‡ç›¸æ–‡ç”Ÿå›¾V2"""
        return get_text_to_image_v2(prompt, **kwargs)
    
    def text_to_image_v1(self, prompt: str, **kwargs) -> str:
        """é€šä¹‰ä¸‡ç›¸æ–‡ç”Ÿå›¾V1"""
        return get_text_to_image_v1(prompt, **kwargs)
    
    # ========== å›¾åƒç¼–è¾‘ç³»åˆ— ==========
    def image_background_edit(self, image_url: str, background_prompt: str, **kwargs) -> str:
        """å›¾åƒèƒŒæ™¯ç¼–è¾‘"""
        return get_image_background_edit(image_url, background_prompt, **kwargs)
    
    # ========== è™šæ‹Ÿæ¨¡ç‰¹ç³»åˆ— ==========
    def virtual_model_v1(self, base_image_url: str, prompt: str, **kwargs) -> str:
        """è™šæ‹Ÿæ¨¡ç‰¹V1"""
        return get_virtual_model_v1(base_image_url, prompt, **kwargs)
    
    def virtual_model_v2(self, base_image_url: str, prompt: str, **kwargs) -> str:
        """è™šæ‹Ÿæ¨¡ç‰¹V2"""
        return get_virtual_model_v2(base_image_url, prompt, **kwargs)
    
    def shoe_model(self, template_image_url: str, shoe_image_url: list, **kwargs) -> str:
        """é‹é´æ¨¡ç‰¹"""
        return get_shoe_model(template_image_url=template_image_url, shoe_image_url=shoe_image_url, **kwargs)
    
    def creative_poster(self, title: str, sub_title: str = None, body_text: str = None, prompt_text_zh: str = None, **kwargs) -> str:
        """åˆ›æ„æµ·æŠ¥ç”Ÿæˆ"""
        return get_creative_poster(title=title, sub_title=sub_title, body_text=body_text, prompt_text_zh=prompt_text_zh, **kwargs)
    
    def background_generation(self, base_image_url: str, background_prompt: str, **kwargs) -> str:
        """èƒŒæ™¯ç”Ÿæˆ"""
        return get_background_generation(base_image_url=base_image_url, ref_prompt=background_prompt, **kwargs)
    
    # ========== AIè¯•è¡£ç³»åˆ— ==========
    def ai_tryon_basic(self, person_image_url: str, top_garment_url: str = None, bottom_garment_url: str = None, **kwargs) -> str:
        """AIè¯•è¡£åŸºç¡€ç‰ˆ"""
        return get_ai_tryon_basic(person_image_url, top_garment_url, bottom_garment_url, **kwargs)
    
    def ai_tryon_plus(self, person_image_url: str, top_garment_url: str = None, bottom_garment_url: str = None, **kwargs) -> str:
        """AIè¯•è¡£Plusç‰ˆ"""
        return get_ai_tryon_plus(person_image_url, top_garment_url, bottom_garment_url, **kwargs)
    
    def ai_tryon_enhance(self, person_image_url: str, top_garment_url: str = None, bottom_garment_url: str = None, **kwargs) -> str:
        """AIè¯•è¡£å›¾ç‰‡ç²¾ä¿®"""
        return get_ai_tryon_enhance(person_image_url=person_image_url, top_garment_url=top_garment_url, bottom_garment_url=bottom_garment_url, **kwargs)
    
    def ai_tryon_segment(self, image_url: str, clothes_type: list, **kwargs) -> dict:
        """AIè¯•è¡£å›¾ç‰‡åˆ†å‰²"""
        return get_ai_tryon_segment(image_url=image_url, clothes_type=clothes_type, **kwargs)
    
    # ========== è§†é¢‘ç”Ÿæˆç³»åˆ— ==========
    def image_to_video_advanced(self, first_frame_url: str, last_frame_url: str, prompt: str, **kwargs) -> str:
        """å›¾ç”Ÿè§†é¢‘é«˜çº§ç‰ˆ"""
        return get_image_to_video_advanced(first_frame_url, last_frame_url, prompt, **kwargs)
    
    # ========== æ•°å­—äººè§†é¢‘ç³»åˆ— ==========
    def animate_anyone(self, image_url: str, dance_video_url: str, **kwargs) -> str:
        """èˆåŠ¨äººåƒ AnimateAnyone"""
        return get_animate_anyone(image_url=image_url, dance_video_url=dance_video_url, **kwargs)
    
    def emo_video(self, image_url: str, audio_url: str, **kwargs) -> str:
        """æ‚¦åŠ¨äººåƒEMO"""
        return get_emo_video(image_url=image_url, audio_url=audio_url, **kwargs)
    
    def live_portrait(self, image_url: str, audio_url: str, **kwargs) -> str:
        """çµåŠ¨äººåƒ LivePortrait"""
        return get_live_portrait(image_url=image_url, audio_url=audio_url, **kwargs)
    
    # ========== è§†é¢‘é£æ ¼é‡ç»˜ ==========
    def video_style_transfer(self, video_url: str, style: int, **kwargs) -> str:
        """è§†é¢‘é£æ ¼é‡ç»˜"""
        return get_video_style_transform(video_url=video_url, style=style, **kwargs)
    
    # ========== æ•°å­—äººå›¾ç‰‡æ’å…¥ ==========
    def dgh_img_insert(self, video_url: str, title: str = None, content: str = None, need_change: bool = False, **kwargs) -> str:
        """æ•°å­—äººå›¾ç‰‡æ’å…¥è§†é¢‘
        
        Args:
            video_url: è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–URL
            title: è§†é¢‘æ ‡é¢˜
            content: è§†é¢‘å†…å®¹æè¿°
            need_change: æ˜¯å¦éœ€è¦ä¿®æ”¹
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            str: å¤„ç†åçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        # ä»å‚æ•°ä¸­æå–ä¿¡æ¯ï¼Œæ”¯æŒä»kwargsä¸­è·å–
        final_title = title or kwargs.get('title', 'æ•°å­—äººå›¾ç‰‡æ’å…¥')
        final_content = content or kwargs.get('content', None)
        final_need_change = need_change or kwargs.get('need_change', False)
        
        # æå–æ–°çš„æ§åˆ¶å‚æ•°
        add_subtitle = kwargs.get('add_subtitle', True)
        insert_image = kwargs.get('insert_image', True)
        audio_url = kwargs.get('audio_url', None)  # ğŸ”¥ æ·»åŠ éŸ³é¢‘URLå‚æ•°

        # è°ƒç”¨å®é™…çš„å¤„ç†å‡½æ•°
        return get_video_dgh_img_insert(
            title=final_title,
            video_file_path=video_url,
            content=final_content,
            need_change=final_need_change,
            add_subtitle=add_subtitle,
            insert_image=insert_image,
            audio_url=audio_url  # ğŸ”¥ ä¼ é€’éŸ³é¢‘URLå‚æ•°
        )
    
    # ========== æœè£…å¿«é€Ÿæ¢è£… ==========
    def clothes_fast_change(self, model_image: str, clothes_list: list, change_speed: str = "normal", **kwargs) -> str:
        """æœè£…å¿«é€Ÿæ¢è£…è§†é¢‘
        
        Args:
            model_image: æ¨¡ç‰¹å›¾ç‰‡URL
            clothes_list: æœè£…åˆ—è¡¨
            change_speed: æ¢è£…é€Ÿåº¦ï¼Œé»˜è®¤ä¸º "normal"
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            str: å¤„ç†åçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        # ä»kwargsä¸­æå–å…¶ä»–å‚æ•°
        has_figure = kwargs.get('has_figure', True)
        description = kwargs.get('description', 'æœè£…å¿«é€Ÿæ¢è£…è§†é¢‘')
        is_down = kwargs.get('is_down', True)
        
        # è°ƒç”¨å®é™…çš„å¤„ç†å‡½æ•°
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæœè£…ä½œä¸ºç¤ºä¾‹
        clothes_url = clothes_list[0] if clothes_list else model_image
        return get_videos_clothes_fast_change(
            has_figure=has_figure,
            clothesurl=clothes_url,
            description=description,
            is_down=is_down
        )
    
    # ========== æ•°å­—äººå‰ªè¾‘ ==========
    def digital_human_clips(self, clips: list, transition: str = "fade", **kwargs) -> str:
        """æ•°å­—äººå‰ªè¾‘è§†é¢‘
        
        Args:
            clips: è§†é¢‘ç‰‡æ®µåˆ—è¡¨
            transition: è½¬åœºæ•ˆæœï¼Œé»˜è®¤ä¸º "fade"
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            str: å¤„ç†åçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦å®ç°ï¼Œéœ€è¦æ ¹æ®å®é™…éœ€æ±‚è¿›è¡Œå…·ä½“å®ç°
        # å¯ä»¥è°ƒç”¨æ™ºèƒ½å‰ªè¾‘åŠŸèƒ½æˆ–å…¶ä»–æ•°å­—äººå¤„ç†åŠŸèƒ½
        if clips and len(clips) > 0:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªclipä½œä¸ºè¾“å…¥
            first_clip = clips[0]
            video_path = first_clip.get('video_path') or first_clip.get('url')
            if video_path:
                return self.get_smart_clip(video_path, **kwargs)
        
        raise ValueError("æ•°å­—äººå‰ªè¾‘åŠŸèƒ½éœ€è¦è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘ç‰‡æ®µ")
    
    # ========== éšæœºè§†é¢‘ç”Ÿæˆ ==========
    def generate_random_video(self, enterprise: str, product: str, description: str, **kwargs) -> str:
        """ç”Ÿæˆéšæœºè§†é¢‘ï¼ˆä»å¤šç§ç±»å‹ä¸­éšæœºé€‰æ‹©ï¼‰
        
        Args:
            enterprise: ä¼ä¸šåç§°
            product: äº§å“åç§°
            description: æè¿°ä¿¡æ¯
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            str: å¤„ç†åçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        import random
        
        # å®šä¹‰å¯ç”¨çš„è§†é¢‘ç±»å‹
        video_types = [
            'advertisement',
            'clicktype', 
            'big_word',
            'catmeme',
            'incitement'
        ]
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘ç±»å‹
        selected_type = random.choice(video_types)
        
        # æ ¹æ®é€‰æ‹©çš„ç±»å‹è°ƒç”¨ç›¸åº”çš„æ–¹æ³•
        if selected_type == 'advertisement':
            return self.generate_advertisement(
                company_name=enterprise,
                service=product,
                topic=description,
                **kwargs
            )
        elif selected_type == 'clicktype':
            return self.generate_clicktype(
                title=f"{enterprise} - {product}",
                content=description,
                **kwargs
            )
        elif selected_type == 'big_word':
            return self.generate_big_word(
                company_name=enterprise,
                title=product,
                description=description,
                **kwargs
            )
        elif selected_type == 'catmeme':
            return self.generate_catmeme(
                dialogue=f"{enterprise} {product}",
                content=description,
                **kwargs
            )
        elif selected_type == 'incitement':
            return self.generate_incitement(
                theme=f"{enterprise} {product} {description}",
                **kwargs
            )
        else:
            # é»˜è®¤ä½¿ç”¨å¹¿å‘Šè§†é¢‘
            return self.generate_advertisement(
                company_name=enterprise,
                service=product,
                topic=description,
                **kwargs
            )
    
    # ========== é€šç”¨æ–¹æ³• ==========
    def get_all_supported_functions(self) -> dict:
        """è·å–æ‰€æœ‰æ”¯æŒçš„åŠŸèƒ½åˆ—è¡¨"""
        return {
            "coze_video_generation": [
                "generate_advertisement", "generate_clicktype", "generate_digital_human",
                "generate_clothes_scene", "generate_big_word", "generate_catmeme",
                "generate_incitement", "generate_introduction", "generate_sinology",
                "generate_stickman", "generate_live"
            ],
            "video_processing": [
                "process_video_by_url", "get_smart_clip"
            ],
            "wanxiang_text_to_image": [
                "text_to_image_v1", "text_to_image_v2"
            ],
            "wanxiang_image_edit": [
                "image_background_edit"
            ],
            "wanxiang_virtual_model": [
                "virtual_model_v1", "virtual_model_v2", "shoe_model", 
                "creative_poster", "background_generation"
            ],
            "wanxiang_ai_tryon": [
                "ai_tryon_basic", "ai_tryon_plus", "ai_tryon_enhance", "ai_tryon_segment"
            ],
            "wanxiang_video_generation": [
                "image_to_video_advanced"
            ],
            "wanxiang_digital_human": [
                "animate_anyone", "emo_video", "live_portrait"
            ],
            "wanxiang_video_style": [
                "video_style_transfer"
            ]
        }


# åˆ›å»ºå…¨å±€APIå®ä¾‹
video_api = UnifiedVideoAPI()

# ä¾¿æ·å‡½æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
def generate_advertisement_video(company_name: str, service: str, topic: str, **kwargs) -> str:
    """ç”Ÿæˆå¹¿å‘Šè§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    return video_api.generate_advertisement(company_name, service, topic, **kwargs)

def generate_clicktype_video(title: str, content: str, **kwargs) -> str:
    """ç”Ÿæˆç‚¹å‡»ç±»è§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    return video_api.generate_clicktype(title, content, **kwargs)

def generate_digital_human_video(video_input: str, topic: str, **kwargs) -> str:
    """ç”Ÿæˆæ•°å­—äººè§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    return video_api.generate_digital_human(video_input, topic, **kwargs)

def generate_clothes_scene_video(has_figure: bool, clothes_url: str, description: str, **kwargs) -> str:
    """ç”Ÿæˆæœè£…åœºæ™¯è§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    return video_api.generate_clothes_scene(has_figure, clothes_url, description, **kwargs)

def generate_any_video(video_type: str, **kwargs) -> str:
    """ç”Ÿæˆä»»æ„ç±»å‹è§†é¢‘çš„ä¾¿æ·å‡½æ•°"""
    return video_api.generate_video_by_type(video_type, **kwargs)

# ========== Tongyi Wanxiang ä¾¿æ·å‡½æ•° ==========
def wanxiang_text_to_image(prompt: str, version: str = "v2", **kwargs) -> str:
    """é€šä¹‰ä¸‡ç›¸æ–‡ç”Ÿå›¾ä¾¿æ·å‡½æ•°"""
    if version == "v2":
        return video_api.text_to_image_v2(prompt, **kwargs)
    else:
        return video_api.text_to_image_v1(prompt, **kwargs)

def wanxiang_ai_tryon(person_image_url: str, top_garment_url: str = None, bottom_garment_url: str = None, version: str = "basic", **kwargs) -> str:
    """é€šä¹‰ä¸‡ç›¸AIè¯•è¡£ä¾¿æ·å‡½æ•°"""
    if version == "plus":
        return video_api.ai_tryon_plus(person_image_url, top_garment_url, bottom_garment_url, **kwargs)
    else:
        return video_api.ai_tryon_basic(person_image_url, top_garment_url, bottom_garment_url, **kwargs)

def wanxiang_virtual_model(base_image_url: str, prompt: str, version: str = "v2", **kwargs) -> str:
    """é€šä¹‰ä¸‡ç›¸è™šæ‹Ÿæ¨¡ç‰¹ä¾¿æ·å‡½æ•°"""
    if version == "v1":
        return video_api.virtual_model_v1(base_image_url, prompt, **kwargs)
    else:
        return video_api.virtual_model_v2(base_image_url, prompt, **kwargs)

def wanxiang_digital_human_video(image_url: str, input_type: str, input_data: str, **kwargs) -> str:
    """é€šä¹‰ä¸‡ç›¸æ•°å­—äººè§†é¢‘ä¾¿æ·å‡½æ•°"""
    if input_type == "dance":
        return video_api.animate_anyone(image_url, input_data, **kwargs)
    elif input_type == "audio":
        return video_api.emo_video(image_url, input_data, **kwargs)
    elif input_type == "driving":
        return video_api.live_portrait(image_url, input_data, **kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {input_type}ã€‚æ”¯æŒ: dance, audio, driving")


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    api = UnifiedVideoAPI()
    
    print("ğŸš€ é‡æ„åçš„ç»Ÿä¸€è§†é¢‘ç”ŸæˆAPI")
    print(f"ğŸ“‹ æ”¯æŒçš„è§†é¢‘ç±»å‹: {api.get_supported_types()}")
    
    # æ˜¾ç¤ºæ‰€æœ‰æ”¯æŒçš„åŠŸèƒ½
    print(f"ğŸ¯ æ‰€æœ‰æ”¯æŒçš„åŠŸèƒ½: {api.get_all_supported_functions()}")
    
    # æµ‹è¯•ç¤ºä¾‹
    test_cases = [
        {
            'type': 'advertisement',
            'func': lambda: api.generate_advertisement("æµ‹è¯•å…¬å¸", "AIæœåŠ¡", "æŠ€æœ¯åˆ›æ–°"),
            'name': 'Cozeå¹¿å‘Šè§†é¢‘'
        },
        {
            'type': 'clicktype', 
            'func': lambda: api.generate_clicktype("éœ‡æƒŠæ ‡é¢˜", "ä½ ç»å¯¹æƒ³ä¸åˆ°çš„å†…å®¹"),
            'name': 'Cozeç‚¹å‡»ç±»è§†é¢‘'
        },
        {
            'type': 'text_to_image',
            'func': lambda: api.text_to_image_v2("ç¾ä¸½çš„é£æ™¯ç”»ï¼Œé«˜è´¨é‡ï¼Œ4K"),
            'name': 'é€šä¹‰ä¸‡ç›¸æ–‡ç”Ÿå›¾'
        },
        {
            'type': 'ai_tryon',
            'func': lambda: wanxiang_ai_tryon("person.jpg", "top.jpg", "bottom.jpg", "basic"),
            'name': 'é€šä¹‰ä¸‡ç›¸AIè¯•è¡£'
        }
    ]
    
    for case in test_cases:
        try:
            print(f"\nğŸ§ª æµ‹è¯• {case['name']}...")
            result = case['func']()
            print(f"âœ… {case['name']} æµ‹è¯•æˆåŠŸ: {result}")
        except Exception as e:
            print(f"âŒ {case['name']} æµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ‰ é‡æ„å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥ç”¨ç»Ÿä¸€çš„APIç”Ÿæˆæ‰€æœ‰ç±»å‹çš„è§†é¢‘äº†ï¼")