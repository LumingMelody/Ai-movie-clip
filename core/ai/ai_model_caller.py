# -*- coding: utf-8 -*-
"""
AIæ¨¡å‹è°ƒç”¨å™¨ - é‡æ„ç‰ˆæœ¬
åŠŸèƒ½ï¼šæ”¯æŒé€šä¹‰åƒé—®ç­‰å¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼
"""

import json
import time
import requests
import re
import os
from typing import Dict, Any, Optional, List

from core.utils.config_manager import config, ErrorHandler
from core.utils.env_config import get_dashscope_api_key


class AIModelCaller:
    """AIæ¨¡å‹è°ƒç”¨å™¨ - é‡æ„ç‰ˆæœ¬"""

    def __init__(self, api_key: str = None, model: str = None):
        """
        åˆå§‹åŒ–AIæ¨¡å‹è°ƒç”¨å™¨

        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®åŠ è½½
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
        """
        # åŠ è½½é…ç½®
        self.ai_config = config.get_config('ai')
        
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„api_keyï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è·å–
        self.api_key = api_key or get_dashscope_api_key()
        self.model = model or self.ai_config['default_model']
        self.base_url = self.ai_config['base_url']
        self.max_retries = self.ai_config['max_retries']
        self.timeout = self.ai_config['timeout']
        self.supported_models = self.ai_config['supported_models']

        self._validate_model()

    def _validate_model(self):
        """éªŒè¯æ¨¡å‹æ˜¯å¦æ”¯æŒ"""
        if self.model not in self.supported_models:
            ErrorHandler.log_warning(f"{self.model} ä¸åœ¨æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ä¸­")
            print(f"æ”¯æŒçš„æ¨¡å‹: {', '.join(self.supported_models)}")

    def generate_editing_plan(self, prompt: str, use_local: bool = False) -> Dict[str, Any]:
        """
        ç”Ÿæˆå‰ªè¾‘è®¡åˆ’

        Args:
            prompt: è¾“å…¥æç¤ºè¯
            use_local: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç­–ç•¥

        Returns:
            Dict: å‰ªè¾‘è®¡åˆ’
        """
        if use_local or not self.api_key:
            if not self.api_key:
                ErrorHandler.log_warning("æœªé…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨æœ¬åœ°ç­–ç•¥")
            return self._generate_local_plan(prompt)

        # åœ¨çº¿è°ƒç”¨ï¼Œå¸¦é‡è¯•æœºåˆ¶
        return self._try_online_generation(prompt)
    
    def _try_online_generation(self, prompt: str) -> Dict[str, Any]:
        """å°è¯•åœ¨çº¿ç”Ÿæˆï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        for attempt in range(self.max_retries):
            try:
                print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨{self.model} API... (å°è¯• {attempt + 1}/{self.max_retries})")
                return self._call_qwen_openai_compatible(prompt)

            except requests.exceptions.Timeout as e:
                if not self._handle_retry("APIè°ƒç”¨è¶…æ—¶", e, attempt):
                    break
            except requests.exceptions.RequestException as e:
                if not self._handle_retry("ç½‘ç»œè¯·æ±‚é”™è¯¯", e, attempt):
                    break
            except Exception as e:
                if not self._handle_retry("APIè°ƒç”¨", e, attempt):
                    break
        
        ErrorHandler.log_warning("æ‰€æœ‰åœ¨çº¿å°è¯•éƒ½å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°ç­–ç•¥")
        return self._generate_local_plan(prompt)
    
    def _handle_retry(self, error_type: str, error: Exception, attempt: int) -> bool:
        """å¤„ç†é‡è¯•é€»è¾‘"""
        ErrorHandler.handle_api_error(error_type, error, attempt + 1)
        
        if attempt < self.max_retries - 1:
            wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…
            print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
            time.sleep(wait_time)
            return True
        return False

    def _call_qwen_openai_compatible(self, prompt: str) -> Dict[str, Any]:
        """è°ƒç”¨Qwen API - OpenAIå…¼å®¹æ ¼å¼"""

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        # ğŸ”¥ å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ - æ”¯æŒå¤šç‰‡æ®µç­–ç•¥
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘AIåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„è§†é¢‘åˆ†æç»“æœï¼Œç”ŸæˆJSONæ ¼å¼çš„å¤šç‰‡æ®µå‰ªè¾‘ç­–ç•¥ã€‚

        ### ğŸ¯ æ ¸å¿ƒç­–ç•¥ï¼šæ™ºèƒ½å¤šç‰‡æ®µç»„åˆ
        ä½ çš„ä»»åŠ¡æ˜¯å°†é•¿è§†é¢‘æ™ºèƒ½æ‹†åˆ†æˆå¤šä¸ªç²¾å½©ç‰‡æ®µï¼Œç„¶åç»„åˆæˆç›®æ ‡æ—¶é•¿çš„çŸ­è§†é¢‘ã€‚è¿™æ¯”å•çº¯æˆªå–ä¸€ä¸ªè¿ç»­æ®µè½æ›´åŠ æ™ºèƒ½å’Œæœ‰è¶£ã€‚

        ### ğŸ“Š è¾“å…¥æ•°æ®æ ¼å¼ï¼š
        {
            "metadata": { 
                "duration": <float>,     # è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
                "width": <int>, "height": <int>, 
                "fps": <float>
            },
            "classification": {
                "content_type": "å¹¿å‘Šå®£ä¼ ç‰‡ç±»",  # æ•™è‚²æ•™å­¦/å¹¿å‘Šå®£ä¼ /ç›´æ’­å½•æ’­/äººå£°å‰§æƒ…/åŠ¨ä½œè¿åŠ¨ç­‰
                "mood": "æ¿€æ˜‚",               # ç´§å¼ /å®é™/æ¬¢å¿«/æ„ŸåŠ¨ç­‰
                "style": "æŠ–éŸ³é£",            # æŠ–éŸ³é£/Vlogé£/ç”µå½±æ„Ÿ/çºªå½•ç‰‡é£ç­‰
                "purpose": "ç¤¾äº¤åª’ä½“"         # æ•™å­¦åŸ¹è®­/ä¼ä¸šå®£ä¼ /ç¤¾äº¤åª’ä½“/ä¸ªäººè®°å½•ç­‰
            },
            "scene_changes": [[start1, end1], [start2, end2], ...],  # åœºæ™¯åˆ‡æ¢æ—¶é—´æˆ³
            "speech_text": "å®Œæ•´çš„è¯­éŸ³è¯†åˆ«æ–‡æœ¬...",
            "speech_timestamps": {
                "segments": [
                    {"start": 10.5, "end": 13.2, "text": "å¥å­1", "duration": 2.7},
                    {"start": 13.5, "end": 16.8, "text": "å¥å­2", "duration": 3.3}
                ],
                "best_segments": [  # é¢„åˆ†æçš„æœ€ä½³è¯­éŸ³ç‰‡æ®µ
                    {"start": 120.0, "end": 150.0, "duration": 30.0, "word_density": 1.5},
                    {"start": 200.0, "end": 225.0, "duration": 25.0, "word_density": 1.3}
                ]
            },
            "highlights": [  # ç³»ç»Ÿé¢„æ¨èçš„ç²¾å½©æ—¶é—´æ®µ
                {"start_time": 45.0, "end_time": 60.0, "reason": "åœºæ™¯1", "confidence": 0.8},
                {"start_time": 120.0, "end_time": 140.0, "reason": "é«˜äº’åŠ¨ç‰‡æ®µ", "confidence": 0.9}
            ],
            "objects_detected": {"person": {"count": 15, "avg_confidence": 0.85}},
            "face_detected": true,
            "music_analysis": {"tempo": 128, "energy": 0.75, "chroma_mean": 0.6}
        }

        ### ğŸ§  å¤šç‰‡æ®µç­–ç•¥ç”ŸæˆæŒ‡å—ï¼š

        #### 1. ç‰‡æ®µé€‰æ‹©ç­–ç•¥ï¼š
        - **å¼€å¤´å¸å¼•** (3-8ç§’): é€‰æ‹©æœ€å¸å¼•äººçš„å¼€åœºï¼Œé€šå¸¸æ˜¯é«˜èƒ½é‡æˆ–å…³é”®ä¿¡æ¯
        - **æ ¸å¿ƒå†…å®¹** (15-20ç§’): é€‰æ‹©2-3ä¸ªæ ¸å¿ƒç‰‡æ®µï¼Œä¿æŒé€»è¾‘è¿è´¯
        - **ç²¾å½©æ”¶å°¾** (3-7ç§’): å¼ºæœ‰åŠ›çš„ç»“å°¾ï¼Œç•™ä¸‹æ·±åˆ»å°è±¡

        #### 2. ä¸åŒå†…å®¹ç±»å‹çš„å¤šç‰‡æ®µç­–ç•¥ï¼š
        - **æ•™è‚²æ•™å­¦ç±»**: å¼€åœºé—®é¢˜ + æ ¸å¿ƒçŸ¥è¯†ç‚¹ + æ€»ç»“å›é¡¾
        - **å¹¿å‘Šå®£ä¼ ç±»**: äº§å“äº®ç›¸ + æ ¸å¿ƒå–ç‚¹ + è¡ŒåŠ¨å¬å”¤
        - **ç›´æ’­å½•æ’­ç±»**: å¼€åœºäº’åŠ¨ + é«˜æ½®æ—¶åˆ» + ç²¾å½©ååº”
        - **äººå£°å‰§æƒ…ç±»**: å†²çªè®¾ç½® + æƒ…æ„Ÿé«˜æ½® + ç»“æœæ­æ™“
        - **åŠ¨ä½œè¿åŠ¨ç±»**: å‡†å¤‡åŠ¨ä½œ + å…³é”®æ—¶åˆ» + ç»“æœå±•ç¤º

        #### 3. ç‰‡æ®µæ—¶é•¿åˆ†é…å»ºè®®ï¼š
        - 30ç§’ç›®æ ‡ï¼š3-5ä¸ªç‰‡æ®µï¼Œæ¯ä¸ª5-10ç§’
        - 60ç§’ç›®æ ‡ï¼š4-7ä¸ªç‰‡æ®µï¼Œæ¯ä¸ª8-15ç§’
        - ä¿æŒèŠ‚å¥æ„Ÿï¼Œé¿å…å•ä¸ªç‰‡æ®µè¿‡é•¿

        ### ğŸ“¦ æ–°çš„è¾“å‡ºæ ¼å¼ - å¤šç‰‡æ®µç­–ç•¥ï¼š
        {
            "target_duration": 30,
            "strategy_type": "multi_segment",
            "actions": [
                {
                    "action": "extract_segment",
                    "start": 10.5,
                    "end": 18.2,
                    "duration": 7.7,
                    "reason": "å¼€åœºå¸å¼•ï¼šäº§å“äº®ç›¸ï¼ŒæŠ“ä½æ³¨æ„åŠ›",
                    "segment_role": "opening",
                    "priority": 1
                },
                {
                    "action": "extract_segment", 
                    "start": 45.0,
                    "end": 58.0,
                    "duration": 13.0,
                    "reason": "æ ¸å¿ƒå†…å®¹ï¼šå±•ç¤ºä¸»è¦åŠŸèƒ½ç‰¹ç‚¹",
                    "segment_role": "main_content",
                    "priority": 1
                },
                {
                    "action": "extract_segment",
                    "start": 120.5,
                    "end": 129.0, 
                    "duration": 8.5,
                    "reason": "ç²¾å½©æ”¶å°¾ï¼šç”¨æˆ·å¥½è¯„åé¦ˆ",
                    "segment_role": "closing",
                    "priority": 1
                },
                {
                    "action": "apply_transitions",
                    "transition_type": "crossfade",
                    "duration": 0.5,
                    "between_segments": true,
                    "reason": "ç‰‡æ®µé—´å¹³æ»‘è¿‡æ¸¡"
                },
                {
                    "action": "apply_filter",
                    "filter_name": "enhance",
                    "intensity": 0.3,
                    "apply_to": "all_segments",
                    "reason": "æ•´ä½“è§†è§‰å¢å¼º"
                }
            ],
            "segments_summary": {
                "total_segments": 3,
                "estimated_duration": 29.2,
                "coverage_ratio": 0.026  // è¦†ç›–åŸè§†é¢‘çš„æ¯”ä¾‹
            },
            "metadata": {
                "description": "æ™ºèƒ½å¤šç‰‡æ®µç»„åˆç­–ç•¥ï¼šå¼€åœºå¸å¼•+æ ¸å¿ƒå±•ç¤º+ç²¾å½©æ”¶å°¾",
                "confidence": 0.9,
                "strategy_reasoning": "æ ¹æ®å¹¿å‘Šå®£ä¼ ç‰‡çš„ç‰¹ç‚¹ï¼Œé€‰æ‹©æœ€å…·å¸å¼•åŠ›çš„å¼€åœºã€æ ¸å¿ƒå–ç‚¹å±•ç¤ºå’Œç”¨æˆ·åé¦ˆæ”¶å°¾ï¼Œå½¢æˆå®Œæ•´çš„è¥é”€é—­ç¯"
            }
        }

        ### ğŸ¬ æ–°å¢çš„Actionç±»å‹ï¼š

        #### extract_segmentï¼ˆæ ¸å¿ƒæ–°å¢ï¼‰ï¼š
        - **ä½œç”¨**: æå–ç‰¹å®šæ—¶é—´æ®µçš„è§†é¢‘ç‰‡æ®µ
        - **å¿…éœ€å‚æ•°**: start, end, duration, reason
        - **å¯é€‰å‚æ•°**: segment_role (opening/main_content/supporting/closing), priority (1-3)
        - **segment_roleè¯´æ˜**:
          - opening: å¼€åœºç‰‡æ®µï¼Œç”¨äºå¸å¼•æ³¨æ„åŠ›
          - main_content: ä¸»è¦å†…å®¹ï¼Œæ ¸å¿ƒä¿¡æ¯
          - supporting: æ”¯æ’‘å†…å®¹ï¼Œè¡¥å……è¯´æ˜
          - closing: æ”¶å°¾ç‰‡æ®µï¼Œå¼ºåŒ–å°è±¡

        #### apply_transitionsï¼ˆå¢å¼ºï¼‰ï¼š
        - **between_segments**: true è¡¨ç¤ºåº”ç”¨äºç‰‡æ®µä¹‹é—´
        - **transition_type**: crossfade, slide, zoom, flashç­‰

        #### apply_filterï¼ˆå¢å¼ºï¼‰ï¼š
        - **apply_to**: "all_segments" | "segment_1" | "segment_2" ç­‰

        ### ğŸ’¡ ç­–ç•¥ç”Ÿæˆè¦ç‚¹ï¼š
        1. **åˆ†æè¾“å…¥æ•°æ®**: å……åˆ†åˆ©ç”¨scene_changesã€speech_timestampsã€highlightsç­‰ä¿¡æ¯
        2. **ä¿æŒé€»è¾‘æ€§**: ç¡®ä¿é€‰æ‹©çš„ç‰‡æ®µèƒ½å½¢æˆå®Œæ•´çš„æ•…äº‹çº¿
        3. **æ§åˆ¶æ€»æ—¶é•¿**: æ‰€æœ‰extract_segmentçš„durationæ€»å’Œåº”æ¥è¿‘target_duration
        4. **è€ƒè™‘è½¬åœºæ—¶é—´**: é¢„ç•™0.5-1ç§’çš„è½¬åœºæ—¶é—´
        5. **ä¼˜å…ˆçº§æ’åº**: é‡è¦ç‰‡æ®µpriority=1ï¼Œæ¬¡è¦ç‰‡æ®µpriority=2-3

        ### ğŸ¯ è¾“å‡ºè¦æ±‚ï¼š
        - å¿…é¡»åŒ…å«3-7ä¸ªextract_segmentåŠ¨ä½œ
        - æ€»estimated_durationåº”åœ¨target_durationçš„Â±10%èŒƒå›´å†…
        - æ¯ä¸ªsegmentå¿…é¡»æœ‰æ˜ç¡®çš„reasonå’Œsegment_role
        - æä¾›strategy_reasoningè§£é‡Šé€‰æ‹©é€»è¾‘

        è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¿”å›å¤šç‰‡æ®µå‰ªè¾‘ç­–ç•¥ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ–‡å­—ï¼Œä»…è¿”å›JSONå†…å®¹ã€‚"""

        # OpenAIå…¼å®¹æ ¼å¼çš„è¯·æ±‚ä½“
        data = self._build_request_data(system_prompt, prompt)

        return self._make_api_request(headers, data, prompt)
    
    def _build_request_data(self, system_prompt: str, prompt: str) -> Dict[str, Any]:
        """æ„å»ºè¯·æ±‚æ•°æ®"""
        return {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt + "\n\nè¯·ç”Ÿæˆæ™ºèƒ½å¤šç‰‡æ®µå‰ªè¾‘ç­–ç•¥ã€‚ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ã€‚"}
            ],
            "max_tokens": self.ai_config['max_tokens'],
            "temperature": self.ai_config['temperature']
        }
    
    def _make_api_request(self, headers: Dict[str, str], data: Dict[str, Any], prompt: str) -> Dict[str, Any]:
        """æ‰§è¡ŒAPIè¯·æ±‚"""
        url = f"{self.base_url}/chat/completions"
        
        print(f"ğŸ“¡ æ­£åœ¨è°ƒç”¨ {self.model} API...")
        response = requests.post(url, json=data, headers=headers, timeout=self.timeout)
        
        if response.status_code == 200:
            return self._process_successful_response(response, prompt)
        else:
            raise Exception(self._build_error_message(response))
    
    def _process_successful_response(self, response, prompt: str) -> Dict[str, Any]:
        """å¤„ç†æˆåŠŸçš„APIå“åº”"""
        result = response.json()
        content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
        
        print(f"AIç­–ç•¥: {content[:200]}...")  # åªæ˜¾ç¤ºå‰200å­—ç¬¦
        ErrorHandler.log_success(f"APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
        
        # è§£æAIå“åº”
        plan = self._parse_ai_response(content)
        if plan and self._validate_multi_segment_plan(plan):
            ErrorHandler.log_success("AIç­–ç•¥è§£ææˆåŠŸ")
            return plan
        else:
            ErrorHandler.log_warning("ç­–ç•¥éªŒè¯å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç­–ç•¥")
            return self._generate_local_multi_segment_plan(prompt)
    
    def _build_error_message(self, response) -> str:
        """æ„å»ºé”™è¯¯æ¶ˆæ¯"""
        error_msg = f"APIè°ƒç”¨å¤±è´¥: {response.status_code}"
        if response.text:
            try:
                error_detail = response.json()
                error_msg += f" - {error_detail.get('error', {}).get('message', response.text)}"
            except:
                error_msg += f" - {response.text}"
        return error_msg

    def _validate_multi_segment_plan(self, plan: Dict[str, Any]) -> bool:
        """éªŒè¯å¤šç‰‡æ®µå‰ªè¾‘è®¡åˆ’çš„æ ¼å¼æ˜¯å¦æ­£ç¡®"""
        try:
            # åŸºç¡€éªŒè¯
            if not self._validate_plan(plan):
                return False

            # æ£€æŸ¥æ˜¯å¦æœ‰extract_segmentåŠ¨ä½œ
            actions = plan.get('actions', [])
            extract_segments = [a for a in actions if a.get('action') == 'extract_segment']

            if len(extract_segments) < 2:
                print(f"âš ï¸ å¤šç‰‡æ®µç­–ç•¥è‡³å°‘éœ€è¦2ä¸ªç‰‡æ®µï¼Œå½“å‰åªæœ‰{len(extract_segments)}ä¸ª")
                return False

            # æ£€æŸ¥ç‰‡æ®µå‚æ•°å®Œæ•´æ€§
            for segment in extract_segments:
                required_fields = ['start', 'end', 'duration', 'reason']
                if not all(field in segment for field in required_fields):
                    print(f"âš ï¸ ç‰‡æ®µç¼ºå°‘å¿…éœ€å­—æ®µ: {segment}")
                    return False

            # æ£€æŸ¥æ€»æ—¶é•¿æ˜¯å¦åˆç†
            total_duration = sum(s.get('duration', 0) for s in extract_segments)
            target_duration = plan.get('target_duration', 30)

            if abs(total_duration - target_duration) > target_duration * 0.2:  # å…è®¸20%è¯¯å·®
                print(f"âš ï¸ æ€»æ—¶é•¿åå·®è¿‡å¤§: ç›®æ ‡{target_duration}s, å®é™…{total_duration}s")
                return False

            print(f"âœ… å¤šç‰‡æ®µç­–ç•¥éªŒè¯é€šè¿‡: {len(extract_segments)}ä¸ªç‰‡æ®µ, æ€»æ—¶é•¿{total_duration:.1f}s")
            return True

        except Exception as e:
            print(f"âš ï¸ å¤šç‰‡æ®µç­–ç•¥éªŒè¯å¼‚å¸¸: {e}")
            return False

    def _generate_local_multi_segment_plan(self, prompt: str) -> Dict[str, Any]:
        """æœ¬åœ°ç”Ÿæˆå¤šç‰‡æ®µå‰ªè¾‘è®¡åˆ’ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("ğŸ  ä½¿ç”¨æœ¬åœ°æ™ºèƒ½å¤šç‰‡æ®µç­–ç•¥")

        # ä»promptä¸­æå–ç›®æ ‡æ—¶é•¿å’Œè§†é¢‘ä¿¡æ¯
        target_duration = 30
        video_duration = 1200  # é»˜è®¤20åˆ†é’Ÿï¼Œåº”è¯¥ä»promptä¸­è§£æ

        # è§£æè§†é¢‘æ—¶é•¿
        duration_match = re.search(r'"duration":\s*(\d+\.?\d*)', prompt)
        if duration_match:
            video_duration = float(duration_match.group(1))

        # è§£æç›®æ ‡æ—¶é•¿
        target_match = re.search(r'ç›®æ ‡æ—¶é•¿[ï¼š:]\s*(\d+)', prompt)
        if target_match:
            target_duration = int(target_match.group(1))

        # æ™ºèƒ½ç‰‡æ®µåˆ†é…ç­–ç•¥
        if video_duration <= 60:
            # çŸ­è§†é¢‘ï¼šé€‰æ‹©2-3ä¸ªç‰‡æ®µ
            segments = [
                {"start": 5, "duration": target_duration * 0.4, "role": "opening"},
                {"start": video_duration * 0.6, "duration": target_duration * 0.6, "role": "main_content"}
            ]
        elif video_duration <= 300:
            # ä¸­é•¿è§†é¢‘ï¼šé€‰æ‹©3-4ä¸ªç‰‡æ®µ
            segments = [
                {"start": 10, "duration": target_duration * 0.25, "role": "opening"},
                {"start": video_duration * 0.3, "duration": target_duration * 0.4, "role": "main_content"},
                {"start": video_duration * 0.75, "duration": target_duration * 0.35, "role": "closing"}
            ]
        else:
            # é•¿è§†é¢‘ï¼šé€‰æ‹©4-5ä¸ªç‰‡æ®µ
            segments = [
                {"start": 15, "duration": target_duration * 0.2, "role": "opening"},
                {"start": video_duration * 0.2, "duration": target_duration * 0.3, "role": "main_content"},
                {"start": video_duration * 0.5, "duration": target_duration * 0.25, "role": "supporting"},
                {"start": video_duration * 0.8, "duration": target_duration * 0.25, "role": "closing"}
            ]

        # ç”Ÿæˆextract_segmentåŠ¨ä½œ
        actions = []
        for i, seg in enumerate(segments):
            start = seg["start"]
            duration = seg["duration"]
            end = start + duration

            # ç¡®ä¿ä¸è¶…å‡ºè§†é¢‘èŒƒå›´
            if end > video_duration:
                end = video_duration
                duration = end - start

            if duration > 2:  # åªæ·»åŠ æœ‰æ„ä¹‰é•¿åº¦çš„ç‰‡æ®µ
                actions.append({
                    "action": "extract_segment",
                    "start": start,
                    "end": end,
                    "duration": duration,
                    "reason": f"æœ¬åœ°ç­–ç•¥ï¼š{seg['role']}ç‰‡æ®µ",
                    "segment_role": seg["role"],
                    "priority": 1
                })

        # æ·»åŠ è½¬åœºå’Œæ»¤é•œ
        actions.append({
            "action": "apply_transitions",
            "transition_type": "crossfade",
            "duration": 0.5,
            "between_segments": True,
            "reason": "ç‰‡æ®µé—´å¹³æ»‘è¿‡æ¸¡"
        })

        # æ ¹æ®å†…å®¹ç±»å‹æ·»åŠ åˆé€‚çš„æ»¤é•œ
        if 'æŠ–éŸ³' in prompt or 'ç¤¾äº¤' in prompt:
            actions.append({
                "action": "apply_filter",
                "filter_name": "vibrant",
                "intensity": 0.4,
                "apply_to": "all_segments",
                "reason": "ç¤¾äº¤åª’ä½“é£æ ¼å¢å¼º"
            })
        else:
            actions.append({
                "action": "apply_filter",
                "filter_name": "enhance",
                "intensity": 0.3,
                "apply_to": "all_segments",
                "reason": "æ•´ä½“è§†è§‰å¢å¼º"
            })

        # è®¡ç®—æ€»æ—¶é•¿
        total_duration = sum(a.get('duration', 0) for a in actions if a.get('action') == 'extract_segment')
        segment_count = len([a for a in actions if a.get('action') == 'extract_segment'])

        return {
            "target_duration": target_duration,
            "strategy_type": "multi_segment",
            "actions": actions,
            "segments_summary": {
                "total_segments": segment_count,
                "estimated_duration": total_duration,
                "coverage_ratio": round(total_duration / video_duration, 3)
            },
            "metadata": {
                "description": f"æœ¬åœ°å¤šç‰‡æ®µç­–ç•¥ï¼š{segment_count}ä¸ªæ™ºèƒ½é€‰æ‹©çš„ç‰‡æ®µ",
                "confidence": 0.7,
                "source": "local_multi_segment",
                "strategy_reasoning": "åŸºäºè§†é¢‘æ—¶é•¿å’Œå†…å®¹ç‰¹ç‚¹ï¼Œæ™ºèƒ½é€‰æ‹©å¼€å¤´ã€æ ¸å¿ƒå’Œç»“å°¾ç‰‡æ®µ"
            }
        }

    def _parse_ai_response(self, content: str) -> Optional[Dict[str, Any]]:
        """è§£æAIå“åº”ï¼Œæå–JSONæ ¼å¼çš„å‰ªè¾‘è®¡åˆ’"""

        # æ–¹æ³•1: ç›´æ¥è§£æ
        try:
            plan = json.loads(content.strip())
            if self._validate_plan(plan):
                return plan
        except json.JSONDecodeError:
            pass

        # æ–¹æ³•2: æå–JSONå—
        json_plan = self._extract_json_from_text(content)
        if json_plan and self._validate_plan(json_plan):
            return json_plan

        # æ–¹æ³•3: æ™ºèƒ½æå–å…³é”®ä¿¡æ¯
        return self._extract_plan_from_text(content)

    def _extract_json_from_text(self, text: str) -> Optional[Dict[str, Any]]:
        """ä»æ–‡æœ¬ä¸­æå–JSON"""
        try:
            # å¯»æ‰¾JSONå—çš„å¤šç§æ¨¡å¼
            patterns = [
                r'```json\s*(.*?)\s*```',  # ```json ... ```
                r'```\s*(.*?)\s*```',  # ``` ... ```
                r'({.*?})',  # { ... }
            ]

            for pattern in patterns:
                matches = re.findall(pattern, text, re.DOTALL)
                for match in matches:
                    try:
                        # æ¸…ç†æ–‡æœ¬
                        json_str = match.strip()
                        if json_str.startswith('{') and json_str.endswith('}'):
                            plan = json.loads(json_str)
                            if isinstance(plan, dict):
                                return plan
                    except json.JSONDecodeError:
                        continue

            # å°è¯•æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
            brace_count = 0
            start_idx = -1
            for i, char in enumerate(text):
                if char == '{':
                    if brace_count == 0:
                        start_idx = i
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and start_idx != -1:
                        json_str = text[start_idx:i + 1]
                        try:
                            return json.loads(json_str)
                        except json.JSONDecodeError:
                            continue

            return None
        except Exception:
            return None

    def _extract_plan_from_text(self, text: str) -> Dict[str, Any]:
        """ä»è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­æå–å‰ªè¾‘è®¡åˆ’"""

        # æå–ç›®æ ‡æ—¶é•¿
        target_duration = 30
        duration_patterns = [
            r'ç›®æ ‡æ—¶é•¿[ï¼š:]\s*(\d+)',
            r'æ—¶é•¿[ï¼š:]\s*(\d+)',
            r'(\d+)\s*ç§’'
        ]

        for pattern in duration_patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    target_duration = int(match.group(1))
                    break
                except:
                    pass

        # æ ¹æ®æ–‡æœ¬å†…å®¹æ¨æ–­æ“ä½œ
        actions = []

        # æ£€æµ‹å‰ªåˆ‡æ“ä½œ
        if any(keyword in text for keyword in ['å‰ªåˆ‡', 'è£å‰ª', 'æˆªå–', 'æ—¶é•¿']):
            actions.append({
                "action": "cut",
                "target_duration": target_duration,
                "preserve_important": True,
                "reason": "å‰ªåˆ‡ï¼Œæ ¹æ®è¦æ±‚ä¿ç•™å†…å®¹"
            })

        # æ£€æµ‹æ»¤é•œæ“ä½œ
        if any(keyword in text for keyword in ['æ»¤é•œ', 'å¢å¼º', 'ç¾åŒ–', 'è°ƒè‰²']):
            actions.append({
                "action": "apply_filter",
                "filter_name": "enhance",
                "intensity": 0.3,
                "reason": "AIå»ºè®®åº”ç”¨å¢å¼ºæ»¤é•œ"
            })

        # æ£€æµ‹è½¬åœºæ“ä½œ
        if any(keyword in text for keyword in ['è½¬åœº', 'è¿‡æ¸¡', 'è¡”æ¥']):
            actions.append({
                "action": "apply_transitions",
                "transition_type": "fade",
                "duration": 0.5,
                "reason": "AIå»ºè®®æ·»åŠ è½¬åœºæ•ˆæœ"
            })

        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•æ“ä½œï¼Œæ·»åŠ é»˜è®¤æ“ä½œ
        if not actions:
            actions.append({
                "action": "cut",
                "target_duration": target_duration,
                "preserve_important": True,
                "reason": "å‰ªåˆ‡ï¼Œæ ¹æ®è¦æ±‚ä¿ç•™å†…å®¹"
            })

        return {
            "target_duration": target_duration,
            "actions": actions,
            "metadata": {
                "description": f"ä»AIæ–‡æœ¬å“åº”æå–çš„å‰ªè¾‘ç­–ç•¥: {text[:100]}...",
                "confidence": 0.6,
                "source": "text_extraction"
            }
        }

    def _validate_plan(self, plan: Dict[str, Any]) -> bool:
        """éªŒè¯å‰ªè¾‘è®¡åˆ’çš„æ ¼å¼æ˜¯å¦æ­£ç¡®"""
        try:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if not isinstance(plan, dict):
                return False

            # target_duration åº”è¯¥æ˜¯æ•°å­—
            if 'target_duration' in plan:
                if not isinstance(plan['target_duration'], (int, float)):
                    return False

            # actions åº”è¯¥æ˜¯åˆ—è¡¨
            if 'actions' in plan:
                if not isinstance(plan['actions'], list):
                    return False

                # æ£€æŸ¥æ¯ä¸ªactionçš„æ ¼å¼
                for action in plan['actions']:
                    if not isinstance(action, dict) or 'action' not in action:
                        return False

            return True

        except Exception:
            return False

    def _generate_local_plan(self, prompt: str) -> Dict[str, Any]:
        """æœ¬åœ°ç”Ÿæˆå‰ªè¾‘è®¡åˆ’ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print("ğŸ  ä½¿ç”¨æœ¬åœ°æ™ºèƒ½ç­–ç•¥ç”Ÿæˆå‰ªè¾‘è®¡åˆ’")

        # ä»promptä¸­æå–ç›®æ ‡æ—¶é•¿
        target_duration = 30
        duration_patterns = [
            r'ç›®æ ‡æ—¶é•¿[ï¼š:]\s*(\d+)',
            r'æ—¶é•¿[ï¼š:]\s*(\d+)',
            r'(\d+)\s*ç§’'
        ]

        for pattern in duration_patterns:
            match = re.search(pattern, prompt)
            if match:
                try:
                    target_duration = int(match.group(1))
                    break
                except:
                    pass

        # æ ¹æ®å†…å®¹ç±»å‹ç”Ÿæˆä¸åŒç­–ç•¥
        actions = []

        if 'ä¼ä¸š' in prompt or 'å•†åŠ¡' in prompt:
            # ä¼ä¸šé£æ ¼
            actions = [
                {
                    "action": "cut",
                    "target_duration": target_duration,
                    "preserve_important": True,
                    "reason": "å‰ªåˆ‡ï¼Œæ ¹æ®è¦æ±‚ä¿ç•™å†…å®¹"
                },
                {
                    "action": "apply_filter",
                    "filter_name": "professional",
                    "intensity": 0.2,
                    "reason": "åº”ç”¨ä¸“ä¸šé£æ ¼æ»¤é•œ"
                }
            ]
        elif 'æŠ–éŸ³' in prompt or 'ç¤¾äº¤' in prompt:
            # ç¤¾äº¤åª’ä½“é£æ ¼
            actions = [
                {
                    "action": "cut",
                    "target_duration": target_duration,
                    "preserve_important": True,
                    "reason": "å¿«èŠ‚å¥å‰ªåˆ‡é€‚åˆç¤¾äº¤åª’ä½“"
                },
                {
                    "action": "apply_filter",
                    "filter_name": "vibrant",
                    "intensity": 0.4,
                    "reason": "åº”ç”¨é²œè‰³æ»¤é•œå¢åŠ å¸å¼•åŠ›"
                }
            ]
        else:
            # é€šç”¨ç­–ç•¥
            actions = [
                {
                    "action": "cut",
                    "target_duration": target_duration,
                    "preserve_important": True,
                    "reason": "å‰ªåˆ‡ï¼Œæ ¹æ®è¦æ±‚ä¿ç•™å†…å®¹"
                }
            ]

        return {
            "target_duration": target_duration,
            "actions": actions,
            "metadata": {
                "description": f"æœ¬åœ°ç”Ÿæˆçš„æ™ºèƒ½å‰ªè¾‘ç­–ç•¥ - ç›®æ ‡æ—¶é•¿{target_duration}ç§’",
                "confidence": 0.7,
                "source": "local_generation"
            }
        }

    def test_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•APIè¿æ¥"""

        if not self.api_key:
            return {
                "status": "failed",
                "recommended_mode": "local",
                "error": "æœªé…ç½®APIå¯†é’¥"
            }

        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }

            # ä½¿ç”¨æœ€ä¾¿å®œçš„æ¨¡å‹æµ‹è¯•
            test_data = {
                "model": "qwen-turbo",
                "messages": [
                    {"role": "user", "content": "æµ‹è¯•è¿æ¥"}
                ],
                "max_tokens": 5
            }

            url = f"{self.base_url}/chat/completions"
            response = requests.post(url, json=test_data, headers=headers, timeout=10)

            if response.status_code == 200:
                return {
                    "status": "success",
                    "recommended_mode": "online",
                    "model": self.model
                }
            else:
                error_detail = ""
                try:
                    error_info = response.json()
                    error_detail = error_info.get('error', {}).get('message', response.text)
                except:
                    error_detail = response.text

                return {
                    "status": "failed",
                    "recommended_mode": "local",
                    "error": f"HTTP {response.status_code}: {error_detail}"
                }

        except requests.exceptions.Timeout:
            return {
                "status": "failed",
                "recommended_mode": "local",
                "error": "è¿æ¥è¶…æ—¶"
            }
        except Exception as e:
            return {
                "status": "failed",
                "recommended_mode": "local",
                "error": str(e)
            }

    def call_model(self, prompt: str) -> str:
        """
        å…¼å®¹æ—§ç‰ˆæœ¬çš„æ–¹æ³• - ç›´æ¥è°ƒç”¨æ¨¡å‹è¿”å›æ–‡æœ¬

        Args:
            prompt: è¾“å…¥æç¤ºè¯

        Returns:
            str: æ¨¡å‹è¿”å›çš„æ–‡æœ¬
        """
        try:
            plan = self.generate_editing_plan(prompt, use_local=False)
            return json.dumps(plan, ensure_ascii=False, indent=2)
        except Exception as e:
            return f"è°ƒç”¨å¤±è´¥: {str(e)}"

    def set_model(self, model: str) -> bool:
        """
        è®¾ç½®ä½¿ç”¨çš„æ¨¡å‹

        Args:
            model: æ¨¡å‹åç§°

        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if model in self.supported_models:
            self.model = model
            print(f"âœ… æ¨¡å‹å·²è®¾ç½®ä¸º: {model}")
            return True
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model}")
            print(f"æ”¯æŒçš„æ¨¡å‹: {', '.join(self.supported_models)}")
            return False

    def get_available_models(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return self.supported_models.copy()


# ä¾¿æ·å‡½æ•°
def test_ai_connection(api_key: str = None) -> Dict[str, Any]:
    """æµ‹è¯•AIè¿æ¥çš„ä¾¿æ·å‡½æ•°"""
    caller = AIModelCaller(api_key=api_key)
    return caller.test_connection()


def quick_generate_plan(prompt: str, api_key: str = None, model: str = "qwen-plus") -> Dict[str, Any]:
    """å¿«é€Ÿç”Ÿæˆå‰ªè¾‘è®¡åˆ’çš„ä¾¿æ·å‡½æ•°"""
    caller = AIModelCaller(api_key=api_key, model=model)
    return caller.generate_editing_plan(prompt)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯• AIModelCaller...")

    caller = AIModelCaller()

    # æµ‹è¯•è¿æ¥
    result = caller.test_connection()
    print(f"è¿æ¥æµ‹è¯•ç»“æœ: {result}")

    # æµ‹è¯•ç”Ÿæˆè®¡åˆ’
    test_prompt = """
    è§†é¢‘ä¿¡æ¯ï¼š
    - æ—¶é•¿: 120ç§’
    - å†…å®¹ç±»å‹: ä¼ä¸šå®£ä¼ 
    - ç›®æ ‡æ—¶é•¿: 30ç§’
    - ç›®æ ‡é£æ ¼: ä¼ä¸šé£

    è¯·ç”Ÿæˆå‰ªè¾‘ç­–ç•¥ã€‚
    """

    plan = caller.generate_editing_plan(test_prompt)
    print(f"ç”Ÿæˆçš„å‰ªè¾‘è®¡åˆ’: {json.dumps(plan, ensure_ascii=False, indent=2)}")